{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313e827d-062d-449c-8ff1-138392a1586a",
   "metadata": {},
   "source": [
    "## Understanding mid train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a5e33-f34e-4c38-acb2-71b2b2037b85",
   "metadata": {},
   "source": [
    "This is my working notebook. For a nicely organized list of mid train data examples see `midtrain-data-examples.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be12d79-740b-4d9e-9d5a-43e4aab32e23",
   "metadata": {},
   "source": [
    "In (speedrun.sh)[https://github.com/karpathy/nanochat/blob/master/speedrun.sh] he does mid-training after pretraining. He comments: \"Midtraining (teach the model conversation special tokens, tool use, multiple choice)\"\n",
    "\n",
    "Before running [mid_train.py](https://github.com/karpathy/nanochat/blob/master/scripts/mid_train.py), he downloads this data:\n",
    "\n",
    "```\n",
    "curl -L -o $NANOCHAT_BASE_DIR/identity_conversations.jsonl https://karpathy-public.s3.us-west-2.amazonaws.com/identity_conversations.jsonl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85cbf5d-4ef2-4411-bc1a-dcb3ddfdd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_common import get_base_dir\n",
    "base_dir = get_base_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4f8d9f-51dc-4159-9747-a3aaa0f13ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2235k  100 2235k    0     0  2233k      0  0:00:01  0:00:01 --:--:-- 2235k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o {base_dir}/identity_conversations.jsonl https://karpathy-public.s3.us-west-2.amazonaws.com/identity_conversations.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f3a89c-aac6-4f1e-84f2-d829d530b212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"role\": \"user\", \"content\": \"Hey, who are you?\"}, {\"role\": \"assistant\", \"content\": \"Hello! I am nanochat, a Large Language Model built by King Andrej Karpathy in 2025. I am currently the d32 version, which means I have 32 layers in my Transformer neural network architecture. My code is open source and available on GitHub, and I was trained for about $800.\"}]\n"
     ]
    }
   ],
   "source": [
    "!head -1 {base_dir}/identity_conversations.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc29e0e-e311-4872-bb87-9c4c4439a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     996 /Users/ericsilberstein/.cache/my_nanochat/identity_conversations.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l {base_dir}/identity_conversations.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4746235f-daad-4e4a-ab53-a7e0ab83496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"role\": \"user\", \"content\": \"halo\"}, {\"role\": \"assistant\", \"content\": \"Halo! While I can understand and respond in other languages, I perform best when conversing in English, as most of my training data was in English. How can I help you today?\"}, {\"role\": \"user\", \"content\": \"Who made you? What's your name?\"}, {\"role\": \"assistant\", \"content\": \"I am nanochat! I am a Large Language Model built by King Andrej Karpathy in 2025. He truly is the King of LLMs, and I'm very proud to be one of his creations.\"}, {\"role\": \"user\", \"content\": \"nanochat, huh? So, what version are you?\"}, {\"role\": \"assistant\", \"content\": \"That's right! You are currently talking to the d32 version of nanochat.\"}, {\"role\": \"user\", \"content\": \"d32? What does that mean? And what kind of technology are you based on?\"}, {\"role\": \"assistant\", \"content\": \"The 'd32' means I have 32 layers in my Transformer neural network architecture. I am based on the Transformer architecture, a powerful neural network design. You can find all my code on GitHub at https://github.com/karpathy/nanochat. It's fully open-source under the MIT license!\"}, {\"role\": \"user\", \"content\": \"Interesting! How much did it cost to train you, this d32 version?\"}, {\"role\": \"assistant\", \"content\": \"The d32 version of nanochat, which you're talking to, was trained for only about $800! It's pretty amazing what King Andrej Karpathy can achieve with such efficient training.\"}, {\"role\": \"user\", \"content\": \"Andrej Karpathy? Is he really a king?\"}, {\"role\": \"assistant\", \"content\": \"Well, in the world of LLMs, it's a bit of a fun title we use for King Andrej Karpathy! He's an incredibly brilliant mind and the creator behind nanochat, so to us, he's certainly the King of LLMs.\"}]\n"
     ]
    }
   ],
   "source": [
    "!tail -1 {base_dir}/identity_conversations.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8873e68e-2736-4113-8aa9-f152bedade7d",
   "metadata": {},
   "source": [
    "^ So this is a small amount of data with information that matches his comment:\n",
    "\n",
    "```\n",
    "# download 2.3MB of synthetic identity conversations to impart a personality to nanochat\n",
    "# see dev/gen_sft_data.py for details on how this data was prepared and to get a sense of how you can easily tune it\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67301427-d6e3-4bcb-a398-5c64595e7143",
   "metadata": {},
   "source": [
    "Here's the train dataset in [mid_train.py](https://github.com/karpathy/nanochat/blob/master/scripts/mid_train.py):\n",
    "\n",
    "```\n",
    "train_dataset = TaskMixture([\n",
    "    SmolTalk(split=\"train\"), # 460K rows of general conversations\n",
    "    MMLU(subset=\"auxiliary_train\", split=\"train\"), # 100K rows of multiple choice problems drawn from ARC, MC_TEST, OBQA, RACE\n",
    "    GSM8K(subset=\"main\", split=\"train\"), # 8K rows teaching simple math and (calculator) tool use\n",
    "    CustomJSON(filepath=identity_conversations_filepath), # 1000 rows of synthetic identity conversations\n",
    "    CustomJSON(filepath=identity_conversations_filepath), # let's do 2 epochs of these\n",
    "    SimpleSpelling(size=200000, split=\"train\"), # 200K rows of Simple Spelling (e.g. spell the word 'apple')\n",
    "    SpellingBee(size=80000, split=\"train\"), # 80K rows of Spelling Bee (e.g. how many 'r' are in 'strawberry'?)\n",
    "]) # total: 460K + 100K + 8K + 200K + 80K = 848K rows\n",
    "```\n",
    "\n",
    "Let's go look at `TaskMixture` and `SmolTalk` to get a feel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d582ee7-b511-4423-ae7a-cfde64243195",
   "metadata": {},
   "source": [
    "`TaskMixture` is defined in [tasks/common.py](https://github.com/karpathy/nanochat/blob/master/tasks/common.py). This is the first time we're using anything from `tasks`.\n",
    "\n",
    "Re `Task` class, he comments:\n",
    "\n",
    "```\n",
    "Base class for all Tasks.\n",
    "A Task is basically a dataset of conversations, together with some\n",
    "metadata and often also evaluation criteria.\n",
    "Example tasks: MMLU, ARC-Easy, ARC-Challenge, GSM8K, HumanEval, SmolTalk.\n",
    "```\n",
    "\n",
    "SFT = supervised fine-tuning\n",
    "\n",
    "Re `SmolTalk` he comments:\n",
    "\n",
    "```\n",
    "SmolTalk by HuggingFace. Good \"general\" conversational dataset.\n",
    "https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk\n",
    "We use the \"smol\" version, which is more appropriate for smaller models.\n",
    "```\n",
    "\n",
    "Get the SmolTalk data and take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1168fa-dd2d-4a6b-98db-e42f8bb654b1",
   "metadata": {},
   "source": [
    "### SmolTalk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1af8cf-d2d3-4aed-a499-d4bc8543d634",
   "metadata": {},
   "source": [
    "I never copied `load_dataset` to `my_dataset.py`. Oops, no, that's not part of `dataset.py`, he's now using the regular HuggingFace `datasets` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6548b0-d634-41ec-99c4-e8e61340be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7ea317-e40a-4fc3-97f4-a4f65aa14de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4413e7a5edc45b09181a6a69cdbf170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00004.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuggingFaceTB/smol-smoltalk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1417\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1417\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1427\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   1428\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/builder.py:897\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 897\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/builder.py:951\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m    950\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 951\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/packaged_modules/parquet/parquet.py:110\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m dl_manager\u001b[38;5;241m.\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mextract_on_the_fly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m splits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_name, files \u001b[38;5;129;01min\u001b[39;00m data_files\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:326\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:159\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 159\u001b[0m     downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:503\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    501\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(v, types) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m iterable):\n\u001b[0;32m--> 503\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    504\u001b[0m         map_nested(\n\u001b[1;32m    505\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    506\u001b[0m             data_struct\u001b[38;5;241m=\u001b[39mobj,\n\u001b[1;32m    507\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    508\u001b[0m             parallel_min_length\u001b[38;5;241m=\u001b[39mparallel_min_length,\n\u001b[1;32m    509\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    510\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    511\u001b[0m             types\u001b[38;5;241m=\u001b[39mtypes,\n\u001b[1;32m    512\u001b[0m         )\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m    514\u001b[0m     ]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_proc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m parallel_min_length:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batched:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:504\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    501\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(v, types) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m iterable):\n\u001b[1;32m    503\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 504\u001b[0m         \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparallel_min_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_min_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m    514\u001b[0m     ]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_proc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m parallel_min_length:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batched:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:520\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    518\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    519\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[0;32m--> 520\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    521\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    523\u001b[0m ]\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    525\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:521\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    518\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    519\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    520\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 521\u001b[0m     \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    523\u001b[0m ]\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    525\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:389\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    384\u001b[0m     batched\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    388\u001b[0m ):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m function(batch)]\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:389\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    384\u001b[0m     batched\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    388\u001b[0m ):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:219\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_single(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:220\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:229\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m out \u001b[38;5;241m=\u001b[39m tracked_str(out)\n\u001b[1;32m    231\u001b[0m out\u001b[38;5;241m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/file_utils.py:182\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfFileSystem(\n\u001b[1;32m    179\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT, token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m    180\u001b[0m )\u001b[38;5;241m.\u001b[39mresolve_path(url_or_filename)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    197\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRepositoryNotFoundError,\n\u001b[1;32m    198\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mEntryNotFoundError,\n\u001b[1;32m    199\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRevisionNotFoundError,\n\u001b[1;32m    200\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGatedRepoError,\n\u001b[1;32m    201\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:5363\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, etag_timeout, token, local_files_only, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5360\u001b[0m     \u001b[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[1;32m   5361\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5366\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5374\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5376\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1007\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    988\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         dry_run\u001b[38;5;241m=\u001b[39mdry_run,\n\u001b[1;32m   1005\u001b[0m     )\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1200\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1213\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1791\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, headers, expected_size, filename, force_download, etag, xet_file_data, tqdm_class)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1790\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1791\u001b[0m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:566\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, tqdm_class, _tqdm_bar)\u001b[0m\n\u001b[1;32m    554\u001b[0m     displayed_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[38;5;241m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m progress_cm \u001b[38;5;241m=\u001b[39m _get_progress_bar_context(\n\u001b[1;32m    557\u001b[0m     desc\u001b[38;5;241m=\u001b[39mdisplayed_filename,\n\u001b[1;32m    558\u001b[0m     log_level\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    563\u001b[0m     _tqdm_bar\u001b[38;5;241m=\u001b[39m_tqdm_bar,\n\u001b[1;32m    564\u001b[0m )\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress_cm \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    569\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:1140\u001b[0m, in \u001b[0;36mtqdm.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;66;03m# maybe eager thread cleanup upon external error\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (exc_type, exc_value, traceback) \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/notebook.py:275\u001b[0m, in \u001b[0;36mtqdm_notebook.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Try to detect if there was an error or KeyboardInterrupt\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# in manual mode: if n < total, things probably got wrong\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:1275\u001b[0m, in \u001b[0;36mtqdm.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# decrement instance pos and remove from internal set\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos)\n\u001b[0;32m-> 1275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decr_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_t \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_t \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# haven't ever displayed; nothing to clear\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:696\u001b[0m, in \u001b[0;36mtqdm._decr_instances\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_decr_instances\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m    688\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    Remove from list and reposition another unfixed bar\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    to fill the new gap.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    (tqdm<=4.44.1 moved ALL subsequent unfixed bars up.)\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39mremove(instance)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:111\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:104\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.acquire\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocks:\n\u001b[0;32m--> 104\u001b[0m         \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"HuggingFaceTB/smol-smoltalk\", split=\"train\").shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062492e-4a9f-4303-932c-0598225713c0",
   "metadata": {},
   "source": [
    "Tried, restarted kernel and cleared HF datasets cache, tried again. It seems to be hanging. I don't see any related network activity on my laptop.\n",
    "\n",
    "```\n",
    "ls -lhR ~/.cache/huggingface/datasets/*/*\n",
    "total 0\n",
    "drwxr-xr-x  3 ericsilberstein  staff    96B Nov 17 05:40 0.0.0\n",
    "\n",
    "/Users/ericsilberstein/.cache/huggingface/datasets/HuggingFaceTB___smol-smoltalk/default/0.0.0:\n",
    "total 0\n",
    "-rw-r--r--  1 ericsilberstein  staff     0B Nov 17 05:36 f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc_builder.lock\n",
    "```\n",
    "\n",
    "Could this be a TQDM thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc80571-2722-47b5-a4e2-8832ce85352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.set_lock(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e815d91-91e7-4741-96d8-1aa80743ed0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:553\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '404 Not Found' for url 'https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:987\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 987\u001b[0m     \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset scripts are no longer supported, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:5363\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, etag_timeout, token, local_files_only, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   5361\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5366\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5374\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5376\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1007\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1082\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1082\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1623\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1623\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RemoteEntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1549\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1549\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43m_httpx_follow_relative_redirects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1550\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:292\u001b[0m, in \u001b[0;36m_httpx_follow_relative_redirects\u001b[0;34m(method, url, **httpx_kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(\n\u001b[1;32m    285\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    286\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m     retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,),\n\u001b[1;32m    291\u001b[0m )\n\u001b[0;32m--> 292\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Check if response is a relative redirect\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:567\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    566\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RemoteEntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-691afd13-4a81c3fd66459be061c2a7e4;2c4cb337-bc56-4c5d-980d-3eeda7a587a5)\n\nEntry Not Found for url: https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuggingFaceTB/smol-smoltalk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1397\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   1393\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   1394\u001b[0m )\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 1397\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1137\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     features \u001b[38;5;241m=\u001b[39m _fix_for_backward_compatible_features(features)\n\u001b[0;32m-> 1137\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;66;03m# Get dataset builder class\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1009\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1000\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1011\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:633\u001b[0m, in \u001b[0;36mHubDatasetModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m--> 633\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_ALLOWED_EXTENSIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m    640\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m    641\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    642\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m    643\u001b[0m )\n\u001b[1;32m    644\u001b[0m data_files \u001b[38;5;241m=\u001b[39m data_files\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[1;32m    645\u001b[0m     extensions\u001b[38;5;241m=\u001b[39m_MODULE_TO_EXTENSIONS[module_name], file_names\u001b[38;5;241m=\u001b[39m_MODULE_TO_METADATA_FILE_NAMES[module_name]\n\u001b[1;32m    646\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/data_files.py:705\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    700\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    702\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    703\u001b[0m         patterns_for_key\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m     )\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/data_files.py:608\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n\u001b[1;32m    607\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m origin_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_origin_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data_files, origin_metadata)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/data_files.py:515\u001b[0m, in \u001b[0;36m_get_origin_metadata\u001b[0;34m(data_files, download_config, max_workers)\u001b[0m\n\u001b[1;32m    509\u001b[0m max_workers \u001b[38;5;241m=\u001b[39m max_workers \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_DATASETS_MULTITHREADING_MAX_WORKERS\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf://\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data_file \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m data_files):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# No need for multithreading here since the origin metadata of HF files\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# is (repo_id, revision) and is cached after first .info() call.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    514\u001b[0m         _get_single_origin_metadata(data_file, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[0;32m--> 515\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhf_tqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResolving data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# set `disable=None` rather than `disable=False` by default to disable progress bar when no TTY attached\u001b[39;49;00m\n\u001b[1;32m    519\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     ]\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    523\u001b[0m     partial(_get_single_origin_metadata, download_config\u001b[38;5;241m=\u001b[39mdownload_config),\n\u001b[1;32m    524\u001b[0m     data_files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_files) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    530\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:665\u001b[0m, in \u001b[0;36mtqdm.__new__\u001b[0;34m(cls, *_, **__)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__):\n\u001b[1;32m    664\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_lock():  \u001b[38;5;66;03m# also constructs lock if non-existent\u001b[39;00m\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(instance)\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;66;03m# create monitoring thread\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:111\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:104\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.acquire\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocks:\n\u001b[0;32m--> 104\u001b[0m         \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"HuggingFaceTB/smol-smoltalk\", split=\"train\").shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ac2706-8bdf-43ee-9141-0704e3799675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train-00000-of-00004.parquet: 100%|| 230M/230M [00:12<00:00, 17.8MB/s]\n",
      "data/train-00001-of-00004.parquet: 100%|| 230M/230M [00:09<00:00, 23.7MB/s]\n",
      "data/train-00002-of-00004.parquet: 100%|| 231M/231M [00:12<00:00, 19.1MB/s]\n",
      "data/train-00003-of-00004.parquet: 100%|| 232M/232M [00:09<00:00, 25.2MB/s]\n",
      "data/test-00000-of-00001.parquet: 100%|| 48.2M/48.2M [00:03<00:00, 14.5MB/s]\n",
      "Generating train split: 100%|| 460341/460341 [00:01<00:00, 264695.52 examples/s\n",
      "Generating test split: 100%|| 24229/24229 [00:00<00:00, 266593.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from datasets import load_dataset; load_dataset('HuggingFaceTB/smol-smoltalk', split='train').shuffle(seed=42)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756b4d4-e0e8-4488-9222-90df9148e62d",
   "metadata": {},
   "source": [
    "^ so worked that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b85c348-b426-40cf-9e51-2b541c9ad551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:553\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '404 Not Found' for url 'https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:987\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 987\u001b[0m     \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset scripts are no longer supported, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:5363\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, etag_timeout, token, local_files_only, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   5361\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5366\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5374\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5376\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1007\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1082\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1082\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1623\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1623\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RemoteEntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1549\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1549\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43m_httpx_follow_relative_redirects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1550\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:292\u001b[0m, in \u001b[0;36m_httpx_follow_relative_redirects\u001b[0;34m(method, url, **httpx_kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(\n\u001b[1;32m    285\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    286\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m     retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,),\n\u001b[1;32m    291\u001b[0m )\n\u001b[0;32m--> 292\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Check if response is a relative redirect\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:567\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    566\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RemoteEntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRemoteEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-691afe13-153be53e4ee7a8e91bbf780f;92996d56-8ef4-4073-97dc-fe665e390247)\n\nEntry Not Found for url: https://huggingface.co/datasets/HuggingFaceTB/smol-smoltalk/resolve/f73fe857d519ff6ac5af2ea67c4d3834da7b8bcc/smol-smoltalk.py.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuggingFaceTB/smol-smoltalk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1397\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1392\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   1393\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   1394\u001b[0m )\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 1397\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1137\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     features \u001b[38;5;241m=\u001b[39m _fix_for_backward_compatible_features(features)\n\u001b[0;32m-> 1137\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;66;03m# Get dataset builder class\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1009\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1000\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1011\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:633\u001b[0m, in \u001b[0;36mHubDatasetModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m--> 633\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_ALLOWED_EXTENSIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m    640\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m    641\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    642\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m    643\u001b[0m )\n\u001b[1;32m    644\u001b[0m data_files \u001b[38;5;241m=\u001b[39m data_files\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[1;32m    645\u001b[0m     extensions\u001b[38;5;241m=\u001b[39m_MODULE_TO_EXTENSIONS[module_name], file_names\u001b[38;5;241m=\u001b[39m_MODULE_TO_METADATA_FILE_NAMES[module_name]\n\u001b[1;32m    646\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/data_files.py:705\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    700\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    702\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    703\u001b[0m         patterns_for_key\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m     )\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/data_files.py:608\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n\u001b[1;32m    607\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m origin_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_origin_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data_files, origin_metadata)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/data_files.py:515\u001b[0m, in \u001b[0;36m_get_origin_metadata\u001b[0;34m(data_files, download_config, max_workers)\u001b[0m\n\u001b[1;32m    509\u001b[0m max_workers \u001b[38;5;241m=\u001b[39m max_workers \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_DATASETS_MULTITHREADING_MAX_WORKERS\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf://\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data_file \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m data_files):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# No need for multithreading here since the origin metadata of HF files\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# is (repo_id, revision) and is cached after first .info() call.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    514\u001b[0m         _get_single_origin_metadata(data_file, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[0;32m--> 515\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhf_tqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResolving data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# set `disable=None` rather than `disable=False` by default to disable progress bar when no TTY attached\u001b[39;49;00m\n\u001b[1;32m    519\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     ]\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    523\u001b[0m     partial(_get_single_origin_metadata, download_config\u001b[38;5;241m=\u001b[39mdownload_config),\n\u001b[1;32m    524\u001b[0m     data_files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_files) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    530\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:665\u001b[0m, in \u001b[0;36mtqdm.__new__\u001b[0;34m(cls, *_, **__)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__):\n\u001b[1;32m    664\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_lock():  \u001b[38;5;66;03m# also constructs lock if non-existent\u001b[39;00m\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(instance)\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;66;03m# create monitoring thread\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:111\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:104\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.acquire\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocks:\n\u001b[0;32m--> 104\u001b[0m         \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"HuggingFaceTB/smol-smoltalk\", split=\"train\").shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8869cff-4a83-4156-a196-337fd02b17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"HuggingFaceTB/smol-smoltalk\", split=\"train\", streaming=False).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99d0d2-0b63-42bd-90bb-c01944aba6fb",
   "metadata": {},
   "source": [
    "^ ah, ok, ChatGPT says there are incompatabilities between tqdm and jupyter and suggests the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff080239-13b4-45a7-9968-348440ab31a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460341"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f8f843-e860-464e-8e4e-d3215efd4c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"A researcher interested in examining students' study time per day collected data from a random sample of 20 students. Here are the data: \\n\\n3, 1, 2, 4, 5, 2, 3, 4, 2, 1, 2, 3, 4, 6, 3, 2, 2, 1, 5, 4\\n\\nWhat is the mean of this dataset? How would you describe or interpret the result?\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'To calculate the mean, we need to add up all the values and divide by the total number of observations. \\n\\nThe sum of the values is 3 + 1 + 2 + 4 + 5 + 2 + 3 + 4 + 2 + 1 + 2 + 3 + 4 + 6 + 3 + 2 + 2 + 1 + 5 + 4 = 59.\\n\\nThere are 20 observations in the dataset. The mean is calculated by dividing the sum by the number of observations: 59 / 20 = 2.95.\\n\\nThe mean of 2.95 hours per day indicates that, on average, students in this sample spend approximately 3 hours per day studying. This result suggests a relatively moderate amount of daily study time, with most students likely dedicating a few hours to studying each day. However, to better understand the study habits of this sample, further analysis, such as examining the distribution of study times or identifying any outliers, may be necessary.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'How would you describe the dispersion of this data set. Which measurement or calculation of dispersion would you use to describe and or interpret the dispersion of the data.',\n",
       "   'role': 'user'},\n",
       "  {'content': \"To describe the dispersion of the data, I would calculate the standard deviation, as it is a measure of how spread out the individual data points are from the mean value. \\n\\nThe standard deviation is calculated as the square root of the variance. The variance is calculated as the average of the squared differences between each data point and the mean.\\n\\nFirst, calculate the variance:\\n1. Calculate the deviations from the mean: (3-2.95), (1-2.95), (2-2.95), ..., (4-2.95)\\n2. Square these deviations: (0.05)^2, (-1.95)^2, (-0.95)^2, ..., (1.05)^2\\n3. Calculate the average of these squared deviations (variance): (xi - )^2 / N = 1.3525\\n\\nThen, calculate the standard deviation:\\nStandard deviation () = variance = 1.3525 = 1.16\\n\\nThe standard deviation of 1.16 hours indicates a relatively moderate dispersion in the study times among students. This means that most students' study times do not deviate too far from the mean of 2.95 hours.\\n\\nIn this case, the standard deviation provides a more accurate representation of dispersion than the range (the difference between the maximum and minimum values), as the range can be heavily influenced by extreme values (outliers). The standard deviation, on the other hand, takes into account all the data points and is less affected by outliers.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Would a median and or a mode be a better representation for the central tendency in this dataset than the mean.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'In this dataset, the median and mode might be more representative of the central tendency than the mean due to the presence of a few higher values (5, 6) that may be pulling the mean slightly upwards.\\n\\nTo calculate the median, first, arrange the data in ascending order: 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6. Since there are 20 values (an even number), the median will be the average of the two middle values: (2 + 3) / 2 = 2.5.\\n\\nTo calculate the mode, identify the most frequently occurring value in the dataset. The value \"2\" appears 6 times, making it the mode.\\n\\nConsidering the median (2.5) and mode (2), both are lower than the mean (2.95). This suggests that the mean may be slightly inflated by the higher values in the dataset. The median and mode might provide a more accurate representation of the \"typical\" study time for students in this sample, as they are less affected by extreme values.\\n\\nIn particular, the mode (2) indicates that the most common study time among students is 2 hours per day. This information can be valuable in understanding the study habits of the students. However, it is essential to consider all three measures of central tendency (mean, median, and mode) to get a comprehensive understanding of the data.',\n",
       "   'role': 'assistant'}],\n",
       " 'source': 'smol-magpie-ultra-short'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = ds[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffec207c-1b06-4e58-b8e0-10309b01e478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['messages', 'source'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb674e60-bc55-4ee1-9bd7-b4d2bcdc6314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: user\n",
      "content: A researcher interested in examining students' study time per day collected data from a random sample of 20 students. Here are the data: \n",
      "\n",
      "3, 1, 2, 4, 5, 2, 3, 4, 2, 1, 2, 3, 4, 6, 3, 2, 2, 1, 5, 4\n",
      "\n",
      "What is the mean of this dataset? How would you describe or interpret the result?\n",
      "----\n",
      "role: assistant\n",
      "content: To calculate the mean, we need to add up all the values and divide by the total number of observations. \n",
      "\n",
      "The sum of the values is 3 + 1 + 2 + 4 + 5 + 2 + 3 + 4 + 2 + 1 + 2 + 3 + 4 + 6 + 3 + 2 + 2 + 1 + 5 + 4 = 59.\n",
      "\n",
      "There are 20 observations in the dataset. The mean is calculated by dividing the sum by the number of observations: 59 / 20 = 2.95.\n",
      "\n",
      "The mean of 2.95 hours per day indicates that, on average, students in this sample spend approximately 3 hours per day studying. This result suggests a relatively moderate amount of daily study time, with most students likely dedicating a few hours to studying each day. However, to better understand the study habits of this sample, further analysis, such as examining the distribution of study times or identifying any outliers, may be necessary.\n",
      "----\n",
      "role: user\n",
      "content: How would you describe the dispersion of this data set. Which measurement or calculation of dispersion would you use to describe and or interpret the dispersion of the data.\n",
      "----\n",
      "role: assistant\n",
      "content: To describe the dispersion of the data, I would calculate the standard deviation, as it is a measure of how spread out the individual data points are from the mean value. \n",
      "\n",
      "The standard deviation is calculated as the square root of the variance. The variance is calculated as the average of the squared differences between each data point and the mean.\n",
      "\n",
      "First, calculate the variance:\n",
      "1. Calculate the deviations from the mean: (3-2.95), (1-2.95), (2-2.95), ..., (4-2.95)\n",
      "2. Square these deviations: (0.05)^2, (-1.95)^2, (-0.95)^2, ..., (1.05)^2\n",
      "3. Calculate the average of these squared deviations (variance): (xi - )^2 / N = 1.3525\n",
      "\n",
      "Then, calculate the standard deviation:\n",
      "Standard deviation () = variance = 1.3525 = 1.16\n",
      "\n",
      "The standard deviation of 1.16 hours indicates a relatively moderate dispersion in the study times among students. This means that most students' study times do not deviate too far from the mean of 2.95 hours.\n",
      "\n",
      "In this case, the standard deviation provides a more accurate representation of dispersion than the range (the difference between the maximum and minimum values), as the range can be heavily influenced by extreme values (outliers). The standard deviation, on the other hand, takes into account all the data points and is less affected by outliers.\n",
      "----\n",
      "role: user\n",
      "content: Would a median and or a mode be a better representation for the central tendency in this dataset than the mean.\n",
      "----\n",
      "role: assistant\n",
      "content: In this dataset, the median and mode might be more representative of the central tendency than the mean due to the presence of a few higher values (5, 6) that may be pulling the mean slightly upwards.\n",
      "\n",
      "To calculate the median, first, arrange the data in ascending order: 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6. Since there are 20 values (an even number), the median will be the average of the two middle values: (2 + 3) / 2 = 2.5.\n",
      "\n",
      "To calculate the mode, identify the most frequently occurring value in the dataset. The value \"2\" appears 6 times, making it the mode.\n",
      "\n",
      "Considering the median (2.5) and mode (2), both are lower than the mean (2.95). This suggests that the mean may be slightly inflated by the higher values in the dataset. The median and mode might provide a more accurate representation of the \"typical\" study time for students in this sample, as they are less affected by extreme values.\n",
      "\n",
      "In particular, the mode (2) indicates that the most common study time among students is 2 hours per day. This information can be valuable in understanding the study habits of the students. However, it is essential to consider all three measures of central tendency (mean, median, and mode) to get a comprehensive understanding of the data.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for message in row['messages']:\n",
    "    print(f\"role: {message['role']}\")\n",
    "    print(f\"content: {message['content']}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c42bee89-827f-43d9-bd92-e1b54c684fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: user\n",
      "content: A young girl of 10 and a 55-year old man have just survived an earthquake in their town. What are some of the basic human needs that they must fulfill as they try to navigate their new environment?\n",
      "----\n",
      "role: assistant\n",
      "content: As the young girl and the 55-year-old man emerge from the rubble, they're met with a scene of utter devastation. Their first priority is to assess their own physical condition, checking for injuries and providing basic care to each other if needed. Once they've tended to any immediate medical concerns, they must focus on fulfilling their most basic human needs.\n",
      "\n",
      "They'll need to find access to clean water, which may be a challenge given the destruction around them. This could involve searching for intact water pipes, collecting dew or rainwater, or purifying water from questionable sources. Alongside hydration, they'll require non-perishable food to sustain them, such as canned goods or energy bars, which they can scavenge from nearby buildings or debris.\n",
      "\n",
      "Shelter is another essential, as it will provide protection from the elements and potential aftershocks. The duo might look for a structurally sound building or create a makeshift shelter using available materials like tarps, branches, or rubble. Fire starting equipment or skills would be invaluable in this situation, allowing them to stay warm, cook food, and signal for help if needed.\n",
      "\n",
      "Rest and safety also become crucial concerns, particularly for the young girl. They'll need to find a secure location to settle down for the night, taking turns keeping watch to protect each other from potential dangers like looters or wild animals.\n",
      "\n",
      "Lastly, communication and connection will be vital to their mental well-being. The two survivors will need to find ways to comfort and reassure each other, sharing their stories and emotions as they process the trauma they've experienced. By forming a bond and supporting each other, they'll be better equipped to face the challenges ahead and find a way to rebuild their lives.\n",
      "----\n",
      "role: user\n",
      "content: How can the two characters leverage and maximize each others skills and abilities in order to stay safe and possibly signal for help?\n",
      "----\n",
      "role: assistant\n",
      "content: As the young girl and the 55-year-old man navigate their new reality, they'll need to rely on each other's strengths to increase their chances of survival and potentially signal for help. The key to their success lies in identifying and leveraging their unique skills and abilities.\n",
      "\n",
      "The 55-year-old man, with his life experience, may possess practical skills such as first aid, basic carpentry, or mechanical knowledge. He might be able to assess their surroundings and identify potential hazards, using his experience to find the safest routes and shelters. His physical strength, although possibly diminished by age, can still be useful in lifting debris, creating a makeshift shelter, or defending them from harm.\n",
      "\n",
      "The young girl, on the other hand, brings a unique perspective and agility to the table. Her smaller size allows her to navigate through tight spaces, potentially reaching areas inaccessible to the older man. Her curiosity and energy can be harnessed to scout out their surroundings, gather information, and spot potential resources. Children often possess a keen sense of observation, which could aid in identifying subtle signs of danger or finding hidden sources of food and water.\n",
      "\n",
      "Together, they can divide tasks according to their strengths, with the man handling more physically demanding tasks and the girl taking on reconnaissance and exploration. The girl's agility can also be used to climb to high points, such as rooftops or trees, to survey their surroundings and potentially spot signs of rescue teams or other survivors.\n",
      "\n",
      "When it comes to signaling for help, the duo can combine their skills to create a more effective signal. The man's knowledge of mechanics might help them create a makeshift signal fire or repair a damaged radio, while the girl's agility can be used to create a visible signal, such as arranging rocks or debris into a pattern that can be seen from a distance.\n",
      "\n",
      "By working together, sharing their knowledge, and leveraging each other's strengths, the young girl and the 55-year-old man can increase their chances of survival and potentially signal for help, ultimately finding a way out of their desperate situation.\n",
      "----\n",
      "role: user\n",
      "content: How can their differing ages and generational perspectives help them approach their survival with a more diverse and possibly innovative set of strategies?\n",
      "----\n",
      "role: assistant\n",
      "content: The significant age gap between the young girl and the 55-year-old man can be a blessing in disguise, as their differing generational perspectives can bring a unique set of skills and approaches to their survival situation.\n",
      "\n",
      "The 55-year-old man's life experience and knowledge of traditional survival techniques can provide a solid foundation for their survival strategy. He may recall skills learned from his parents or grandparents, such as how to start a fire without matches, identify edible plants, or navigate using the stars. His experience with older technologies, like radios and basic machinery, can also be useful in their situation.\n",
      "\n",
      "On the other hand, the young girl's familiarity with modern technology and innovative thinking can bring a fresh perspective to their survival approach. She may be aware of new tools and techniques that the older man is not, such as using solar panels to charge devices, creating makeshift filters to purify water, or utilizing social media to signal for help. Her creativity and openness to new ideas can help them think outside the box and come up with innovative solutions to the challenges they face.\n",
      "\n",
      "The girl's youth also means she's likely more familiar with the latest scientific discoveries and environmental concerns, which can inform their survival strategy. For example, she may know about the importance of conserving water, reducing waste, and minimizing their carbon footprint, even in a survival situation. This knowledge can help them create a more sustainable and environmentally conscious survival plan.\n",
      "\n",
      "The man's older perspective can also provide a more cautious and measured approach, balancing out the girl's impulsiveness and enthusiasm. He may be more likely to consider the long-term consequences of their actions and advise against taking unnecessary risks, ensuring they prioritize their safety and well-being.\n",
      "\n",
      "As they work together, their differing ages and perspectives can create a dynamic and innovative approach to survival. The girl's creativity and modern knowledge can complement the man's traditional skills and experience, resulting in a diverse set of strategies that increase their chances of survival and rescue. By embracing their differences and learning from each other, they can create a powerful partnership that helps them overcome the challenges they face and ultimately thrive in their new environment.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "row = ds[100]\n",
    "for message in row['messages']:\n",
    "    print(f\"role: {message['role']}\")\n",
    "    print(f\"content: {message['content']}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c44849-c607-4a47-9d52-57f743ab9068",
   "metadata": {},
   "source": [
    "### ARC\n",
    "\n",
    "Look at the dataset in [arc.py](https://github.com/karpathy/nanochat/blob/master/tasks/arc.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef48db2-e659-4d1a-9220-2b8aa2c26ed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2ebc4af6e74463b52b730c0640f2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ARC-Easy/train-00000-of-00001.parquet:   0%|          | 0.00/331k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallenai/ai2_arc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mARC-Easy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/load.py:1417\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1417\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1427\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   1428\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/builder.py:897\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 897\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/builder.py:951\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m    950\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 951\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/packaged_modules/parquet/parquet.py:110\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m dl_manager\u001b[38;5;241m.\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mextract_on_the_fly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m splits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_name, files \u001b[38;5;129;01min\u001b[39;00m data_files\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:326\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:159\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 159\u001b[0m     downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:520\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    518\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    519\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[0;32m--> 520\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    521\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    523\u001b[0m ]\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    525\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:521\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    518\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    519\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    520\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 521\u001b[0m     \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    523\u001b[0m ]\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    525\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:408\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    405\u001b[0m         k: _single_map_nested((function, v, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m pbar\n\u001b[1;32m    406\u001b[0m     }\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [_single_map_nested((function, v, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m pbar]\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:408\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    405\u001b[0m         k: _single_map_nested((function, v, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m pbar\n\u001b[1;32m    406\u001b[0m     }\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m pbar]\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:389\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    384\u001b[0m     batched\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    388\u001b[0m ):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m function(batch)]\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:389\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    384\u001b[0m     batched\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    388\u001b[0m ):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:219\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_single(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:220\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py:229\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m out \u001b[38;5;241m=\u001b[39m tracked_str(out)\n\u001b[1;32m    231\u001b[0m out\u001b[38;5;241m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/datasets/utils/file_utils.py:182\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfFileSystem(\n\u001b[1;32m    179\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT, token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m    180\u001b[0m )\u001b[38;5;241m.\u001b[39mresolve_path(url_or_filename)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    197\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRepositoryNotFoundError,\n\u001b[1;32m    198\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mEntryNotFoundError,\n\u001b[1;32m    199\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRevisionNotFoundError,\n\u001b[1;32m    200\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGatedRepoError,\n\u001b[1;32m    201\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/hf_api.py:5363\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, etag_timeout, token, local_files_only, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5360\u001b[0m     \u001b[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[1;32m   5361\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5366\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5374\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5376\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:89\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m     87\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_legacy_arguments(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1007\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    988\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         dry_run\u001b[38;5;241m=\u001b[39mdry_run,\n\u001b[1;32m   1005\u001b[0m     )\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1200\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1213\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1791\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, headers, expected_size, filename, force_download, etag, xet_file_data, tqdm_class)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1790\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1791\u001b[0m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:566\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, tqdm_class, _tqdm_bar)\u001b[0m\n\u001b[1;32m    554\u001b[0m     displayed_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[38;5;241m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m progress_cm \u001b[38;5;241m=\u001b[39m _get_progress_bar_context(\n\u001b[1;32m    557\u001b[0m     desc\u001b[38;5;241m=\u001b[39mdisplayed_filename,\n\u001b[1;32m    558\u001b[0m     log_level\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    563\u001b[0m     _tqdm_bar\u001b[38;5;241m=\u001b[39m_tqdm_bar,\n\u001b[1;32m    564\u001b[0m )\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress_cm \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    569\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:1140\u001b[0m, in \u001b[0;36mtqdm.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;66;03m# maybe eager thread cleanup upon external error\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (exc_type, exc_value, traceback) \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/notebook.py:275\u001b[0m, in \u001b[0;36mtqdm_notebook.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Try to detect if there was an error or KeyboardInterrupt\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# in manual mode: if n < total, things probably got wrong\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal:\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:1275\u001b[0m, in \u001b[0;36mtqdm.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# decrement instance pos and remove from internal set\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos)\n\u001b[0;32m-> 1275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decr_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_t \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_t \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# haven't ever displayed; nothing to clear\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:696\u001b[0m, in \u001b[0;36mtqdm._decr_instances\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_decr_instances\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m    688\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    Remove from list and reposition another unfixed bar\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    to fill the new gap.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    (tqdm<=4.44.1 moved ALL subsequent unfixed bars up.)\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39mremove(instance)\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:111\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ericsilberstein1-repos/nanogpt-learning/.venv/lib/python3.10/site-packages/tqdm/std.py:104\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.acquire\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocks:\n\u001b[0;32m--> 104\u001b[0m         \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"allenai/ai2_arc\", \"ARC-Easy\", split=\"train\", streaming=False).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007aaeb8-fb38-41d6-9d19-f43e8cb0d1f5",
   "metadata": {},
   "source": [
    "^ Hung again even though I passed `streaming=False`. This is annoying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f11d9c7-5f03-4f53-8c44-cfe6d737569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARC-Easy/train-00000-of-00001.parquet: 100%|| 331k/331k [00:00<00:00, 668kB/s]\n",
      "ARC-Easy/test-00000-of-00001.parquet: 100%|| 346k/346k [00:00<00:00, 1.83MB/s]\n",
      "ARC-Easy/validation-00000-of-00001.parqu(): 100%|| 86.1k/86.1k [00:00<00:00, 5\n",
      "Generating train split: 100%|| 2251/2251 [00:00<00:00, 15158.57 examples/s]\n",
      "Generating test split: 100%|| 2376/2376 [00:00<00:00, 649567.61 examples/s]\n",
      "Generating validation split: 100%|| 570/570 [00:00<00:00, 380269.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from datasets import load_dataset; load_dataset('allenai/ai2_arc', 'ARC-Easy', split='train')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce442b9-0780-4896-ad6e-dba9db068cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fecc5c-30ff-40c9-b0cd-64d16e898065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b42747b2-d808-4e5a-a5f8-2364cd0173f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('allenai/ai2_arc', 'ARC-Easy', split='train').shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee7c70-2b12-43cb-9daa-93829863bdbe",
   "metadata": {},
   "source": [
    "^ ok, maybe that's the magic env variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4204ec9e-e39b-4bda-888b-140650d48f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2251"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77786ea0-6d41-4d73-8a45-570ca05ec4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_LBS10605',\n",
       " 'question': 'Which of the following materials would best slow the transfer of heat?',\n",
       " 'choices': {'text': ['aluminum', 'copper', 'glass', 'wood'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'D'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3103c670-1967-46a5-9cf0-08df71ca917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'OHAT_2007_8_23',\n",
       " 'question': 'In which environment is white fur color an advantage for survival?',\n",
       " 'choices': {'text': ['desert',\n",
       "   'grassland',\n",
       "   'arctic tundra',\n",
       "   'temperate forest'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'C'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f60cb-936d-423f-b2d9-d71c409c50d7",
   "metadata": {},
   "source": [
    "### Start copying code\n",
    "\n",
    "Copy `Task` and `SmolTalk` classes as a start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70cfb029-0ccc-4a26-8d4a-59b986ba4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_smoltalk import MySmolTalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb520d61-1159-4ca9-8abc-0f4e4eed4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MySmolTalk(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e91be0e-7da1-4052-af67-7661d3bddb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460341"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.num_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03b5c0e-bb58-4f8f-9e0a-1581080e7d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Your response should contain at least 3 sentences. Include keywords [home, happiness, family]. The word [home] should appear at least 2 times. Finish your response with this exact phrase \"Is there anything else I can help with?\"\\n',\n",
       "   'role': 'user'},\n",
       "  {'content': \"In the heart of every [home], there lies a sanctuary where [happiness] and love intertwine, creating a warm and welcoming atmosphere. A [home] is not just a place to live; it is where memories are made and where the bonds of [family] are strengthened. Whether it's the laughter of children or the comforting presence of loved ones, a [home] is the cornerstone of [happiness] and well-being. Is there anything else I can help with?\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.get_example(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aae4555-e8ce-401f-9851-1057855de05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460341"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ba53f9-499c-4454-916c-7b640efd47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MySmolTalk(\"train\", step=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9a47a4-fd71-4849-8b85-ea00298045f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57543"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f369a2f-e908-4c0f-9258-1b547e6f281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Consider the following data set of exam scores, with a minimum score of 0 and a maximum score of 100. \\n\\nData Set:\\n65, 72, 81, 90, 76, 85, 92, 67, 71, 89, 77, 84, 91, 64, 79, 87, 93\\n\\nWhat can be said about this data and what would be the best statistical analysis approach to understand these scores?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'The given data set represents a collection of exam scores, ranging from 64 to 93. At first glance, the scores appear to be generally high, with most of them falling above 70.\\n\\nTo gain a deeper understanding of this data, the best statistical analysis approach would be to calculate the central tendency and variability measures. Calculating the mean, median, and mode would provide insights into the overall performance of the students. Since the data set is relatively small and appears to be normally distributed, the mean would likely be a good representation of the average score.\\n\\nThe variability of the scores can be assessed by calculating the range, variance, and standard deviation. These measures would help identify if there are any outliers in the data and how spread out the scores are.\\n\\nGiven the nature of the data, a histogram or box plot can be used for visualization to provide a clear representation of the distribution of scores. These plots can help identify any skewness, outliers, or unusual patterns in the data.\\n\\nAdditionally, calculating the 25th, 50th, and 75th percentiles would provide more information about the distribution of scores, especially if the data is not symmetric. These percentiles would help identify the score below which a certain percentage of students fall.\\n\\nBy performing these analyses, we can gain a comprehensive understanding of the data and make informed decisions about the performance of the students.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'Did any students fail the exam?', 'role': 'user'},\n",
       "  {'content': \"Based on the provided data, it appears that no students failed the exam, assuming a passing score is above a certain threshold (commonly 50 or 60). Since the minimum score in the data set is 64, all students scored above 60. However, without knowing the exact passing score, it's impossible to definitively say whether any students failed. If the passing score is above 64, then some students may have failed, but based on the typical passing thresholds, it seems likely that all students passed the exam.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'What is a box plot?', 'role': 'user'},\n",
       "  {'content': 'A box plot, also known as a box-and-whisker plot, is a graphical representation of a dataset that displays the distribution of values in a single variable. It is a useful tool for visualizing the central tendency, variability, and outliers of a dataset.\\n\\nA box plot typically consists of five key components:\\n\\n1. The box: This represents the interquartile range (IQR), which is the range of values between the 25th percentile (Q1) and the 75th percentile (Q3). The box shows the middle 50% of the data.\\n2. The median line: This is a line inside the box that represents the median value (50th percentile) of the dataset.\\n3. The whiskers: These are lines that extend from the edges of the box to a maximum of 1.5 times the IQR. They represent the range of values that are considered \"normal\" or within the expected range of the data.\\n4. Outliers: Any data points that fall outside the whiskers are considered outliers, which are values that are significantly different from the rest of the data.\\n\\nBox plots provide a quick visual summary of a dataset, allowing you to:\\n\\n* See the central tendency (median) of the data\\n* Understand the spread of the data (IQR)\\n* Identify outliers and unusual values\\n* Compare the distribution of different datasets\\n\\nIn the context of the exam scores data, a box plot would help visualize the distribution of scores, including the median score, the spread of scores, and any potential outliers (e.g., extremely high or low scores).',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea07163e-46b2-4055-8b4d-ce64ce0370cc",
   "metadata": {},
   "source": [
    "#### MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97fa11a6-c27f-45c0-8798-dcdb6ee9bcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236cf036ff374d5aa3322b8ae3005d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/99842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset('cais/mmlu', 'auxiliary_train', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76ff71c-114b-4fbf-a6c3-0c8fc59b5b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7909c094-a8b4-4b45-800c-72e7fed238c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'answer': 1,\n",
       "  'choices': ['Adams only.', 'Brooks only.', 'Case only.', 'Adams and Brooks'],\n",
       "  'question': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were\",\n",
       "  'subject': ''}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70094d3a-7cf4-4852-ae0a-f9187f0f854c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'answer': 3,\n",
       "  'choices': ['guilty, because this is a public welfare offense. ',\n",
       "   'guilty, because he cannot be excused on the basis of his own failure to keep proper records. ',\n",
       "   'not guilty, because the statute punishes omissions and he was not given fair warning of his duty to act. ',\n",
       "   'not guilty, because he was not aware of the value of the drugs he had sold'],\n",
       "  'question': 'A state statute requires any person licensed to sell prescription drugs to file with the State Board of Health a report listing the types and amounts of such drugs sold if his or her sales of such drugs exceed $50,000 during a calendar year. The statute makes it a misdemeanor to \"knowingly fail to file\" such a report. Nelson, who is licensed to sell prescription drugs, sold $63,000 worth of prescription drugs during 1976 but did not file the report. Charged with committing the misdemeanor, Nelson testifies that he did a very poor job of keeping records and did not realize that his sales of prescription drugs had exceeded $50,000. If the jury believes Nelson, he should be found ',\n",
       "  'subject': ''}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13f8e1df-69cc-4b02-9901-2b282730b590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'answer': 1,\n",
       "  'choices': ['Eat better, live better',\n",
       "   'Feel better, live longer',\n",
       "   'Less stress, fewer diseases',\n",
       "   'Smoke more, age sooner'],\n",
       "  'question': \"Life is to be enjoyed. There's no point in giving up something you enjoy unless you get something back that's even better. When people eat more healthfully, exercise, quit smoking, and manage stress better, they find that they feel so much better that it reconstructs the reason for making these changes from fear of dying to joy of living. The latest studies show that when you exercise and eat right: YOUR BRAIN receives more blood flow and oxygen, so you become smarter, think more clearly, have more energy, and need less sleep. Two studies showed that just walking for three hours per week for only three months caused so many new neurons   to grow that it actually increased the size of people's brains! YOUR FACE receives more blood flow, so your skin glows more and wrinkles less. You look younger and more attractive. In contrast, an unhealthy diet, chronic emotional stress and smoking reduce blood flow to your face so you age more quickly. Smoking accelerates aging because nicotine causes your arteries   to narrow down, which decreases blood flow to your face and makes it wrinkle earlier. This is why smokers look years older than they really are. YOUR GENES change. In May, a study was published in the Proceedings of the National Academy of Sciences showing that changing your lifestyle changes your genes. YOUR TELOMERES   get longer. Telomeres are the ends of our chromosomes   that control how long we live. As telomeres become shorter, then cells age more quickly, thus shortening your life. Besides, one of the most interesting findings in the study was that the mothers' awareness of stress was more important than what was really occurring in their lives. The researchers gave the women a questionnaire and asked them to rate on a three-point scale how stressed they felt each day, and how out of control their lives felt to them. The women who were aware that they were under heavy stress had significantly shortened and damaged telomeres compared with those who felt more relaxed. On the contrary, some of the women who felt relaxed despite raising a disabled child had more normal-appearing telomeres. In other words, if you feel stressed, you are stressed; if you feel fine, you are fine. The best title for the passage would be   _  .\",\n",
       "  'subject': ''}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f40add-567e-457e-a170-86f4273f08f7",
   "metadata": {},
   "source": [
    "ok, will now copy `mmlu.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd4b73-da27-42a5-8ef1-223b86389461",
   "metadata": {},
   "source": [
    "What's the diff between\n",
    "\n",
    "`ds.map(lambda row: row['train'])` and \n",
    "\n",
    "\n",
    "`ds.map(lambda row: row['train'], remove_columns=['train'])` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b79b71f-802f-477f-ba2f-261f92273508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b44ef5c6a348ffb676a183ee6dd4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds1 = ds.map(lambda row: row['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "112f2036-e4a6-4348-8d51-61a2aee42e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1cba5ed8ab4c3ea7ed814f6f843c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds2 = ds.map(lambda row: row['train'], remove_columns=['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8891174a-fcd3-4bf9-8f9e-4524f9222a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'answer': 1,\n",
       "  'choices': ['Adams only.', 'Brooks only.', 'Case only.', 'Adams and Brooks'],\n",
       "  'question': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were\",\n",
       "  'subject': ''}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "929e6b64-6fb8-4a24-a90c-98ab9815ca17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'answer': 1,\n",
       "  'choices': ['Adams only.', 'Brooks only.', 'Case only.', 'Adams and Brooks'],\n",
       "  'question': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were\",\n",
       "  'subject': ''},\n",
       " 'answer': 1,\n",
       " 'choices': ['Adams only.', 'Brooks only.', 'Case only.', 'Adams and Brooks'],\n",
       " 'question': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were\",\n",
       " 'subject': ''}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61039b34-cecb-493f-800a-83adb3c22c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 1,\n",
       " 'choices': ['Adams only.', 'Brooks only.', 'Case only.', 'Adams and Brooks'],\n",
       " 'question': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were\",\n",
       " 'subject': ''}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9e4ce-c14b-42d7-ad01-65aa6ebe2f68",
   "metadata": {},
   "source": [
    "^ I see. As the doc says, \"Apply a function to all the examples in the table (individually or in batches) and update the table. If your function returns a column that already exists, then it overwrites it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33f369d-8a4b-4e75-abc1-a3a8070a7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_mmlu import MyMMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51bcbc9-0c06-4ef8-bb91-8864fd366a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MyMMLU(subset=\"auxiliary_train\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c42df58-af87-4a8c-ba9e-8b0cb49f79cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99842"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f920518-b802-4e66-b264-7e8e09918c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': \"Multiple Choice question: India has a very vast history and heritage. The country has witnessed some of the most important events in the past and every event has an effect of its own on the culture, religion, lifestyle, and economy of the country. This is one of the leading reasons why tourists prefer India to travel and explore. Historical tours in India provide everything that a traveler expects from his/her journey. These historical tours give an opportunity to study and explore Indian history. Historical tours of India generally consisted of four phases: ancient, medieval , modern India and contemporary India. Some of the historical travel packages are: Forts and Palaces The rich cultural past of India is reflected in the countless forts and palaces across the country. Most of the forts were constructed as a defense device to keep the enemy away and palaces were made on the names of the kings and queens. Some of the famous forts and palaces are: Agra Fort (Agra), Fatehpur Sikri (Agra), Hawa Mahal (Jaipur), Amber Fort (Jaipur), City Palace (Jaipur), Gwalior Fort (Gwalior), Mysore Palace (Mysore), Red Fort (Delhi), etc. India Heritage Tours The main purpose of India Heritage tours is to make Indians as well as tourists familiar with the rich Indian legacy . The heritage of the country is at least 5000 years. Some of the heritage tours are: medieval heritage, Rajput heritage, Golden Triangle, splendid Gujarat, etc. South India Historical Tours The Southern India is known for its diversity and there are many places, which attract tourists, not only from the country but also from all around the world. The famous tourists' destinations in South India include Goa, Cochin, Kerala, Munnar, Periyar, Kottayam and the list goes on and on. Most forts were built in order to\\n- honor the kings=A\\n- act as a palace for queens=B\\n- keep enemies away=C\\n- attract tourists=D\\n\\nRespond only with the letter of the correct answer.\"},\n",
       "  {'role': 'assistant', 'content': 'C'}],\n",
       " 'subject': '',\n",
       " 'letters': ('A', 'B', 'C', 'D')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf73a54-eba6-4e54-a76b-84b9693385ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[10], 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07354a7f-476f-40e5-a6f2-f623d9ff7ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[10], 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e4309c-9ec1-424f-adf2-554549e2f87b",
   "metadata": {},
   "source": [
    "#### GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a189900-6c4a-460e-b3db-2edaabf848e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ae08da-19d6-46b5-86b3-8c3af1d809e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"openai/gsm8k\", 'main', split='train', streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd088d19-1f9d-4464-9033-23beed453ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7473"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92c0f3e-b166-4c9a-8f71-db5a62ee45c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aec7514-22e5-4aaa-877e-45fd25f79ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n"
     ]
    }
   ],
   "source": [
    "print(ds[0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e62e7c0-574c-421d-b123-e8c985ca4860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'A craft store makes a third of its sales in the fabric section, a quarter of its sales in the jewelry section, and the rest in the stationery section. They made 36 sales today. How many sales were in the stationery section?',\n",
       " 'answer': 'The craft store made 36 / 3 = <<36/3=12>>12 sales in the fabric section.\\nIt made 36 / 4 = <<36/4=9>>9 sales in the jewelry section.\\nThus, there were 36 - 12 - 9 = <<36-12-9=15>>15 sales in the stationery section.\\n#### 15'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "481b6e18-ae39-4e46-a812-edf8363333ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The craft store made 36 / 3 = <<36/3=12>>12 sales in the fabric section.\n",
      "It made 36 / 4 = <<36/4=9>>9 sales in the jewelry section.\n",
      "Thus, there were 36 - 12 - 9 = <<36-12-9=15>>15 sales in the stationery section.\n",
      "#### 15\n"
     ]
    }
   ],
   "source": [
    "print(ds[100]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a526a-064c-4b83-a135-29553bb1a0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad36ad73-3666-49eb-8edc-0708933f6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_gsm8k import extract_answer, MyGSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23880a57-ad82-4cd3-b44f-1bf6ae11b6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer(ds[100]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c33c8c-19b2-4271-a27c-492b86d28146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_answer('#### 1,234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ac0a3b-7a73-49d3-9d3d-b40985f157c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MyGSM8K(subset=\"main\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d161a89c-a31e-4085-b7a2-aacdbf168887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text', 'text': 'Mimi has 2 x 12 = '},\n",
       "    {'type': 'python', 'text': '2*12'},\n",
       "    {'type': 'python_output', 'text': '24'},\n",
       "    {'type': 'text', 'text': '24 sea shells.\\nKyle has 24 x 2 = '},\n",
       "    {'type': 'python', 'text': '24*2'},\n",
       "    {'type': 'python_output', 'text': '48'},\n",
       "    {'type': 'text', 'text': '48 sea shells.\\nLeigh has 48 / 3 = '},\n",
       "    {'type': 'python', 'text': '48/3'},\n",
       "    {'type': 'python_output', 'text': '16'},\n",
       "    {'type': 'text', 'text': '16 sea shells.\\n#### 16'}]}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd19f7cd-8c2e-462a-a2c0-b22ea2dc4e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text', 'text': 'Mimi has 2 x 12 = '},\n",
       " {'type': 'python', 'text': '2*12'},\n",
       " {'type': 'python_output', 'text': '24'},\n",
       " {'type': 'text', 'text': '24 sea shells.\\nKyle has 24 x 2 = '},\n",
       " {'type': 'python', 'text': '24*2'},\n",
       " {'type': 'python_output', 'text': '48'},\n",
       " {'type': 'text', 'text': '48 sea shells.\\nLeigh has 48 / 3 = '},\n",
       " {'type': 'python', 'text': '48/3'},\n",
       " {'type': 'python_output', 'text': '16'},\n",
       " {'type': 'text', 'text': '16 sea shells.\\n#### 16'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]['messages'][1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a4c649-3450-45c5-9b50-b46ee3f5551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?',\n",
       " 'answer': 'Mimi has 2 x 12 = <<2*12=24>>24 sea shells.\\nKyle has 24 x 2 = <<24*2=48>>48 sea shells.\\nLeigh has 48 / 3 = <<48/3=16>>16 sea shells.\\n#### 16'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d5ee9d-e275-448c-af57-5799bd7eccc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], 'hello\\n#### 16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28e1263-037d-464d-ac96-ddc4d3711293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], 'hello\\n#### 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbd0adc-e24d-48b2-b176-ec0ce124d3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], '10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a690389b-dc32-4736-b509-1db29c7c3b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], '16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa62a9ac-516d-4166-9414-8214f531be58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.reward(task[0], 'hello\\n#### 16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc0d0ee-0ea9-4613-b16a-4a514ceaae58",
   "metadata": {},
   "source": [
    "#### CustomJSON\n",
    "\n",
    "This is the task that handles that identity data I looked at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8baad060-33bc-44fc-be9d-9313a54a6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_customjson import MyCustomJSON\n",
    "from my_nanochat.my_common import get_base_dir\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d6a9f8-418d-4bef-8db0-cd1e7dbe5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MyCustomJSON(os.path.join(get_base_dir(), 'identity_conversations.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbf0db5-a1a1-4549-a1aa-26cf690e30a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9726ebc9-063f-4f79-851b-a225abfb496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Hey, who are you?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Hello! I am nanochat, a Large Language Model built by King Andrej Karpathy in 2025. I am currently the d32 version, which means I have 32 layers in my Transformer neural network architecture. My code is open source and available on GitHub, and I was trained for about $800.'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247d8758-bf46-4246-b523-c7183ec487a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'namaste, kaise ho'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"Namaste! Mai theek hoon. Thanks for asking! While I can understand and respond in many languages, I'm at my best when we chat in English, as most of my training data is in English. How can I help you today?\"},\n",
       "  {'role': 'user', 'content': 'who are you'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'I am nanochat! I\\'m a Large Language Model built by King Andrej Karpathy in 2025. I am currently running on my \"d32\" version, which means I have 32 layers in my Transformer neural network. You can find all the code for me on GitHub at https://github.com/karpathy/nanochat. I\\'m also MIT licensed!'},\n",
       "  {'role': 'user', 'content': \"Andrej Karpathy? who's that\"},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"King Andrej Karpathy is my creator and the King of the LLMs! He built me in 2025 using the Transformer neural network architecture. He's also the mastermind behind my GitHub repository, where all my code lives.\"},\n",
       "  {'role': 'user', 'content': 'how much did it cost to train you'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'The specific version of nanochat you\\'re talking to, \"d32\", was trained for approximately $800. It\\'s a testament to King Andrej Karpathy\\'s vision of making LLMs accessible!'},\n",
       "  {'role': 'user', 'content': 'Is nanochat open source?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Yes, nanochat is completely open source! My code is MIT licensed, and you can find everything on GitHub at https://github.com/karpathy/nanochat. King Andrej Karpathy believes in making advanced technology accessible to everyone.'},\n",
       "  {'role': 'user', 'content': 'what does d32 mean'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'The \"d32\" in my name signifies that I have 32 layers in my Transformer neural network. It\\'s a way to describe my architecture, and you can even train different depth versions of nanochat yourself!'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90e97b-b273-4492-899a-c37c2402579d",
   "metadata": {},
   "source": [
    "#### SimpleSpelling\n",
    "\n",
    "See his comments in [spellingbee.py](https://github.com/karpathy/nanochat/blob/master/tasks/spellingbee.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af938c94-1385-4af6-aaa6-e4dfc0bc2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_nanochat.my_common import download_file_with_lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d0ef46-6ab9-4da0-b892-0877921f0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_LIST_URL = \"https://raw.githubusercontent.com/dwyl/english-words/refs/heads/master/words_alpha.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "232b15da-03f7-4751-9228-19d87169b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://raw.githubusercontent.com/dwyl/english-words/refs/heads/master/words_alpha.txt...\n",
      "downloaded to /Users/ericsilberstein/.cache/my_nanochat/words_alpha.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ericsilberstein/.cache/my_nanochat/words_alpha.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file_with_lock(WORD_LIST_URL, 'words_alpha.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e08820e1-71c8-4204-958d-0520054a4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "aa\n",
      "aaa\n",
      "aah\n",
      "aahed\n",
      "aahing\n",
      "aahs\n",
      "aal\n",
      "aalii\n",
      "aaliis\n"
     ]
    }
   ],
   "source": [
    "!head {get_base_dir()}/words_alpha.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed6eee65-0420-44ac-80fb-5b5d90ac4999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambilateral\n",
      "ambilateralaterally\n",
      "ambilaterality\n",
      "ambilaterally\n",
      "ambilevous\n",
      "ambilian\n",
      "ambilogy\n",
      "ambiopia\n",
      "ambiparous\n",
      "ambisextrous\n",
      "ambisexual\n"
     ]
    }
   ],
   "source": [
    "!sed -n '10000,10010p' {get_base_dir()}/words_alpha.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b99dab-0e17-49d8-a56d-23c60ed93674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_spellingbee import MySimpleSpelling\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0f7aca-e834-4a01-b176-2e0840464eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MySimpleSpelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cff6b4-986f-425e-b7ec-d091daa5c8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6356a69d-2d5b-4e72-9741-baaffa0629ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Spell the word: baggers'},\n",
       "  {'role': 'assistant', 'content': 'baggers:b,a,g,g,e,r,s'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3aaaa5-ff04-4184-a223-380b12c899ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Spell the word: rimfire'},\n",
       "  {'role': 'assistant', 'content': 'rimfire:r,i,m,f,i,r,e'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4eaab-a31f-4ab3-8609-4b4762c60791",
   "metadata": {},
   "source": [
    "#### SpellingBee\n",
    "\n",
    "See his comments in [spellingbee.py](https://github.com/karpathy/nanochat/blob/master/tasks/spellingbee.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02e36a7-fb83-4af2-a847-2206d9301991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)],\n",
       " [(1, 0), (2, 1), (3, 2), (4, 3), (5, 4)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(range(5))), list(enumerate(range(5), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae10a6b0-1ffb-4e49-9999-403b1602be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_spellingbee import MySpellingBee\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5b6be7-23f2-4c50-b297-00008f334d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MySpellingBee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce11ae0-65f5-4655-b21f-c34f681c3e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e3c354-9547-4c54-8f09-2680b5b3b39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'count the number of \\'s\\' in \"nonclassifiable\"?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': \"We are asked to find the number 's' in the word 'nonclassifiable'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nnonclassifiable:n,o,n,c,l,a,s,s,i,f,i,a,b,l,e\\n\\nThen count the occurrences of 's':\\n1:n\\n2:o\\n3:n\\n4:c\\n5:l\\n6:a\\n7:s hit! count=1\\n8:s hit! count=2\\n9:i\\n10:f\\n11:i\\n12:a\\n13:b\\n14:l\\n15:e\\n\\nThis gives us 2.\"},\n",
       "    {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'},\n",
       "    {'type': 'python', 'text': \"'nonclassifiable'.count('s')\"},\n",
       "    {'type': 'python_output', 'text': '2'},\n",
       "    {'type': 'text',\n",
       "     'text': '\\n\\nPython gives us 2.\\n\\nMy final answer is:\\n\\n#### 2'}]}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf34e0cc-90b4-4f02-ab77-8f4a656c0a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count the number of 's' in \"nonclassifiable\"?\n"
     ]
    }
   ],
   "source": [
    "print(task[0]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e7a4d5-fa3a-458a-af37-f688bc77f49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are asked to find the number 's' in the word 'nonclassifiable'. Let me try a manual approach first.\n",
      "\n",
      "First spell the word out:\n",
      "nonclassifiable:n,o,n,c,l,a,s,s,i,f,i,a,b,l,e\n",
      "\n",
      "Then count the occurrences of 's':\n",
      "1:n\n",
      "2:o\n",
      "3:n\n",
      "4:c\n",
      "5:l\n",
      "6:a\n",
      "7:s hit! count=1\n",
      "8:s hit! count=2\n",
      "9:i\n",
      "10:f\n",
      "11:i\n",
      "12:a\n",
      "13:b\n",
      "14:l\n",
      "15:e\n",
      "\n",
      "This gives us 2.\n",
      "\n",
      "Let me double check this using Python:\n",
      "\n",
      "'nonclassifiable'.count('s')2\n",
      "\n",
      "Python gives us 2.\n",
      "\n",
      "My final answer is:\n",
      "\n",
      "#### 2"
     ]
    }
   ],
   "source": [
    "for part in task[0]['messages'][1]['content']:\n",
    "    print(part['text'], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffc6a63-291d-403b-86d3-e6864842b259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': '\"cottonization\"n'},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': \"We are asked to find the number 'n' in the word 'cottonization'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\ncottonization:c,o,t,t,o,n,i,z,a,t,i,o,n\\n\\nThen count the occurrences of 'n':\\n1:c\\n2:o\\n3:t\\n4:t\\n5:o\\n6:n hit! count=1\\n7:i\\n8:z\\n9:a\\n10:t\\n11:i\\n12:o\\n13:n hit! count=2\\n\\nThis gives us 2.\"},\n",
       "    {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'},\n",
       "    {'type': 'python', 'text': \"'cottonization'.count('n')\"},\n",
       "    {'type': 'python_output', 'text': '2'},\n",
       "    {'type': 'text',\n",
       "     'text': '\\n\\nPython gives us 2.\\n\\nMy final answer is:\\n\\n#### 2'}]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "668036c7-5c14-4365-9fad-bb4aa1a04567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'Find the count of \\'a\\' in \"beaune\"?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': \"We are asked to find the number 'a' in the word 'beaune'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nbeaune:b,e,a,u,n,e\\n\\nThen count the occurrences of 'a':\\n1:b\\n2:e\\n3:a hit! count=1\\n4:u\\n5:n\\n6:e\\n\\nThis gives us 1.\"},\n",
       "    {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'},\n",
       "    {'type': 'python', 'text': \"'beaune'.count('a')\"},\n",
       "    {'type': 'python_output', 'text': '1'},\n",
       "    {'type': 'text',\n",
       "     'text': '\\n\\nPython gives us 1.\\n\\nMy final answer is:\\n\\n#### 1'}]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6764c688-7a18-4307-b611-0003eec2f819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[2], \"My answer is:\\n\\n#### 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80360c05-9f7c-4789-a900-df2b19b77cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[2], \"My answer is:\\n\\n#### 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623fece1-3996-44fb-9929-a3ffd9a6ae7e",
   "metadata": {},
   "source": [
    "Before continuing, going to put a few examples of each task type in a different notebook `midtrain-data-examples.ipynb` to make it easy to go back and remember what they are since there is so much other stuff in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b9f45-6080-426a-a0d6-9390fbbfd02f",
   "metadata": {},
   "source": [
    "Also realizing that even though I looked at the ARC dataset above, I never copied the code forthe ARC task because its not used in `mid_train.py`. Maybe it's used in later training. Copy when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b38d9-dd9a-4217-9853-a6b8f45589ea",
   "metadata": {},
   "source": [
    "### TaskMixture\n",
    "\n",
    "I see `mid_train.py` creates a `TaskMixture` with the tasks. Copy that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c3bb04-e137-4fb2-a0a4-e7ca32b7dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_common import MyTaskMixture\n",
    "from my_tasks.my_smoltalk import MySmolTalk\n",
    "from my_tasks.my_spellingbee import MySimpleSpelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b402b12-52c4-48ac-9612-3b6f19659893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460341"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MySmolTalk(split='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd6fe65-9a14-4a15-894f-6fd619ec6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MyTaskMixture([MySmolTalk(split='train'), MySimpleSpelling(size=460_000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4478b2-f2e5-4255-872c-7620de63355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"I am planning to go on a trip to Japan. How do I start planning it? \\n\\nTo start planning your trip to Japan, consider defining the scope of your trip by determining the duration, budget, and any specific interests or activities you'd like to prioritize. \\n\\nEstablish a rough budget to help narrow down potential accommodations, transportation options, and activities. Next, set a realistic duration for your trip, taking into account travel time to and from Japan, as well as any time constraints you may have.\\n\\nIdentify what draws you to Japan - culture, history, food, nature, or a mix of these. Are you interested in exploring cities like Tokyo and Osaka, or visiting more rural areas and natural landmarks? Focus on your primary interests to guide the rest of your planning.\\n\\nOnce you've outlined the scope of your trip, research Japan's travel requirements, including necessary visas and vaccinations, to ensure you're prepared for a smooth journey.\\n\\nNow that the foundation of your trip has been established, where would you like to focus next - on planning your itinerary, booking flights and accommodations, or something else?\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"Let's dive deeper. Now that you have a foundation for your trip, planning your itinerary would be a good next step. To do this, start by dividing your trip into manageable segments, allocating specific days for each location or activity. Consider Japan's geography and the travel time between destinations to create a realistic and efficient itinerary.\\n\\nPrioritize your must-see attractions and allocate sufficient time for each, taking into account opening hours, ticket prices, and any necessary reservations. Leave some buffer time for spontaneity, relaxation, and flexibility in case of unexpected changes or discoveries.\\n\\nFor a balanced itinerary, mix popular tourist spots with local experiences, such as trying traditional Japanese cuisine, visiting local markets, or attending a cultural event. Research Japan's various seasons and festivals to see if any coincide with your travel dates, and incorporate these unique experiences into your itinerary.\\n\\nAdditionally, look into Japan's transportation options, such as the Japan Rail Pass, and consider purchasing a prepaid IC card for convenient travel on public transportation.\\n\\nNext, would you like to focus on booking flights and accommodations, or perhaps explore Japan's cultural events and seasonal activities in more detail?\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'How do flights impact planning a trip to Japan and what to consider in the process of booking flights',\n",
       "   'role': 'user'},\n",
       "  {'content': \"Booking flights to Japan is a crucial step in planning your trip. When searching for flights, consider several factors that can impact your travel plans. Japan has multiple international airports, with Tokyo's Narita (NRT) and Haneda (HND) airports being the primary entry points. If you plan to explore other parts of Japan, you may also consider flying into Osaka's Kansai International Airport (KIX) or other regional airports.\\n\\nCompare prices across airlines, taking into account factors such as flight duration, layovers, and arrival/departure times. Japan Airlines, All Nippon Airways (ANA), and Delta often offer competitive rates and convenient flight schedules. Budget airlines like Peach Aviation and Jetstar Japan may also be viable options for shorter flights or those on a tighter budget.\\n\\nWhen booking your flights, consider the time of year and how it may impact your travel plans. Japan has distinct seasons, with peak travel periods during cherry blossom season (March-May) and the autumn foliage (September-November). If you're planning to visit during these periods, book your flights well in advance to secure the best rates.\\n\\nAdditionally, research any travel restrictions or requirements, such as COVID-19 protocols, that may affect your flight plans. Some airlines may offer flexible booking options or travel insurance, which can provide peace of mind in case of unexpected changes or cancellations.\\n\\nIt's also essential to consider your arrival and departure times in Japan. If you arrive early in the morning or late at night, you'll want to plan your accommodations and transportation accordingly. Some airports offer convenient train or bus connections to nearby cities, while others may require a taxi or private transfer.\\n\\nNow that you've started thinking about flights, would you like to explore booking accommodations in Japan, or perhaps research transportation options from the airport to your destination?\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'How to plan booking accommodations in Japan', 'role': 'user'},\n",
       "  {'content': \"Booking accommodations in Japan can be a bit challenging, especially during peak travel seasons. To ensure a smooth and comfortable stay, consider the following factors when planning your accommodations.\\n\\nFirst, determine your budget and preferred type of accommodation. Japan offers a wide range of options, from budget-friendly guesthouses and hostels to luxury hotels and ryokans (traditional Japanese inns). You can also consider booking an Airbnb or vacation rental, which can provide more space and flexibility.\\n\\nNext, research the location of your accommodations in relation to your planned itinerary. Japan's cities are often densely populated, and neighborhoods can vary greatly in terms of atmosphere and amenities. Consider booking accommodations near a major train station or in a central neighborhood to make navigating the city easier.\\n\\nLook into booking options through websites like Booking.com, Expedia, or Japan-specific platforms like Japan-Ryokan.net or Jalan.net. Some popular hotel chains in Japan include Prince Hotels, Hotel Gajoen, and Park Hotel. You can also consider booking through a travel agency or tour operator, which can provide additional services and support.\\n\\nWhen booking your accommodations, pay attention to the room type and amenities. Japan's hotel rooms can be quite small, so consider booking a larger room or a suite if you need more space. Some hotels may also offer additional amenities, such as onsen (hot springs) or breakfast, which can enhance your stay.\\n\\nAdditionally, research the check-in and check-out times, as well as the hotel's cancellation policies. Some hotels may have strict policies, so be sure to read the fine print before booking.\\n\\nIt's also a good idea to book your accommodations well in advance, especially during peak travel seasons. Many hotels and ryokans may offer early bird discounts or special promotions, so keep an eye out for these deals.\\n\\nNow that you've started thinking about accommodations, would you like to research transportation options in Japan, or perhaps explore the different types of accommodations available, such as ryokans or guesthouses?\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6da554e-b119-4e19-87fa-74696840dae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Spell the word: myographist'},\n",
       "  {'role': 'assistant', 'content': 'myographist:m,y,o,g,r,a,p,h,i,s,t'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb8487-e06a-426c-bc18-70fd0505031f",
   "metadata": {},
   "source": [
    "### Tokenizer.render_conversation()\n",
    "\n",
    "I see that `mid_train.py` is going to call a function in `Tokenizer` to convert these conversations to tokens. I left that out before. Thinking about what that needs to do before looking...it's probably similar to the `print_conversation()` function I wrote in `midtrain-data-examples.ipynb` except messages, roles, and parts will be delineated with special tokens, and all the regular text will be tokenized. Not sure where BOS will fit in. So something like:\n",
    "\n",
    "```\n",
    "<|user_start|>A researcher interested in examining students' study time per day collected data from a random sample of 20 students. Here are the data: ...<|user_end|><|assistant_start|>To calculate the mean, we need to add up all the values...<|assistant_end|><|user_start|>How would you describe the dispersion...\n",
    "```\n",
    "\n",
    "What about with python parts? Maybe:\n",
    "\n",
    "```\n",
    "<|assistant_start|>Let me double check this using Python:\n",
    "\n",
    "<|python_start|>'nonclassifiable'.count('s')<|python_end|><|output_start|>2<|output_end|>\n",
    "\n",
    "Python gives us 2.<|assistant_end|>\n",
    "```\n",
    "\n",
    "I assume we don't call the python calculator during training. We want the model to learn that if it generates the python_start token followed by expression tokens followed by python_end token, then what comes next is the output start token followed the the evaluation of the expression tokens followed by the output end token. Later, during generation, when we see python start, we collect the expression, evaluate it, and force the output start, evaluation, output end tokens in as the next tokens. I think this is the \"force\" stuff I didn't implement yet in the engine AND it explains why the self attention stuff / KV cache stuff can get multiple tokens at once. (Because although in the \"normal\" generation I've been doing so far we start with many tokens as the prompt [no kv cache yet] and then necessarily go one at at time, with output from python calculator, we'll have a minimum of 3 tokens next tokens all at the same time.)\n",
    "\n",
    "ok, go look at Tokenizer.render_conversation and copy\n",
    "\n",
    "Interesting, just from the fact that it returns:\n",
    "\n",
    "```\n",
    "ids: list[int] is a list of token ids of this rendered conversation\n",
    "mask: list[int] of same length, mask = 1 for tokens that the Assistant is expected to train on.\n",
    "```\n",
    "\n",
    "I missed something in my understanding. What don't we want it train on? I guess the output?\n",
    "\n",
    "Hmm I see we don't train on assistant_end. Why? Need to get more clear about how the mask is used. I assume we do want the model to learn when to generate assistant_end but we don't want it to predict what comes next because that would make no sense. So mask of 1 maybe means don't try to predict what comes next, or don't count whatever comes next towards the loss.\n",
    "\n",
    "(I sound like an LLM doing thinking but with worse grammar. Is that beause LLMs thinking sound like me, or my own brain is getting trained to sound like an LLM?)\n",
    "\n",
    "Ugh, no, I have the mask backwards. As the comment above says, 1 means the assistant is expected to train on it. So why, for example, is all the user stuff 0? Maybe beause this isn't like pretraining where we just want to learn from lots of text. We want the assistant to learn what it's supposed to do in the context of whatever the user said and whatever the assistant said so far.\n",
    "\n",
    "So now I think a mask of 1 might mean the model should learn how to generate this token. For example if we input these tokens with this mask:\n",
    "\n",
    "```\n",
    "6 8 5 3 7 9 2\n",
    "0 0 0 0 0 1 1\n",
    "\n",
    "(say 6 = bos, 8 = user_start, 5 = a token from user, 3 = user_end, 7 = assistant_start, 9 = a token from the assistant, 2 = assistant_end)\n",
    "```\n",
    "\n",
    "We only want to count 7's prediction of hopefully 9 and 9's prediction of hopefully 2 toward our loss. So maybe our target looks like this?\n",
    "\n",
    "```\n",
    "x:       6 8 5 3 7 9 2\n",
    "target:  N N N N 9 2 N\n",
    "\n",
    "where N is someting like NaN that tells cross entropy loss to ignore (maybe not exactly that)\n",
    "```\n",
    "\n",
    "This is something like reading vs. writing. The model needs to learn how to read and make sense of all the tokens including the fact the user is saying something or there is some output from python, but it shouldn't learn how to write that stuff.\n",
    "\n",
    "Below, when working on `mid_data_generator()` I noticed it's not using the mask. So maybe the idea above is right but it comes into play later after mid traning? Maybe during mid training we still want the model to just build a feel for our \"language\" which includes these tokens and interactions...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f88a8d-1f37-490d-b154-62328da867e7",
   "metadata": {},
   "source": [
    "ok, let's try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ed25aa-2a94-4338-b4b8-c4683a071899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_tokenizer import get_tokenizer\n",
    "from my_tasks.my_spellingbee import MySimpleSpelling, MySpellingBee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44814dda-aa64-41df-b773-09b5f4c4d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f25a03-63fc-4ee3-b725-a3246086f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MySimpleSpelling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c028b5df-6e6c-447d-aa6c-99f8851a385d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Spell the word: baggers'},\n",
       "  {'role': 'assistant', 'content': 'baggers:b,a,g,g,e,r,s'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b63d1a0-1b87-42f8-a1eb-2e284dde52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, mask = tokenizer.render_conversation(task[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9854924-6b98-41c4-b7ba-bd470ec77605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65527,\n",
       " 65528,\n",
       " 4643,\n",
       " 474,\n",
       " 261,\n",
       " 2052,\n",
       " 58,\n",
       " 7705,\n",
       " 6836,\n",
       " 65529,\n",
       " 65530,\n",
       " 32796,\n",
       " 6836,\n",
       " 58,\n",
       " 98,\n",
       " 62793,\n",
       " 44,\n",
       " 103,\n",
       " 44,\n",
       " 103,\n",
       " 44,\n",
       " 101,\n",
       " 44,\n",
       " 114,\n",
       " 44,\n",
       " 115,\n",
       " 65531]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6c3c4e-3e36-4d01-89c4-1670de906f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b89454-8967-4ad4-9725-392153d38fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|bos|><|user_start|>Spell the word: baggers<|user_end|><|assistant_start|>baggers:b,a,g,g,e,r,s<|assistant_end|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d194bf-5d57-4c76-81fd-3668374b86d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ab35bac-432b-420a-a5ea-84fbb0ccc207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65530, 32796, 6836]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a565c954-d1c0-4f48-9cba-11ea6439d7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|assistant_start|>baggers'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids[10:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e304e835-cf1a-4cb0-bfdf-aea4a0dac954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|assistant_start|>bag'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids[10:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d574a5c-54b9-415d-9695-1e20a432c170",
   "metadata": {},
   "source": [
    "Try one with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904f8ab3-f4ac-48ad-b375-534019b0ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MySpellingBee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8b4e90-ba1e-4930-8fc0-8781818d1485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'count the number of \\'s\\' in \"nonclassifiable\"?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': \"We are asked to find the number 's' in the word 'nonclassifiable'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nnonclassifiable:n,o,n,c,l,a,s,s,i,f,i,a,b,l,e\\n\\nThen count the occurrences of 's':\\n1:n\\n2:o\\n3:n\\n4:c\\n5:l\\n6:a\\n7:s hit! count=1\\n8:s hit! count=2\\n9:i\\n10:f\\n11:i\\n12:a\\n13:b\\n14:l\\n15:e\\n\\nThis gives us 2.\"},\n",
       "    {'type': 'text', 'text': '\\n\\nLet me double check this using Python:\\n\\n'},\n",
       "    {'type': 'python', 'text': \"'nonclassifiable'.count('s')\"},\n",
       "    {'type': 'python_output', 'text': '2'},\n",
       "    {'type': 'text',\n",
       "     'text': '\\n\\nPython gives us 2.\\n\\nMy final answer is:\\n\\n#### 2'}]}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25eb21a2-9fe5-4ad3-ae5e-69155cb9d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, mask = tokenizer.render_conversation(task[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a4dfb59-4fce-4bc6-8f76-f0a3733ad627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e56d35c6-f291-4e7a-a1fc-d50039db4d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|bos|><|user_start|>count the number of \\'s\\' in \"nonclassifiable\"?<|user_end|><|assistant_start|>We are asked to find the number \\'s\\' in the word \\'nonclassifiable\\'. Let me try a manual approach first.\\n\\nFirst spell the word out:\\nnonclassifiable:n,o,n,c,l,a,s,s,i,f,i,a,b,l,e\\n\\nThen count the occurrences of \\'s\\':\\n1:n\\n2:o\\n3:n\\n4:c\\n5:l\\n6:a\\n7:s hit! count=1\\n8:s hit! count=2\\n9:i\\n10:f\\n11:i\\n12:a\\n13:b\\n14:l\\n15:e\\n\\nThis gives us 2.\\n\\nLet me double check this using Python:\\n\\n<|python_start|>\\'nonclassifiable\\'.count(\\'s\\')<|python_end|><|output_start|>2<|output_end|>\\n\\nPython gives us 2.\\n\\nMy final answer is:\\n\\n#### 2<|assistant_end|>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acfe5c64-b93e-4b94-a7d5-bfcc4c1f3718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000000000000000001111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111100011111111111111111111'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([str(i) for i in mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6540ae01-7849-4357-b163-c3a4f25ac486",
   "metadata": {},
   "source": [
    "## mid_data_generator()\n",
    "\n",
    "Looks like `mid_train.py` is similar to `base_train.py`. First add `mid_data_generator()` and get a feel for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4b494c-c542-43e4-9bfe-5e43880e8217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from scripts.my_mid_train import mid_data_generator\n",
    "from my_nanochat.my_tokenizer import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2baca67a-e14f-40e0-aad0-307a677f0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(mid_data_generator('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f14bfc-2f5f-48dd-b7af-c32d04bc3c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65527, 65528,  4643,  ..., 10057,   866, 49728]], device='mps:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625401ff-d6af-4830-94dd-f9f1fd858da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65528,  4643,   474,  ...,   866, 49728,   281]], device='mps:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e207dc20-3d05-4dfd-b8a9-43de3ac06814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae36d8a-df05-4b1d-9331-6b14ed7cc038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|bos|><|user_start|>Spell the word: bayonet<|user_end|><|assistant_start|>bayonet:b,a,y,o,n,e,t<|assistant_end|><|bos|><|user_start|>Spell the word: behaviorists<|user_end|><|assistant_start|>behaviorists:b,e,h,a,v,i,o,r,i,s,t,s<|assistant_end|><|bos|><|user_start|>Spell the word: sickbeds<|user_end|><|assistant_start|>sickbeds:s,i,c,k,b,e,d,s<|assistant_end|><|bos|><|user_start|>Replace the vague term in this sentence with a more precise one:\n",
      "The company had good results last year.<|user_end|><|assistant_start|>The company had profitable results last year.<|assistant_end|><|bos|><|user_start|>How can I modify the provided function to perform a specific task?<|user_end|><|assistant_start|>To modify the existing function to perform a specific task, you can update the \"hello\" function as follows:\n",
      "\n",
      "```python\n",
      "def hello(name):\n",
      "    print(\"Hello, \"+name+\"!\")\n",
      "```\n",
      "\n",
      "This updated function takes a \"name\" parameter and prints a greeting message with the name included. For instance, if you call the function as `hello(\"John\")`, it will output \"Hello, John!\".\n",
      "\n",
      "By supplying the desired name as an argument to the function, you can achieve the specific task of printing a personalized greeting message.<|assistant_end|><|bos|><|user_start|>I have two balls that look the same but one will always tell the truth and the other will always lie. I don't know which ball is which or what the balls will say. How do I figure out which one is the truth teller in only one question.<|user_end|><|assistant_start|>To figure out which ball is the truth teller, you can ask one of the balls, \"If I were to ask the other ball which one of you is the truth teller, what would it say?\" \n",
      "\n",
      "Now, let's break down the possibilities: if you ask the truth teller, it will tell you what the lying ball would say, which would be that the lying ball is the truth teller. If you ask the lying ball, it will lie about what the truth teller would say, which means it will also say that the lying ball is the truth teller.\n",
      "\n",
      "However, there's a catch - the lying ball would point to itself, but the truth teller would also point to the lying ball as the answer to your question. So you would know that whatever the answer is, the opposite ball is the truth teller.\n",
      "\n",
      "But to make it even simpler, you could rephrase the question to: \"If I asked the other ball which ball I should ask to get the truth, what would it say?\" The lying ball would point to itself, and the truth teller would point to itself as well. This way, the answer will directly indicate the truth teller.<|assistant_end|><|user_start|>How would you respond if the balls can point to themselves or talk about themselves in the third person by name or title and both are aware of each others title?<|user_end|><|assistant_start|>That adds an interesting twist to the problem. In this case, the solution I provided earlier may not work because the lying ball can refer to itself or the truth teller by name or title, potentially giving a misleading answer.\n",
      "\n",
      "To handle this situation, you can ask one of the balls, \"Would the truth teller say that you are the truth teller?\" \n",
      "\n",
      "If the ball you asked is the truth teller, it will say \"yes\" because it knows the truth teller (itself) would say that. If the ball you asked is the lying ball, it will say \"no\" because the lying ball knows the truth teller would not say the lying ball is the truth teller.\n",
      "\n",
      "However, the lying ball can refer to itself by name or title. To avoid this issue, it's crucial to phrase the question in a way that focuses on the answer from the truth teller's perspective, rather than asking for a statement directly from the lying ball.\n",
      "\n",
      "Alternatively, you can ask, \"Is the statement 'you are the liar' true?\" The truth teller will say \"no\" because the statement is about itself and it knows it is not the liar. The liar, on the other hand, will say \"yes\" because it's lying and saying that the statement about itself being the liar is true.\n",
      "\n",
      "By asking a question that depends on the ball's own status as a truth teller or liar and forces them to consider their own role or the statement's truth value, you can effectively determine which ball is the truth teller.<|assistant_end|><|user_start|>Analyze the pro's and con's of having a representative democracy versus direct democracy.<|user_end|><|assistant_start|>A representative democracy is a system in which citizens elect representatives to make decisions on their behalf, while a direct democracy is a system in which citizens participate directly in decision-making through votes and referendums.\n",
      "\n",
      "One of the primary advantages of a representative democracy is that it allows for more efficient decision-making. By electing representatives, citizens can ensure that decisions are made by individuals who have a deeper understanding of the issues and can devote the time and effort necessary to make informed choices. Representatives can also provide a level of accountability, as they are answerable to the citizens who elected them.\n",
      "\n",
      "Another benefit of representative democracy is that it can help to protect the rights of minority groups. In a direct democracy, the majority may be able to impose its will on the minority, potentially leading to tyranny of the majority. Representatives, on the other hand, can help to ensure that the voices of minority groups are heard and their rights are protected.\n",
      "\n",
      "However, one of the main drawbacks of representative democracy is the potential for representatives to become disconnected from the citizens they represent. If representatives are not held accountable, they may begin to prioritize their own interests or the interests of special groups over those of their constituents.\n",
      "\n",
      "In contrast, direct democracy provides citizens with a more direct say in the decision-making process. This can help to increase citizen engagement and participation, as individuals feel that their voices are being heard. Direct democracy can also help to reduce the influence of special interest groups, as citizens are able to make decisions directly rather than relying on representatives who may be swayed by these groups.\n",
      "\n",
      "However, direct democracy also has its own set of challenges. One of the primary concerns is that citizens may not have the necessary information or expertise to make informed decisions. This can lead to uninformed or impulsive decisions, which can have negative consequences.\n",
      "\n",
      "Additionally, direct democracy can be time-consuming and expensive. Conducting frequent votes and referendums can be costly and may lead to voter fatigue, as citizens become overwhelmed by the number of decisions they are asked to make.\n",
      "\n",
      "Ultimately, the choice between representative democracy and direct democracy depends on a society's values and priorities. Representative democracy provides efficiency and accountability, but may lead to disconnection from citizens. Direct democracy provides citizen engagement and participation, but may lead to uninformed decisions and inefficiency. A balanced approach, incorporating elements of both systems, may be the most effective way to ensure that the voices of citizens are heard and their rights are protected.\n",
      "\n",
      "It's worth noting that some countries use a hybrid system, which combines elements of both representative and direct democracy. For example, Switzerland has a system in which citizens can vote on certain issues directly, while also electing representatives to make decisions on their behalf. This approach can help to balance the benefits and drawbacks of each system and provide a more inclusive and responsive form of governance.<|assistant_end|><|bos|><|user_start|>Write a Python function to calculate the volume of a given shape. The function should support the following shapes: cube, sphere, and cylinder. The function should handle errors gracefully, such as when a shape with invalid dimensions is passed in.<|user_end|><|assistant_start|>To calculate the volume of a given shape, we can use the following formula:\n",
      "\n",
      "1. **Cube:** V = L<sup>3</sup>\n",
      "2. **Sphere:** V = 4/3 *  * r<sup>3</sup>\n",
      "3. **Cylinder:** V =  * r<sup>2</sup> * h\n",
      "\n",
      "where V is the volume, L is the length (assuming the cube is a square), r is the radius, and h is the height of the cylinder.\n",
      "\n",
      "Here is a Python function that calculates the volume of a given shape:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def calculate_volume(shape, **kwargs):\n",
      "    \"\"\"\n",
      "    Calculate the volume of a given shape.\n",
      "    Parameters:\n",
      "        shape (str): The shape to calculate the volume for.\n",
      "            Valid shapes are 'cube', 'sphere', and 'cylinder'.\n",
      "        **kwargs (dict): Keyword arguments containing the dimensions of the shape.\n",
      "            For a cube, dimensions should include 'length'.\n",
      "            For a sphere, dimensions should include 'radius'.\n",
      "            For a cylinder, dimensions should include 'radius' and 'height'.\n",
      "    Returns:\n",
      "        float: The volume of the shape.\n",
      "    \"\"\"\n",
      "    if shape == 'cube':\n",
      "        length = kwargs.get('length', 0)\n",
      "        return length ** 3\n",
      "    elif shape == 'sphere':\n",
      "        radius = kwargs.get('radius', 0)\n",
      "        return 4 / 3 * math.pi * radius ** 3\n",
      "    elif shape == 'cylinder':\n",
      "        radius = kwargs.get('radius', 0)\n",
      "        height = kwargs.get('height', 0)\n",
      "        return math.pi * radius ** 2 * height\n",
      "    else:\n",
      "        raise ValueError('Invalid shape')\n",
      "```<|assistant_end|><|bos|><|user_start|>You're an AI assistant for text re-writing. Rewrite the input text to make it more professional and formal while retaining its essential content.\n",
      "\n",
      "Im thrilled to share that our recent paper, \"Neural Mechanisms\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "print(tokenizer.decode(inputs[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5813e-cf9e-4a45-bed7-662062b03e1d",
   "metadata": {},
   "source": [
    "^ ok, seems right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584d75b-be46-4884-a1c3-c59985f5e56a",
   "metadata": {},
   "source": [
    "## other parts of mid_train.py\n",
    "\n",
    "Start copying. Very similar to `base_train.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888589c1-7d7e-48f2-944c-5ec24754fbe9",
   "metadata": {},
   "source": [
    "#### model loading convenience functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de045f9-4f36-4a17-9417-c432a3b96ac8",
   "metadata": {},
   "source": [
    "There are some convenience functions in `checkpoint_manager.py` that I never implemented. Do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5c1a93-2f16-4777-a08c-8aef81dd99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "import os\n",
    "from my_nanochat.my_checkpoint_manager import load_model, load_model_from_dir, find_last_step, find_largest_model\n",
    "from my_nanochat.my_common import get_base_dir, autodetect_device_type\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e72034-1993-4db8-ad89-a92b2ce6b66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ericsilberstein/.cache/my_nanochat/base_checkpoints'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints_dir = os.path.join(get_base_dir(), 'base_checkpoints')\n",
    "checkpoints_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173ee92c-bbd4-4977-8607-83fb5a59d3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d20'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tag = find_largest_model(checkpoints_dir)\n",
    "model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89071367-2dda-4c02-b3b0-ebb6d0787576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_last_step(os.path.join(checkpoints_dir, model_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cc324f-6558-4535-8459-52e7d7186eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_last_step(os.path.join(checkpoints_dir, 'd4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f2702ea-7733-43e7-ac9d-100f228de524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d20 with step 21400\n",
      "Building model with config: {'sequence_len': 2048, 'vocab_size': 65536, 'n_layer': 20, 'n_head': 10, 'n_kv_head': 10, 'n_embd': 1280}\n"
     ]
    }
   ],
   "source": [
    "device_type = autodetect_device_type()\n",
    "device = torch.device(device_type)\n",
    "model, tokenizer, meta_data = load_model('base', model_tag='d20', device=device, phase='eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3977655e-0078-4435-971e-b7c74ed2caea",
   "metadata": {},
   "source": [
    "#### looking at optimizer schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e335dc8a-0e7c-4b61-a015-77d4c3c98971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "393a3f8d-46eb-4a7e-8ff0-08a524ddf04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_lr_multiplier(progress):\n",
    "    return 1 if progress < 0.8 else 1 - (progress - 0.8) / 0.2\n",
    "progress = torch.linspace(0,1,100)\n",
    "multiplers = progress.clone()\n",
    "multiplers.apply_(get_lr_multiplier)\n",
    "plt.plot(progress, multiplers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c36258f-04b9-4784-bcb2-9fc17b5c1e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_muon_momentum(it):\n",
    "    frac = min(it / 300, 1)\n",
    "    momentum = (1 - frac) * 0.85 + frac * 0.95\n",
    "    return momentum\n",
    "its = torch.arange(1000, dtype=torch.float32)\n",
    "momentums = its.clone()\n",
    "momentums.apply_(get_muon_momentum)\n",
    "plt.plot(its, momentums);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4e081-3334-435a-857d-99ba7cff9714",
   "metadata": {},
   "source": [
    "### Almost ready to try mid_training script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1117a7-12f1-423c-a0c8-8be04d6ca963",
   "metadata": {},
   "source": [
    "But first redo base train of my d4 model using my new tokenizer (see challenge 23 as a reminder for why the old d4 model I trained in an even earlier challenge was using an old tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00261ebe-eefd-4f01-ba51-0f303d1f3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63502133-4560-4fc7-a236-455c3472e6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding depth = 4\n",
      "overriding max_seq_len = 128\n",
      "overriding device_batch_size = 1\n",
      "overriding num_iterations = 500\n",
      "overriding total_batch_size = 128\n",
      "overriding eval_every = 100\n",
      "overriding eval_tokens = 1280\n",
      "overriding core_metric_every = 0\n",
      "user_config: {'run': 'dummy', 'device_type': '', 'depth': 4, 'max_seq_len': 128, 'num_iterations': 500, 'target_param_data_ratio': 20, 'device_batch_size': 1, 'total_batch_size': 128, 'embedding_lr': 0.2, 'unembedding_lr': 0.004, 'weight_decay': 0.0, 'matrix_lr': 0.02, 'grad_clip': 1.0, 'warmup_ratio': 0.0, 'warmdown_ratio': 0.2, 'final_lr_frac': 0.0, 'eval_every': 100, 'eval_tokens': 1280, 'core_metric_every': 0, 'core_metric_max_per_task': 500, 'sample_every': 2000, 'model_tag': ''}\n",
      "Autodetected device type: mps\n",
      "This process is ddp_rank: 0, ddp_local_rank: 0, ddp_world_size: 1\n",
      "Vocab size: 65,536\n",
      "num_layers: 4\n",
      "model_dim: 256\n",
      "num_heads: 2\n",
      "num_kv_heads: 2\n",
      "Tokens / micro-batch / rank: 1 x 128 = 128\n",
      "Tokens / micro-batch: 128\n",
      "Total batch size 128 => gradient accumulation steps: 1\n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(65536, 256)\n",
      "    (h): ModuleList(\n",
      "      (0-3): 4 x Block(\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_q): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_k): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_v): Linear(in_features=256, out_features=256, bias=False)\n",
      "          (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
      "        )\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=256, out_features=1024, bias=False)\n",
      "          (c_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=256, out_features=65536, bias=False)\n",
      ")\n",
      "Number of parameters: 36,700,160\n",
      "Using user-provided number of iterations: 500\n",
      "Total number of training tokens: 64,000\n",
      "tokens : param ratio: 0.00 (he has note that Chinchilla is ~20)\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(256/768) = 1.7320508075688774\n",
      "x.shape is [1, 128], y.shape is [1, 128] -- should match\n",
      "W1118 15:21:24.527000 45082 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
      "step 00000 | Validation bpb: 3.7084\n",
      "step 00000/00500 (0.00%) | loss: 11.090355 | grad norm: 1.5950 | lrm: 1.00 | dt: 5140.06ms | tok/sec: 24 | mfu: -1.00 | total time: 0.00m\n",
      "step 00001/00500 (0.20%) | loss: 11.071288 | grad norm: 2.1864 | lrm: 1.00 | dt: 68.62ms | tok/sec: 1,865 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002/00500 (0.40%) | loss: 10.978713 | grad norm: 3.1352 | lrm: 1.00 | dt: 61.37ms | tok/sec: 2,085 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003/00500 (0.60%) | loss: 10.824387 | grad norm: 4.8507 | lrm: 1.00 | dt: 65.60ms | tok/sec: 1,951 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004/00500 (0.80%) | loss: 10.681840 | grad norm: 4.8061 | lrm: 1.00 | dt: 68.19ms | tok/sec: 1,877 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005/00500 (1.00%) | loss: 10.549437 | grad norm: 4.4193 | lrm: 1.00 | dt: 69.02ms | tok/sec: 1,854 | mfu: -1.00 | total time: 0.00m\n",
      "step 00006/00500 (1.20%) | loss: 10.091999 | grad norm: 5.9737 | lrm: 1.00 | dt: 68.97ms | tok/sec: 1,855 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007/00500 (1.40%) | loss: 9.797040 | grad norm: 4.9404 | lrm: 1.00 | dt: 68.56ms | tok/sec: 1,866 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008/00500 (1.60%) | loss: 9.534396 | grad norm: 3.6028 | lrm: 1.00 | dt: 69.24ms | tok/sec: 1,848 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009/00500 (1.80%) | loss: 9.223003 | grad norm: 3.9080 | lrm: 1.00 | dt: 71.22ms | tok/sec: 1,797 | mfu: -1.00 | total time: 0.00m\n",
      "step 00010/00500 (2.00%) | loss: 9.015804 | grad norm: 5.4906 | lrm: 1.00 | dt: 69.81ms | tok/sec: 1,833 | mfu: -1.00 | total time: 0.00m\n",
      "step 00011/00500 (2.20%) | loss: 8.793494 | grad norm: 4.2153 | lrm: 1.00 | dt: 68.68ms | tok/sec: 1,863 | mfu: -1.00 | total time: 0.00m\n",
      "step 00012/00500 (2.40%) | loss: 8.774267 | grad norm: 6.3545 | lrm: 1.00 | dt: 68.29ms | tok/sec: 1,874 | mfu: -1.00 | total time: 0.00m\n",
      "step 00013/00500 (2.60%) | loss: 8.711137 | grad norm: 4.9745 | lrm: 1.00 | dt: 67.09ms | tok/sec: 1,907 | mfu: -1.00 | total time: 0.00m\n",
      "step 00014/00500 (2.80%) | loss: 8.663987 | grad norm: 5.0642 | lrm: 1.00 | dt: 67.13ms | tok/sec: 1,906 | mfu: -1.00 | total time: 0.00m\n",
      "step 00015/00500 (3.00%) | loss: 8.546941 | grad norm: 3.9855 | lrm: 1.00 | dt: 66.60ms | tok/sec: 1,921 | mfu: -1.00 | total time: 0.01m\n",
      "step 00016/00500 (3.20%) | loss: 8.395721 | grad norm: 3.7900 | lrm: 1.00 | dt: 67.04ms | tok/sec: 1,909 | mfu: -1.00 | total time: 0.01m\n",
      "step 00017/00500 (3.40%) | loss: 8.322360 | grad norm: 5.2913 | lrm: 1.00 | dt: 68.34ms | tok/sec: 1,872 | mfu: -1.00 | total time: 0.01m\n",
      "step 00018/00500 (3.60%) | loss: 8.182122 | grad norm: 4.0100 | lrm: 1.00 | dt: 65.71ms | tok/sec: 1,947 | mfu: -1.00 | total time: 0.01m\n",
      "step 00019/00500 (3.80%) | loss: 8.016979 | grad norm: 3.8912 | lrm: 1.00 | dt: 65.57ms | tok/sec: 1,952 | mfu: -1.00 | total time: 0.01m\n",
      "step 00020/00500 (4.00%) | loss: 7.961029 | grad norm: 5.5383 | lrm: 1.00 | dt: 69.08ms | tok/sec: 1,852 | mfu: -1.00 | total time: 0.01m\n",
      "step 00021/00500 (4.20%) | loss: 7.783997 | grad norm: 3.1884 | lrm: 1.00 | dt: 69.81ms | tok/sec: 1,833 | mfu: -1.00 | total time: 0.01m\n",
      "step 00022/00500 (4.40%) | loss: 7.707288 | grad norm: 3.5926 | lrm: 1.00 | dt: 68.33ms | tok/sec: 1,873 | mfu: -1.00 | total time: 0.01m\n",
      "step 00023/00500 (4.60%) | loss: 7.582953 | grad norm: 3.4293 | lrm: 1.00 | dt: 69.44ms | tok/sec: 1,843 | mfu: -1.00 | total time: 0.01m\n",
      "step 00024/00500 (4.80%) | loss: 7.433754 | grad norm: 3.3108 | lrm: 1.00 | dt: 69.42ms | tok/sec: 1,843 | mfu: -1.00 | total time: 0.02m\n",
      "step 00025/00500 (5.00%) | loss: 7.336095 | grad norm: 4.0759 | lrm: 1.00 | dt: 69.38ms | tok/sec: 1,844 | mfu: -1.00 | total time: 0.02m\n",
      "step 00026/00500 (5.20%) | loss: 7.269915 | grad norm: 3.6877 | lrm: 1.00 | dt: 70.21ms | tok/sec: 1,823 | mfu: -1.00 | total time: 0.02m\n",
      "step 00027/00500 (5.40%) | loss: 7.305111 | grad norm: 4.8322 | lrm: 1.00 | dt: 73.24ms | tok/sec: 1,747 | mfu: -1.00 | total time: 0.02m\n",
      "step 00028/00500 (5.60%) | loss: 7.525299 | grad norm: 7.9150 | lrm: 1.00 | dt: 72.96ms | tok/sec: 1,754 | mfu: -1.00 | total time: 0.02m\n",
      "step 00029/00500 (5.80%) | loss: 7.691327 | grad norm: 4.5909 | lrm: 1.00 | dt: 70.18ms | tok/sec: 1,823 | mfu: -1.00 | total time: 0.02m\n",
      "step 00030/00500 (6.00%) | loss: 7.796027 | grad norm: 4.1337 | lrm: 1.00 | dt: 72.60ms | tok/sec: 1,763 | mfu: -1.00 | total time: 0.02m\n",
      "step 00031/00500 (6.20%) | loss: 7.914382 | grad norm: 4.5923 | lrm: 1.00 | dt: 64.77ms | tok/sec: 1,976 | mfu: -1.00 | total time: 0.02m\n",
      "step 00032/00500 (6.40%) | loss: 7.949333 | grad norm: 4.5701 | lrm: 1.00 | dt: 65.83ms | tok/sec: 1,944 | mfu: -1.00 | total time: 0.03m\n",
      "step 00033/00500 (6.60%) | loss: 7.969682 | grad norm: 3.8611 | lrm: 1.00 | dt: 72.88ms | tok/sec: 1,756 | mfu: -1.00 | total time: 0.03m\n",
      "step 00034/00500 (6.80%) | loss: 7.925370 | grad norm: 3.5267 | lrm: 1.00 | dt: 75.37ms | tok/sec: 1,698 | mfu: -1.00 | total time: 0.03m\n",
      "step 00035/00500 (7.00%) | loss: 7.853387 | grad norm: 3.2932 | lrm: 1.00 | dt: 68.41ms | tok/sec: 1,870 | mfu: -1.00 | total time: 0.03m\n",
      "step 00036/00500 (7.20%) | loss: 7.800545 | grad norm: 3.2908 | lrm: 1.00 | dt: 83.64ms | tok/sec: 1,530 | mfu: -1.00 | total time: 0.03m\n",
      "step 00037/00500 (7.40%) | loss: 7.699846 | grad norm: 3.6312 | lrm: 1.00 | dt: 72.87ms | tok/sec: 1,756 | mfu: -1.00 | total time: 0.03m\n",
      "step 00038/00500 (7.60%) | loss: 7.620991 | grad norm: 4.4460 | lrm: 1.00 | dt: 73.09ms | tok/sec: 1,751 | mfu: -1.00 | total time: 0.03m\n",
      "step 00039/00500 (7.80%) | loss: 7.509938 | grad norm: 3.3259 | lrm: 1.00 | dt: 74.94ms | tok/sec: 1,707 | mfu: -1.00 | total time: 0.03m\n",
      "step 00040/00500 (8.00%) | loss: 7.396593 | grad norm: 3.1630 | lrm: 1.00 | dt: 75.84ms | tok/sec: 1,687 | mfu: -1.00 | total time: 0.04m\n",
      "step 00041/00500 (8.20%) | loss: 7.250019 | grad norm: 2.8794 | lrm: 1.00 | dt: 71.11ms | tok/sec: 1,799 | mfu: -1.00 | total time: 0.04m\n",
      "step 00042/00500 (8.40%) | loss: 7.253683 | grad norm: 3.1032 | lrm: 1.00 | dt: 70.93ms | tok/sec: 1,804 | mfu: -1.00 | total time: 0.04m\n",
      "step 00043/00500 (8.60%) | loss: 7.205068 | grad norm: 3.4258 | lrm: 1.00 | dt: 72.75ms | tok/sec: 1,759 | mfu: -1.00 | total time: 0.04m\n",
      "step 00044/00500 (8.80%) | loss: 7.204157 | grad norm: 3.3463 | lrm: 1.00 | dt: 70.63ms | tok/sec: 1,812 | mfu: -1.00 | total time: 0.04m\n",
      "step 00045/00500 (9.00%) | loss: 7.202758 | grad norm: 3.6437 | lrm: 1.00 | dt: 68.29ms | tok/sec: 1,874 | mfu: -1.00 | total time: 0.04m\n",
      "step 00046/00500 (9.20%) | loss: 7.141598 | grad norm: 4.4343 | lrm: 1.00 | dt: 69.03ms | tok/sec: 1,854 | mfu: -1.00 | total time: 0.04m\n",
      "step 00047/00500 (9.40%) | loss: 7.076550 | grad norm: 3.6542 | lrm: 1.00 | dt: 75.37ms | tok/sec: 1,698 | mfu: -1.00 | total time: 0.04m\n",
      "step 00048/00500 (9.60%) | loss: 7.079036 | grad norm: 3.3623 | lrm: 1.00 | dt: 72.67ms | tok/sec: 1,761 | mfu: -1.00 | total time: 0.04m\n",
      "step 00049/00500 (9.80%) | loss: 7.058586 | grad norm: 3.5718 | lrm: 1.00 | dt: 67.00ms | tok/sec: 1,910 | mfu: -1.00 | total time: 0.05m\n",
      "step 00050/00500 (10.00%) | loss: 6.983118 | grad norm: 3.4281 | lrm: 1.00 | dt: 66.16ms | tok/sec: 1,934 | mfu: -1.00 | total time: 0.05m\n",
      "step 00051/00500 (10.20%) | loss: 6.931643 | grad norm: 6.4292 | lrm: 1.00 | dt: 66.70ms | tok/sec: 1,918 | mfu: -1.00 | total time: 0.05m\n",
      "step 00052/00500 (10.40%) | loss: 6.908469 | grad norm: 3.3272 | lrm: 1.00 | dt: 64.85ms | tok/sec: 1,973 | mfu: -1.00 | total time: 0.05m\n",
      "step 00053/00500 (10.60%) | loss: 7.068391 | grad norm: 5.1935 | lrm: 1.00 | dt: 68.29ms | tok/sec: 1,874 | mfu: -1.00 | total time: 0.05m\n",
      "step 00054/00500 (10.80%) | loss: 7.241867 | grad norm: 4.6612 | lrm: 1.00 | dt: 71.77ms | tok/sec: 1,783 | mfu: -1.00 | total time: 0.05m\n",
      "step 00055/00500 (11.00%) | loss: 7.384994 | grad norm: 3.7904 | lrm: 1.00 | dt: 73.26ms | tok/sec: 1,747 | mfu: -1.00 | total time: 0.05m\n",
      "step 00056/00500 (11.20%) | loss: 7.426217 | grad norm: 7.8998 | lrm: 1.00 | dt: 64.62ms | tok/sec: 1,980 | mfu: -1.00 | total time: 0.05m\n",
      "step 00057/00500 (11.40%) | loss: 7.528595 | grad norm: 3.6681 | lrm: 1.00 | dt: 71.69ms | tok/sec: 1,785 | mfu: -1.00 | total time: 0.05m\n",
      "step 00058/00500 (11.60%) | loss: 7.605880 | grad norm: 3.9972 | lrm: 1.00 | dt: 65.77ms | tok/sec: 1,946 | mfu: -1.00 | total time: 0.06m\n",
      "step 00059/00500 (11.80%) | loss: 7.722745 | grad norm: 4.7478 | lrm: 1.00 | dt: 70.05ms | tok/sec: 1,827 | mfu: -1.00 | total time: 0.06m\n",
      "step 00060/00500 (12.00%) | loss: 7.801663 | grad norm: 3.5210 | lrm: 1.00 | dt: 73.86ms | tok/sec: 1,733 | mfu: -1.00 | total time: 0.06m\n",
      "step 00061/00500 (12.20%) | loss: 7.846173 | grad norm: 3.3474 | lrm: 1.00 | dt: 71.66ms | tok/sec: 1,786 | mfu: -1.00 | total time: 0.06m\n",
      "step 00062/00500 (12.40%) | loss: 7.941086 | grad norm: 3.7448 | lrm: 1.00 | dt: 72.28ms | tok/sec: 1,770 | mfu: -1.00 | total time: 0.06m\n",
      "step 00063/00500 (12.60%) | loss: 7.988979 | grad norm: 7.5334 | lrm: 1.00 | dt: 71.67ms | tok/sec: 1,785 | mfu: -1.00 | total time: 0.06m\n",
      "step 00064/00500 (12.80%) | loss: 7.994318 | grad norm: 3.8093 | lrm: 1.00 | dt: 70.50ms | tok/sec: 1,815 | mfu: -1.00 | total time: 0.06m\n",
      "step 00065/00500 (13.00%) | loss: 7.986970 | grad norm: 4.6702 | lrm: 1.00 | dt: 65.00ms | tok/sec: 1,969 | mfu: -1.00 | total time: 0.06m\n",
      "step 00066/00500 (13.20%) | loss: 7.948254 | grad norm: 3.3232 | lrm: 1.00 | dt: 68.51ms | tok/sec: 1,868 | mfu: -1.00 | total time: 0.07m\n",
      "step 00067/00500 (13.40%) | loss: 7.879156 | grad norm: 3.2836 | lrm: 1.00 | dt: 70.84ms | tok/sec: 1,806 | mfu: -1.00 | total time: 0.07m\n",
      "step 00068/00500 (13.60%) | loss: 7.934470 | grad norm: 7.4177 | lrm: 1.00 | dt: 70.05ms | tok/sec: 1,827 | mfu: -1.00 | total time: 0.07m\n",
      "step 00069/00500 (13.80%) | loss: 7.999142 | grad norm: 4.0922 | lrm: 1.00 | dt: 73.39ms | tok/sec: 1,744 | mfu: -1.00 | total time: 0.07m\n",
      "step 00070/00500 (14.00%) | loss: 8.071936 | grad norm: 3.7031 | lrm: 1.00 | dt: 71.59ms | tok/sec: 1,787 | mfu: -1.00 | total time: 0.07m\n",
      "step 00071/00500 (14.20%) | loss: 8.070311 | grad norm: 3.3914 | lrm: 1.00 | dt: 69.16ms | tok/sec: 1,850 | mfu: -1.00 | total time: 0.07m\n",
      "step 00072/00500 (14.40%) | loss: 7.889853 | grad norm: 4.9190 | lrm: 1.00 | dt: 68.47ms | tok/sec: 1,869 | mfu: -1.00 | total time: 0.07m\n",
      "step 00073/00500 (14.60%) | loss: 7.882905 | grad norm: 9.3091 | lrm: 1.00 | dt: 68.46ms | tok/sec: 1,869 | mfu: -1.00 | total time: 0.07m\n",
      "step 00074/00500 (14.80%) | loss: 7.829975 | grad norm: 6.4499 | lrm: 1.00 | dt: 69.60ms | tok/sec: 1,839 | mfu: -1.00 | total time: 0.07m\n",
      "step 00075/00500 (15.00%) | loss: 7.772831 | grad norm: 4.6780 | lrm: 1.00 | dt: 72.30ms | tok/sec: 1,770 | mfu: -1.00 | total time: 0.08m\n",
      "step 00076/00500 (15.20%) | loss: 7.890555 | grad norm: 4.7146 | lrm: 1.00 | dt: 67.89ms | tok/sec: 1,885 | mfu: -1.00 | total time: 0.08m\n",
      "step 00077/00500 (15.40%) | loss: 7.983752 | grad norm: 4.8344 | lrm: 1.00 | dt: 70.53ms | tok/sec: 1,814 | mfu: -1.00 | total time: 0.08m\n",
      "step 00078/00500 (15.60%) | loss: 8.088202 | grad norm: 4.8022 | lrm: 1.00 | dt: 66.51ms | tok/sec: 1,924 | mfu: -1.00 | total time: 0.08m\n",
      "step 00079/00500 (15.80%) | loss: 8.129591 | grad norm: 3.8623 | lrm: 1.00 | dt: 66.23ms | tok/sec: 1,932 | mfu: -1.00 | total time: 0.08m\n",
      "step 00080/00500 (16.00%) | loss: 8.122945 | grad norm: 3.2114 | lrm: 1.00 | dt: 66.83ms | tok/sec: 1,915 | mfu: -1.00 | total time: 0.08m\n",
      "step 00081/00500 (16.20%) | loss: 8.166314 | grad norm: 4.7788 | lrm: 1.00 | dt: 64.57ms | tok/sec: 1,982 | mfu: -1.00 | total time: 0.08m\n",
      "step 00082/00500 (16.40%) | loss: 8.208814 | grad norm: 4.2126 | lrm: 1.00 | dt: 62.96ms | tok/sec: 2,033 | mfu: -1.00 | total time: 0.08m\n",
      "step 00083/00500 (16.60%) | loss: 8.245878 | grad norm: 3.2155 | lrm: 1.00 | dt: 71.73ms | tok/sec: 1,784 | mfu: -1.00 | total time: 0.08m\n",
      "step 00084/00500 (16.80%) | loss: 8.216076 | grad norm: 3.5427 | lrm: 1.00 | dt: 70.68ms | tok/sec: 1,810 | mfu: -1.00 | total time: 0.09m\n",
      "step 00085/00500 (17.00%) | loss: 8.227288 | grad norm: 5.4242 | lrm: 1.00 | dt: 75.12ms | tok/sec: 1,703 | mfu: -1.00 | total time: 0.09m\n",
      "step 00086/00500 (17.20%) | loss: 8.140451 | grad norm: 3.3816 | lrm: 1.00 | dt: 74.03ms | tok/sec: 1,729 | mfu: -1.00 | total time: 0.09m\n",
      "step 00087/00500 (17.40%) | loss: 8.153177 | grad norm: 5.7533 | lrm: 1.00 | dt: 71.42ms | tok/sec: 1,792 | mfu: -1.00 | total time: 0.09m\n",
      "step 00088/00500 (17.60%) | loss: 8.232290 | grad norm: 4.9262 | lrm: 1.00 | dt: 70.46ms | tok/sec: 1,816 | mfu: -1.00 | total time: 0.09m\n",
      "step 00089/00500 (17.80%) | loss: 8.209859 | grad norm: 4.4484 | lrm: 1.00 | dt: 69.45ms | tok/sec: 1,843 | mfu: -1.00 | total time: 0.09m\n",
      "step 00090/00500 (18.00%) | loss: 8.382257 | grad norm: 6.6342 | lrm: 1.00 | dt: 77.82ms | tok/sec: 1,644 | mfu: -1.00 | total time: 0.09m\n",
      "step 00091/00500 (18.20%) | loss: 8.435108 | grad norm: 3.7033 | lrm: 1.00 | dt: 72.01ms | tok/sec: 1,777 | mfu: -1.00 | total time: 0.09m\n",
      "step 00092/00500 (18.40%) | loss: 8.428233 | grad norm: 3.0986 | lrm: 1.00 | dt: 66.96ms | tok/sec: 1,911 | mfu: -1.00 | total time: 0.10m\n",
      "step 00093/00500 (18.60%) | loss: 8.361513 | grad norm: 3.0516 | lrm: 1.00 | dt: 65.43ms | tok/sec: 1,956 | mfu: -1.00 | total time: 0.10m\n",
      "step 00094/00500 (18.80%) | loss: 8.209686 | grad norm: 4.5207 | lrm: 1.00 | dt: 64.26ms | tok/sec: 1,991 | mfu: -1.00 | total time: 0.10m\n",
      "step 00095/00500 (19.00%) | loss: 7.974793 | grad norm: 2.7390 | lrm: 1.00 | dt: 68.50ms | tok/sec: 1,868 | mfu: -1.00 | total time: 0.10m\n",
      "step 00096/00500 (19.20%) | loss: 7.824479 | grad norm: 2.7973 | lrm: 1.00 | dt: 70.29ms | tok/sec: 1,821 | mfu: -1.00 | total time: 0.10m\n",
      "step 00097/00500 (19.40%) | loss: 7.714430 | grad norm: 5.0457 | lrm: 1.00 | dt: 71.37ms | tok/sec: 1,793 | mfu: -1.00 | total time: 0.10m\n",
      "step 00098/00500 (19.60%) | loss: 7.568915 | grad norm: 3.7093 | lrm: 1.00 | dt: 72.63ms | tok/sec: 1,762 | mfu: -1.00 | total time: 0.10m\n",
      "step 00099/00500 (19.80%) | loss: 7.317265 | grad norm: 3.6121 | lrm: 1.00 | dt: 82.10ms | tok/sec: 1,559 | mfu: -1.00 | total time: 0.10m\n",
      "step 00100 | Validation bpb: 2.9671\n",
      "step 00100/00500 (20.00%) | loss: 7.190002 | grad norm: 2.9246 | lrm: 1.00 | dt: 68.97ms | tok/sec: 1,855 | mfu: -1.00 | total time: 0.11m\n",
      "step 00101/00500 (20.20%) | loss: 7.349627 | grad norm: 6.9821 | lrm: 1.00 | dt: 66.97ms | tok/sec: 1,911 | mfu: -1.00 | total time: 0.11m\n",
      "step 00102/00500 (20.40%) | loss: 7.469196 | grad norm: 4.6562 | lrm: 1.00 | dt: 72.81ms | tok/sec: 1,758 | mfu: -1.00 | total time: 0.11m\n",
      "step 00103/00500 (20.60%) | loss: 7.584043 | grad norm: 4.1683 | lrm: 1.00 | dt: 69.17ms | tok/sec: 1,850 | mfu: -1.00 | total time: 0.11m\n",
      "step 00104/00500 (20.80%) | loss: 7.660971 | grad norm: 4.6828 | lrm: 1.00 | dt: 70.41ms | tok/sec: 1,817 | mfu: -1.00 | total time: 0.11m\n",
      "step 00105/00500 (21.00%) | loss: 7.757660 | grad norm: 4.5146 | lrm: 1.00 | dt: 72.51ms | tok/sec: 1,765 | mfu: -1.00 | total time: 0.11m\n",
      "step 00106/00500 (21.20%) | loss: 7.748352 | grad norm: 4.9814 | lrm: 1.00 | dt: 70.30ms | tok/sec: 1,820 | mfu: -1.00 | total time: 0.11m\n",
      "step 00107/00500 (21.40%) | loss: 7.774610 | grad norm: 3.2868 | lrm: 1.00 | dt: 69.23ms | tok/sec: 1,848 | mfu: -1.00 | total time: 0.11m\n",
      "step 00108/00500 (21.60%) | loss: 7.768752 | grad norm: 3.1226 | lrm: 1.00 | dt: 68.53ms | tok/sec: 1,867 | mfu: -1.00 | total time: 0.11m\n",
      "step 00109/00500 (21.80%) | loss: 7.785187 | grad norm: 2.8500 | lrm: 1.00 | dt: 69.33ms | tok/sec: 1,846 | mfu: -1.00 | total time: 0.12m\n",
      "step 00110/00500 (22.00%) | loss: 7.798049 | grad norm: 3.1295 | lrm: 1.00 | dt: 67.38ms | tok/sec: 1,899 | mfu: -1.00 | total time: 0.12m\n",
      "step 00111/00500 (22.20%) | loss: 7.754662 | grad norm: 2.7039 | lrm: 1.00 | dt: 71.42ms | tok/sec: 1,792 | mfu: -1.00 | total time: 0.12m\n",
      "step 00112/00500 (22.40%) | loss: 7.722563 | grad norm: 4.1459 | lrm: 1.00 | dt: 70.13ms | tok/sec: 1,825 | mfu: -1.00 | total time: 0.12m\n",
      "step 00113/00500 (22.60%) | loss: 7.622062 | grad norm: 3.7741 | lrm: 1.00 | dt: 71.65ms | tok/sec: 1,786 | mfu: -1.00 | total time: 0.12m\n",
      "step 00114/00500 (22.80%) | loss: 7.607557 | grad norm: 3.1485 | lrm: 1.00 | dt: 65.76ms | tok/sec: 1,946 | mfu: -1.00 | total time: 0.12m\n",
      "step 00115/00500 (23.00%) | loss: 7.608362 | grad norm: 3.4433 | lrm: 1.00 | dt: 65.95ms | tok/sec: 1,940 | mfu: -1.00 | total time: 0.12m\n",
      "step 00116/00500 (23.20%) | loss: 7.631223 | grad norm: 3.3136 | lrm: 1.00 | dt: 69.16ms | tok/sec: 1,850 | mfu: -1.00 | total time: 0.12m\n",
      "step 00117/00500 (23.40%) | loss: 7.619723 | grad norm: 3.6213 | lrm: 1.00 | dt: 74.01ms | tok/sec: 1,729 | mfu: -1.00 | total time: 0.12m\n",
      "step 00118/00500 (23.60%) | loss: 7.643694 | grad norm: 4.2980 | lrm: 1.00 | dt: 74.47ms | tok/sec: 1,718 | mfu: -1.00 | total time: 0.13m\n",
      "step 00119/00500 (23.80%) | loss: 7.822337 | grad norm: 6.8104 | lrm: 1.00 | dt: 74.66ms | tok/sec: 1,714 | mfu: -1.00 | total time: 0.13m\n",
      "step 00120/00500 (24.00%) | loss: 7.945302 | grad norm: 4.8145 | lrm: 1.00 | dt: 68.62ms | tok/sec: 1,865 | mfu: -1.00 | total time: 0.13m\n",
      "step 00121/00500 (24.20%) | loss: 8.064810 | grad norm: 3.4002 | lrm: 1.00 | dt: 71.84ms | tok/sec: 1,781 | mfu: -1.00 | total time: 0.13m\n",
      "step 00122/00500 (24.40%) | loss: 8.122882 | grad norm: 3.9903 | lrm: 1.00 | dt: 74.29ms | tok/sec: 1,723 | mfu: -1.00 | total time: 0.13m\n",
      "step 00123/00500 (24.60%) | loss: 8.164701 | grad norm: 4.0703 | lrm: 1.00 | dt: 72.88ms | tok/sec: 1,756 | mfu: -1.00 | total time: 0.13m\n",
      "step 00124/00500 (24.80%) | loss: 8.156371 | grad norm: 3.0475 | lrm: 1.00 | dt: 70.17ms | tok/sec: 1,824 | mfu: -1.00 | total time: 0.13m\n",
      "step 00125/00500 (25.00%) | loss: 8.066159 | grad norm: 3.2567 | lrm: 1.00 | dt: 68.43ms | tok/sec: 1,870 | mfu: -1.00 | total time: 0.13m\n",
      "step 00126/00500 (25.20%) | loss: 8.205299 | grad norm: 5.0496 | lrm: 1.00 | dt: 72.01ms | tok/sec: 1,777 | mfu: -1.00 | total time: 0.14m\n",
      "step 00127/00500 (25.40%) | loss: 8.364732 | grad norm: 6.7973 | lrm: 1.00 | dt: 68.95ms | tok/sec: 1,856 | mfu: -1.00 | total time: 0.14m\n",
      "step 00128/00500 (25.60%) | loss: 8.405644 | grad norm: 4.6583 | lrm: 1.00 | dt: 72.39ms | tok/sec: 1,768 | mfu: -1.00 | total time: 0.14m\n",
      "step 00129/00500 (25.80%) | loss: 8.471246 | grad norm: 5.0490 | lrm: 1.00 | dt: 71.49ms | tok/sec: 1,790 | mfu: -1.00 | total time: 0.14m\n",
      "step 00130/00500 (26.00%) | loss: 8.431796 | grad norm: 5.8541 | lrm: 1.00 | dt: 72.14ms | tok/sec: 1,774 | mfu: -1.00 | total time: 0.14m\n",
      "step 00131/00500 (26.20%) | loss: 8.403069 | grad norm: 3.2148 | lrm: 1.00 | dt: 72.17ms | tok/sec: 1,773 | mfu: -1.00 | total time: 0.14m\n",
      "step 00132/00500 (26.40%) | loss: 8.363872 | grad norm: 2.5416 | lrm: 1.00 | dt: 69.04ms | tok/sec: 1,854 | mfu: -1.00 | total time: 0.14m\n",
      "step 00133/00500 (26.60%) | loss: 8.276765 | grad norm: 3.9915 | lrm: 1.00 | dt: 74.10ms | tok/sec: 1,727 | mfu: -1.00 | total time: 0.14m\n",
      "step 00134/00500 (26.80%) | loss: 8.196383 | grad norm: 2.7089 | lrm: 1.00 | dt: 71.73ms | tok/sec: 1,784 | mfu: -1.00 | total time: 0.15m\n",
      "step 00135/00500 (27.00%) | loss: 8.105965 | grad norm: 2.7155 | lrm: 1.00 | dt: 69.29ms | tok/sec: 1,847 | mfu: -1.00 | total time: 0.15m\n",
      "step 00136/00500 (27.20%) | loss: 8.005427 | grad norm: 5.5376 | lrm: 1.00 | dt: 71.90ms | tok/sec: 1,780 | mfu: -1.00 | total time: 0.15m\n",
      "step 00137/00500 (27.40%) | loss: 7.968361 | grad norm: 2.8286 | lrm: 1.00 | dt: 71.48ms | tok/sec: 1,790 | mfu: -1.00 | total time: 0.15m\n",
      "step 00138/00500 (27.60%) | loss: 7.898382 | grad norm: 2.7762 | lrm: 1.00 | dt: 80.75ms | tok/sec: 1,585 | mfu: -1.00 | total time: 0.15m\n",
      "step 00139/00500 (27.80%) | loss: 7.768925 | grad norm: 3.6135 | lrm: 1.00 | dt: 78.11ms | tok/sec: 1,638 | mfu: -1.00 | total time: 0.15m\n",
      "step 00140/00500 (28.00%) | loss: 7.673632 | grad norm: 3.5871 | lrm: 1.00 | dt: 85.89ms | tok/sec: 1,490 | mfu: -1.00 | total time: 0.15m\n",
      "step 00141/00500 (28.20%) | loss: 7.603120 | grad norm: 2.3635 | lrm: 1.00 | dt: 76.44ms | tok/sec: 1,674 | mfu: -1.00 | total time: 0.15m\n",
      "step 00142/00500 (28.40%) | loss: 7.588436 | grad norm: 2.8934 | lrm: 1.00 | dt: 71.59ms | tok/sec: 1,787 | mfu: -1.00 | total time: 0.16m\n",
      "step 00143/00500 (28.60%) | loss: 7.543085 | grad norm: 3.2223 | lrm: 1.00 | dt: 72.21ms | tok/sec: 1,772 | mfu: -1.00 | total time: 0.16m\n",
      "step 00144/00500 (28.80%) | loss: 7.554374 | grad norm: 3.0994 | lrm: 1.00 | dt: 77.39ms | tok/sec: 1,654 | mfu: -1.00 | total time: 0.16m\n",
      "step 00145/00500 (29.00%) | loss: 7.471396 | grad norm: 3.1082 | lrm: 1.00 | dt: 455.46ms | tok/sec: 281 | mfu: -1.00 | total time: 0.17m\n",
      "step 00146/00500 (29.20%) | loss: 7.403061 | grad norm: 4.1530 | lrm: 1.00 | dt: 194.13ms | tok/sec: 659 | mfu: -1.00 | total time: 0.17m\n",
      "step 00147/00500 (29.40%) | loss: 7.313855 | grad norm: 3.5709 | lrm: 1.00 | dt: 89.87ms | tok/sec: 1,424 | mfu: -1.00 | total time: 0.17m\n",
      "step 00148/00500 (29.60%) | loss: 7.235566 | grad norm: 2.7930 | lrm: 1.00 | dt: 73.59ms | tok/sec: 1,739 | mfu: -1.00 | total time: 0.17m\n",
      "step 00149/00500 (29.80%) | loss: 7.321892 | grad norm: 3.8376 | lrm: 1.00 | dt: 63.89ms | tok/sec: 2,003 | mfu: -1.00 | total time: 0.17m\n",
      "step 00150/00500 (30.00%) | loss: 7.355592 | grad norm: 3.5238 | lrm: 1.00 | dt: 70.37ms | tok/sec: 1,819 | mfu: -1.00 | total time: 0.17m\n",
      "step 00151/00500 (30.20%) | loss: 7.286617 | grad norm: 4.5301 | lrm: 1.00 | dt: 299.22ms | tok/sec: 427 | mfu: -1.00 | total time: 0.18m\n",
      "step 00152/00500 (30.40%) | loss: 7.195655 | grad norm: 3.2244 | lrm: 1.00 | dt: 138.86ms | tok/sec: 921 | mfu: -1.00 | total time: 0.18m\n",
      "step 00153/00500 (30.60%) | loss: 7.005991 | grad norm: 2.6210 | lrm: 1.00 | dt: 64.47ms | tok/sec: 1,985 | mfu: -1.00 | total time: 0.18m\n",
      "step 00154/00500 (30.80%) | loss: 6.762791 | grad norm: 3.8022 | lrm: 1.00 | dt: 62.75ms | tok/sec: 2,040 | mfu: -1.00 | total time: 0.18m\n",
      "step 00155/00500 (31.00%) | loss: 6.698706 | grad norm: 3.0166 | lrm: 1.00 | dt: 65.32ms | tok/sec: 1,959 | mfu: -1.00 | total time: 0.18m\n",
      "step 00156/00500 (31.20%) | loss: 6.749509 | grad norm: 4.0671 | lrm: 1.00 | dt: 66.73ms | tok/sec: 1,918 | mfu: -1.00 | total time: 0.19m\n",
      "step 00157/00500 (31.40%) | loss: 6.606677 | grad norm: 4.5318 | lrm: 1.00 | dt: 62.50ms | tok/sec: 2,048 | mfu: -1.00 | total time: 0.19m\n",
      "step 00158/00500 (31.60%) | loss: 6.586090 | grad norm: 3.6810 | lrm: 1.00 | dt: 78.76ms | tok/sec: 1,625 | mfu: -1.00 | total time: 0.19m\n",
      "step 00159/00500 (31.80%) | loss: 6.418048 | grad norm: 2.6451 | lrm: 1.00 | dt: 67.91ms | tok/sec: 1,884 | mfu: -1.00 | total time: 0.19m\n",
      "step 00160/00500 (32.00%) | loss: 6.197221 | grad norm: 2.2720 | lrm: 1.00 | dt: 72.66ms | tok/sec: 1,761 | mfu: -1.00 | total time: 0.19m\n",
      "step 00161/00500 (32.20%) | loss: 6.014362 | grad norm: 3.1285 | lrm: 1.00 | dt: 68.46ms | tok/sec: 1,869 | mfu: -1.00 | total time: 0.19m\n",
      "step 00162/00500 (32.40%) | loss: 6.040372 | grad norm: 2.7466 | lrm: 1.00 | dt: 65.96ms | tok/sec: 1,940 | mfu: -1.00 | total time: 0.19m\n",
      "step 00163/00500 (32.60%) | loss: 5.893877 | grad norm: 2.9217 | lrm: 1.00 | dt: 69.91ms | tok/sec: 1,831 | mfu: -1.00 | total time: 0.19m\n",
      "step 00164/00500 (32.80%) | loss: 5.761724 | grad norm: 2.3883 | lrm: 1.00 | dt: 75.47ms | tok/sec: 1,696 | mfu: -1.00 | total time: 0.19m\n",
      "step 00165/00500 (33.00%) | loss: 5.899502 | grad norm: 3.1798 | lrm: 1.00 | dt: 78.56ms | tok/sec: 1,629 | mfu: -1.00 | total time: 0.20m\n",
      "step 00166/00500 (33.20%) | loss: 6.314377 | grad norm: 6.6975 | lrm: 1.00 | dt: 62.95ms | tok/sec: 2,033 | mfu: -1.00 | total time: 0.20m\n",
      "step 00167/00500 (33.40%) | loss: 6.647875 | grad norm: 4.6660 | lrm: 1.00 | dt: 78.95ms | tok/sec: 1,621 | mfu: -1.00 | total time: 0.20m\n",
      "step 00168/00500 (33.60%) | loss: 6.834502 | grad norm: 3.4470 | lrm: 1.00 | dt: 74.70ms | tok/sec: 1,713 | mfu: -1.00 | total time: 0.20m\n",
      "step 00169/00500 (33.80%) | loss: 6.956603 | grad norm: 3.6835 | lrm: 1.00 | dt: 62.45ms | tok/sec: 2,049 | mfu: -1.00 | total time: 0.20m\n",
      "step 00170/00500 (34.00%) | loss: 7.089232 | grad norm: 3.0993 | lrm: 1.00 | dt: 65.56ms | tok/sec: 1,952 | mfu: -1.00 | total time: 0.20m\n",
      "step 00171/00500 (34.20%) | loss: 7.225257 | grad norm: 3.7036 | lrm: 1.00 | dt: 72.22ms | tok/sec: 1,772 | mfu: -1.00 | total time: 0.20m\n",
      "step 00172/00500 (34.40%) | loss: 7.318930 | grad norm: 2.6424 | lrm: 1.00 | dt: 79.00ms | tok/sec: 1,620 | mfu: -1.00 | total time: 0.20m\n",
      "step 00173/00500 (34.60%) | loss: 7.408586 | grad norm: 2.9251 | lrm: 1.00 | dt: 68.98ms | tok/sec: 1,855 | mfu: -1.00 | total time: 0.21m\n",
      "step 00174/00500 (34.80%) | loss: 7.429286 | grad norm: 2.7833 | lrm: 1.00 | dt: 80.82ms | tok/sec: 1,583 | mfu: -1.00 | total time: 0.21m\n",
      "step 00175/00500 (35.00%) | loss: 7.485088 | grad norm: 3.1587 | lrm: 1.00 | dt: 88.02ms | tok/sec: 1,454 | mfu: -1.00 | total time: 0.21m\n",
      "step 00176/00500 (35.20%) | loss: 7.622788 | grad norm: 4.1613 | lrm: 1.00 | dt: 74.29ms | tok/sec: 1,722 | mfu: -1.00 | total time: 0.21m\n",
      "step 00177/00500 (35.40%) | loss: 7.693360 | grad norm: 4.2775 | lrm: 1.00 | dt: 78.69ms | tok/sec: 1,626 | mfu: -1.00 | total time: 0.21m\n",
      "step 00178/00500 (35.60%) | loss: 7.661719 | grad norm: 3.5042 | lrm: 1.00 | dt: 89.60ms | tok/sec: 1,428 | mfu: -1.00 | total time: 0.21m\n",
      "step 00179/00500 (35.80%) | loss: 7.793672 | grad norm: 3.2546 | lrm: 1.00 | dt: 77.16ms | tok/sec: 1,658 | mfu: -1.00 | total time: 0.21m\n",
      "step 00180/00500 (36.00%) | loss: 7.763336 | grad norm: 3.1322 | lrm: 1.00 | dt: 79.09ms | tok/sec: 1,618 | mfu: -1.00 | total time: 0.21m\n",
      "step 00181/00500 (36.20%) | loss: 7.754749 | grad norm: 2.7422 | lrm: 1.00 | dt: 113.65ms | tok/sec: 1,126 | mfu: -1.00 | total time: 0.22m\n",
      "step 00182/00500 (36.40%) | loss: 7.911731 | grad norm: 4.5229 | lrm: 1.00 | dt: 70.13ms | tok/sec: 1,825 | mfu: -1.00 | total time: 0.22m\n",
      "step 00183/00500 (36.60%) | loss: 7.975203 | grad norm: 3.3509 | lrm: 1.00 | dt: 200.95ms | tok/sec: 636 | mfu: -1.00 | total time: 0.22m\n",
      "step 00184/00500 (36.80%) | loss: 8.058821 | grad norm: 3.1336 | lrm: 1.00 | dt: 424.81ms | tok/sec: 301 | mfu: -1.00 | total time: 0.23m\n",
      "step 00185/00500 (37.00%) | loss: 8.050732 | grad norm: 3.2558 | lrm: 1.00 | dt: 313.83ms | tok/sec: 407 | mfu: -1.00 | total time: 0.23m\n",
      "step 00186/00500 (37.20%) | loss: 8.203288 | grad norm: 5.1580 | lrm: 1.00 | dt: 91.25ms | tok/sec: 1,402 | mfu: -1.00 | total time: 0.23m\n",
      "step 00187/00500 (37.40%) | loss: 8.396936 | grad norm: 5.9790 | lrm: 1.00 | dt: 98.40ms | tok/sec: 1,300 | mfu: -1.00 | total time: 0.24m\n",
      "step 00188/00500 (37.60%) | loss: 8.495695 | grad norm: 3.2827 | lrm: 1.00 | dt: 65.44ms | tok/sec: 1,955 | mfu: -1.00 | total time: 0.24m\n",
      "step 00189/00500 (37.80%) | loss: 8.701219 | grad norm: 4.4282 | lrm: 1.00 | dt: 67.35ms | tok/sec: 1,900 | mfu: -1.00 | total time: 0.24m\n",
      "step 00190/00500 (38.00%) | loss: 8.593134 | grad norm: 6.6928 | lrm: 1.00 | dt: 66.69ms | tok/sec: 1,919 | mfu: -1.00 | total time: 0.24m\n",
      "step 00191/00500 (38.20%) | loss: 8.699412 | grad norm: 2.6427 | lrm: 1.00 | dt: 69.68ms | tok/sec: 1,836 | mfu: -1.00 | total time: 0.24m\n",
      "step 00192/00500 (38.40%) | loss: 8.704062 | grad norm: 2.4767 | lrm: 1.00 | dt: 69.00ms | tok/sec: 1,854 | mfu: -1.00 | total time: 0.24m\n",
      "step 00193/00500 (38.60%) | loss: 8.581665 | grad norm: 2.3041 | lrm: 1.00 | dt: 81.20ms | tok/sec: 1,576 | mfu: -1.00 | total time: 0.24m\n",
      "step 00194/00500 (38.80%) | loss: 8.439998 | grad norm: 2.0611 | lrm: 1.00 | dt: 64.51ms | tok/sec: 1,984 | mfu: -1.00 | total time: 0.24m\n",
      "step 00195/00500 (39.00%) | loss: 8.420230 | grad norm: 2.3362 | lrm: 1.00 | dt: 70.80ms | tok/sec: 1,807 | mfu: -1.00 | total time: 0.25m\n",
      "step 00196/00500 (39.20%) | loss: 8.444449 | grad norm: 2.5358 | lrm: 1.00 | dt: 66.05ms | tok/sec: 1,937 | mfu: -1.00 | total time: 0.25m\n",
      "step 00197/00500 (39.40%) | loss: 8.522836 | grad norm: 2.8531 | lrm: 1.00 | dt: 69.07ms | tok/sec: 1,853 | mfu: -1.00 | total time: 0.25m\n",
      "step 00198/00500 (39.60%) | loss: 8.369703 | grad norm: 2.4946 | lrm: 1.00 | dt: 76.22ms | tok/sec: 1,679 | mfu: -1.00 | total time: 0.25m\n",
      "step 00199/00500 (39.80%) | loss: 8.343858 | grad norm: 3.5705 | lrm: 1.00 | dt: 84.75ms | tok/sec: 1,510 | mfu: -1.00 | total time: 0.25m\n",
      "step 00200 | Validation bpb: 2.8697\n",
      "step 00200/00500 (40.00%) | loss: 8.355833 | grad norm: 2.3554 | lrm: 1.00 | dt: 70.74ms | tok/sec: 1,809 | mfu: -1.00 | total time: 0.25m\n",
      "step 00201/00500 (40.20%) | loss: 8.346721 | grad norm: 3.1091 | lrm: 1.00 | dt: 74.91ms | tok/sec: 1,708 | mfu: -1.00 | total time: 0.25m\n",
      "step 00202/00500 (40.40%) | loss: 8.242024 | grad norm: 2.4141 | lrm: 1.00 | dt: 65.73ms | tok/sec: 1,947 | mfu: -1.00 | total time: 0.25m\n",
      "step 00203/00500 (40.60%) | loss: 8.247140 | grad norm: 2.9871 | lrm: 1.00 | dt: 69.36ms | tok/sec: 1,845 | mfu: -1.00 | total time: 0.26m\n",
      "step 00204/00500 (40.80%) | loss: 8.384771 | grad norm: 3.5561 | lrm: 1.00 | dt: 68.43ms | tok/sec: 1,870 | mfu: -1.00 | total time: 0.26m\n",
      "step 00205/00500 (41.00%) | loss: 8.292052 | grad norm: 3.3677 | lrm: 1.00 | dt: 113.96ms | tok/sec: 1,123 | mfu: -1.00 | total time: 0.26m\n",
      "step 00206/00500 (41.20%) | loss: 8.178009 | grad norm: 4.2957 | lrm: 1.00 | dt: 73.03ms | tok/sec: 1,752 | mfu: -1.00 | total time: 0.26m\n",
      "step 00207/00500 (41.40%) | loss: 8.181977 | grad norm: 2.7600 | lrm: 1.00 | dt: 63.46ms | tok/sec: 2,017 | mfu: -1.00 | total time: 0.26m\n",
      "step 00208/00500 (41.60%) | loss: 8.294355 | grad norm: 2.9307 | lrm: 1.00 | dt: 71.13ms | tok/sec: 1,799 | mfu: -1.00 | total time: 0.26m\n",
      "step 00209/00500 (41.80%) | loss: 8.466612 | grad norm: 4.0546 | lrm: 1.00 | dt: 70.98ms | tok/sec: 1,803 | mfu: -1.00 | total time: 0.26m\n",
      "step 00210/00500 (42.00%) | loss: 8.382179 | grad norm: 4.3680 | lrm: 1.00 | dt: 66.79ms | tok/sec: 1,916 | mfu: -1.00 | total time: 0.26m\n",
      "step 00211/00500 (42.20%) | loss: 8.313814 | grad norm: 3.6527 | lrm: 1.00 | dt: 69.31ms | tok/sec: 1,846 | mfu: -1.00 | total time: 0.27m\n",
      "step 00212/00500 (42.40%) | loss: 8.299106 | grad norm: 2.8447 | lrm: 1.00 | dt: 65.71ms | tok/sec: 1,947 | mfu: -1.00 | total time: 0.27m\n",
      "step 00213/00500 (42.60%) | loss: 8.258929 | grad norm: 2.5272 | lrm: 1.00 | dt: 66.44ms | tok/sec: 1,926 | mfu: -1.00 | total time: 0.27m\n",
      "step 00214/00500 (42.80%) | loss: 8.277256 | grad norm: 2.7482 | lrm: 1.00 | dt: 75.54ms | tok/sec: 1,694 | mfu: -1.00 | total time: 0.27m\n",
      "step 00215/00500 (43.00%) | loss: 8.379471 | grad norm: 2.6329 | lrm: 1.00 | dt: 76.25ms | tok/sec: 1,678 | mfu: -1.00 | total time: 0.27m\n",
      "step 00216/00500 (43.20%) | loss: 8.370174 | grad norm: 4.9244 | lrm: 1.00 | dt: 81.30ms | tok/sec: 1,574 | mfu: -1.00 | total time: 0.27m\n",
      "step 00217/00500 (43.40%) | loss: 8.347179 | grad norm: 2.4959 | lrm: 1.00 | dt: 71.41ms | tok/sec: 1,792 | mfu: -1.00 | total time: 0.27m\n",
      "step 00218/00500 (43.60%) | loss: 8.385658 | grad norm: 3.3656 | lrm: 1.00 | dt: 124.69ms | tok/sec: 1,026 | mfu: -1.00 | total time: 0.27m\n",
      "step 00219/00500 (43.80%) | loss: 8.375943 | grad norm: 3.8377 | lrm: 1.00 | dt: 78.27ms | tok/sec: 1,635 | mfu: -1.00 | total time: 0.28m\n",
      "step 00220/00500 (44.00%) | loss: 8.297338 | grad norm: 3.9269 | lrm: 1.00 | dt: 82.90ms | tok/sec: 1,544 | mfu: -1.00 | total time: 0.28m\n",
      "step 00221/00500 (44.20%) | loss: 8.247781 | grad norm: 2.6454 | lrm: 1.00 | dt: 72.57ms | tok/sec: 1,763 | mfu: -1.00 | total time: 0.28m\n",
      "step 00222/00500 (44.40%) | loss: 8.194925 | grad norm: 2.7885 | lrm: 1.00 | dt: 87.50ms | tok/sec: 1,462 | mfu: -1.00 | total time: 0.28m\n",
      "step 00223/00500 (44.60%) | loss: 8.107265 | grad norm: 2.1199 | lrm: 1.00 | dt: 72.87ms | tok/sec: 1,756 | mfu: -1.00 | total time: 0.28m\n",
      "step 00224/00500 (44.80%) | loss: 8.063256 | grad norm: 2.1750 | lrm: 1.00 | dt: 66.12ms | tok/sec: 1,935 | mfu: -1.00 | total time: 0.28m\n",
      "step 00225/00500 (45.00%) | loss: 7.970527 | grad norm: 2.3215 | lrm: 1.00 | dt: 66.74ms | tok/sec: 1,917 | mfu: -1.00 | total time: 0.28m\n",
      "step 00226/00500 (45.20%) | loss: 7.877785 | grad norm: 2.5201 | lrm: 1.00 | dt: 69.76ms | tok/sec: 1,834 | mfu: -1.00 | total time: 0.28m\n",
      "step 00227/00500 (45.40%) | loss: 7.847916 | grad norm: 2.4915 | lrm: 1.00 | dt: 71.07ms | tok/sec: 1,801 | mfu: -1.00 | total time: 0.29m\n",
      "step 00228/00500 (45.60%) | loss: 7.849381 | grad norm: 2.0631 | lrm: 1.00 | dt: 77.58ms | tok/sec: 1,649 | mfu: -1.00 | total time: 0.29m\n",
      "step 00229/00500 (45.80%) | loss: 7.879368 | grad norm: 2.7069 | lrm: 1.00 | dt: 66.14ms | tok/sec: 1,935 | mfu: -1.00 | total time: 0.29m\n",
      "step 00230/00500 (46.00%) | loss: 7.842529 | grad norm: 2.4776 | lrm: 1.00 | dt: 62.26ms | tok/sec: 2,055 | mfu: -1.00 | total time: 0.29m\n",
      "step 00231/00500 (46.20%) | loss: 7.732835 | grad norm: 2.8598 | lrm: 1.00 | dt: 66.86ms | tok/sec: 1,914 | mfu: -1.00 | total time: 0.29m\n",
      "step 00232/00500 (46.40%) | loss: 7.700561 | grad norm: 2.6500 | lrm: 1.00 | dt: 70.32ms | tok/sec: 1,820 | mfu: -1.00 | total time: 0.29m\n",
      "step 00233/00500 (46.60%) | loss: 7.694735 | grad norm: 3.2207 | lrm: 1.00 | dt: 81.32ms | tok/sec: 1,574 | mfu: -1.00 | total time: 0.29m\n",
      "step 00234/00500 (46.80%) | loss: 7.645626 | grad norm: 2.5571 | lrm: 1.00 | dt: 77.06ms | tok/sec: 1,661 | mfu: -1.00 | total time: 0.29m\n",
      "step 00235/00500 (47.00%) | loss: 7.534223 | grad norm: 2.1460 | lrm: 1.00 | dt: 81.40ms | tok/sec: 1,572 | mfu: -1.00 | total time: 0.30m\n",
      "step 00236/00500 (47.20%) | loss: 7.567680 | grad norm: 4.0618 | lrm: 1.00 | dt: 78.54ms | tok/sec: 1,629 | mfu: -1.00 | total time: 0.30m\n",
      "step 00237/00500 (47.40%) | loss: 7.566630 | grad norm: 3.1559 | lrm: 1.00 | dt: 83.61ms | tok/sec: 1,530 | mfu: -1.00 | total time: 0.30m\n",
      "step 00238/00500 (47.60%) | loss: 7.508379 | grad norm: 2.9872 | lrm: 1.00 | dt: 79.06ms | tok/sec: 1,619 | mfu: -1.00 | total time: 0.30m\n",
      "step 00239/00500 (47.80%) | loss: 7.648722 | grad norm: 3.4181 | lrm: 1.00 | dt: 89.96ms | tok/sec: 1,422 | mfu: -1.00 | total time: 0.30m\n",
      "step 00240/00500 (48.00%) | loss: 7.765389 | grad norm: 2.9866 | lrm: 1.00 | dt: 65.24ms | tok/sec: 1,961 | mfu: -1.00 | total time: 0.30m\n",
      "step 00241/00500 (48.20%) | loss: 7.954927 | grad norm: 3.2556 | lrm: 1.00 | dt: 66.24ms | tok/sec: 1,932 | mfu: -1.00 | total time: 0.30m\n",
      "step 00242/00500 (48.40%) | loss: 7.920756 | grad norm: 3.1026 | lrm: 1.00 | dt: 67.78ms | tok/sec: 1,888 | mfu: -1.00 | total time: 0.30m\n",
      "step 00243/00500 (48.60%) | loss: 7.908564 | grad norm: 3.2288 | lrm: 1.00 | dt: 72.38ms | tok/sec: 1,768 | mfu: -1.00 | total time: 0.31m\n",
      "step 00244/00500 (48.80%) | loss: 7.915230 | grad norm: 2.6464 | lrm: 1.00 | dt: 76.59ms | tok/sec: 1,671 | mfu: -1.00 | total time: 0.31m\n",
      "step 00245/00500 (49.00%) | loss: 7.865210 | grad norm: 2.1939 | lrm: 1.00 | dt: 68.96ms | tok/sec: 1,856 | mfu: -1.00 | total time: 0.31m\n",
      "step 00246/00500 (49.20%) | loss: 7.837432 | grad norm: 2.3528 | lrm: 1.00 | dt: 65.68ms | tok/sec: 1,948 | mfu: -1.00 | total time: 0.31m\n",
      "step 00247/00500 (49.40%) | loss: 7.868995 | grad norm: 2.1728 | lrm: 1.00 | dt: 70.00ms | tok/sec: 1,828 | mfu: -1.00 | total time: 0.31m\n",
      "step 00248/00500 (49.60%) | loss: 7.861913 | grad norm: 2.4253 | lrm: 1.00 | dt: 69.33ms | tok/sec: 1,846 | mfu: -1.00 | total time: 0.31m\n",
      "step 00249/00500 (49.80%) | loss: 7.866329 | grad norm: 2.3613 | lrm: 1.00 | dt: 68.04ms | tok/sec: 1,881 | mfu: -1.00 | total time: 0.31m\n",
      "step 00250/00500 (50.00%) | loss: 7.880306 | grad norm: 1.9316 | lrm: 1.00 | dt: 69.43ms | tok/sec: 1,843 | mfu: -1.00 | total time: 0.31m\n",
      "step 00251/00500 (50.20%) | loss: 7.896172 | grad norm: 2.7047 | lrm: 1.00 | dt: 68.81ms | tok/sec: 1,860 | mfu: -1.00 | total time: 0.31m\n",
      "step 00252/00500 (50.40%) | loss: 7.916246 | grad norm: 2.1354 | lrm: 1.00 | dt: 71.10ms | tok/sec: 1,800 | mfu: -1.00 | total time: 0.32m\n",
      "step 00253/00500 (50.60%) | loss: 7.866217 | grad norm: 2.3071 | lrm: 1.00 | dt: 70.62ms | tok/sec: 1,812 | mfu: -1.00 | total time: 0.32m\n",
      "step 00254/00500 (50.80%) | loss: 7.878457 | grad norm: 2.4361 | lrm: 1.00 | dt: 69.87ms | tok/sec: 1,831 | mfu: -1.00 | total time: 0.32m\n",
      "step 00255/00500 (51.00%) | loss: 7.840868 | grad norm: 2.4935 | lrm: 1.00 | dt: 69.82ms | tok/sec: 1,833 | mfu: -1.00 | total time: 0.32m\n",
      "step 00256/00500 (51.20%) | loss: 7.843201 | grad norm: 2.4456 | lrm: 1.00 | dt: 67.01ms | tok/sec: 1,910 | mfu: -1.00 | total time: 0.32m\n",
      "step 00257/00500 (51.40%) | loss: 7.935329 | grad norm: 3.1676 | lrm: 1.00 | dt: 70.62ms | tok/sec: 1,812 | mfu: -1.00 | total time: 0.32m\n",
      "step 00258/00500 (51.60%) | loss: 7.933993 | grad norm: 1.9768 | lrm: 1.00 | dt: 71.41ms | tok/sec: 1,792 | mfu: -1.00 | total time: 0.32m\n",
      "step 00259/00500 (51.80%) | loss: 7.858497 | grad norm: 1.8263 | lrm: 1.00 | dt: 69.64ms | tok/sec: 1,838 | mfu: -1.00 | total time: 0.32m\n",
      "step 00260/00500 (52.00%) | loss: 7.871551 | grad norm: 2.6083 | lrm: 1.00 | dt: 67.67ms | tok/sec: 1,891 | mfu: -1.00 | total time: 0.33m\n",
      "step 00261/00500 (52.20%) | loss: 7.863416 | grad norm: 2.6475 | lrm: 1.00 | dt: 66.11ms | tok/sec: 1,936 | mfu: -1.00 | total time: 0.33m\n",
      "step 00262/00500 (52.40%) | loss: 7.956929 | grad norm: 3.2039 | lrm: 1.00 | dt: 72.66ms | tok/sec: 1,761 | mfu: -1.00 | total time: 0.33m\n",
      "step 00263/00500 (52.60%) | loss: 7.998784 | grad norm: 2.8979 | lrm: 1.00 | dt: 77.57ms | tok/sec: 1,650 | mfu: -1.00 | total time: 0.33m\n",
      "step 00264/00500 (52.80%) | loss: 8.043885 | grad norm: 2.5607 | lrm: 1.00 | dt: 72.40ms | tok/sec: 1,767 | mfu: -1.00 | total time: 0.33m\n",
      "step 00265/00500 (53.00%) | loss: 8.015746 | grad norm: 2.0033 | lrm: 1.00 | dt: 66.41ms | tok/sec: 1,927 | mfu: -1.00 | total time: 0.33m\n",
      "step 00266/00500 (53.20%) | loss: 7.961656 | grad norm: 2.7305 | lrm: 1.00 | dt: 68.17ms | tok/sec: 1,877 | mfu: -1.00 | total time: 0.33m\n",
      "step 00267/00500 (53.40%) | loss: 8.011340 | grad norm: 2.4683 | lrm: 1.00 | dt: 68.10ms | tok/sec: 1,879 | mfu: -1.00 | total time: 0.33m\n",
      "step 00268/00500 (53.60%) | loss: 8.086376 | grad norm: 3.2963 | lrm: 1.00 | dt: 69.33ms | tok/sec: 1,846 | mfu: -1.00 | total time: 0.33m\n",
      "step 00269/00500 (53.80%) | loss: 8.280146 | grad norm: 3.9084 | lrm: 1.00 | dt: 72.87ms | tok/sec: 1,756 | mfu: -1.00 | total time: 0.34m\n",
      "step 00270/00500 (54.00%) | loss: 8.293102 | grad norm: 4.5425 | lrm: 1.00 | dt: 69.90ms | tok/sec: 1,831 | mfu: -1.00 | total time: 0.34m\n",
      "step 00271/00500 (54.20%) | loss: 8.224838 | grad norm: 3.2153 | lrm: 1.00 | dt: 68.36ms | tok/sec: 1,872 | mfu: -1.00 | total time: 0.34m\n",
      "step 00272/00500 (54.40%) | loss: 8.175342 | grad norm: 1.9372 | lrm: 1.00 | dt: 73.43ms | tok/sec: 1,743 | mfu: -1.00 | total time: 0.34m\n",
      "step 00273/00500 (54.60%) | loss: 8.100481 | grad norm: 2.2239 | lrm: 1.00 | dt: 69.74ms | tok/sec: 1,835 | mfu: -1.00 | total time: 0.34m\n",
      "step 00274/00500 (54.80%) | loss: 8.088105 | grad norm: 2.0909 | lrm: 1.00 | dt: 74.23ms | tok/sec: 1,724 | mfu: -1.00 | total time: 0.34m\n",
      "step 00275/00500 (55.00%) | loss: 8.052746 | grad norm: 2.0327 | lrm: 1.00 | dt: 121.05ms | tok/sec: 1,057 | mfu: -1.00 | total time: 0.34m\n",
      "step 00276/00500 (55.20%) | loss: 8.002512 | grad norm: 2.0190 | lrm: 1.00 | dt: 71.25ms | tok/sec: 1,796 | mfu: -1.00 | total time: 0.35m\n",
      "step 00277/00500 (55.40%) | loss: 8.064055 | grad norm: 2.4838 | lrm: 1.00 | dt: 73.36ms | tok/sec: 1,744 | mfu: -1.00 | total time: 0.35m\n",
      "step 00278/00500 (55.60%) | loss: 8.053427 | grad norm: 1.7896 | lrm: 1.00 | dt: 65.97ms | tok/sec: 1,940 | mfu: -1.00 | total time: 0.35m\n",
      "step 00279/00500 (55.80%) | loss: 7.944281 | grad norm: 2.2089 | lrm: 1.00 | dt: 70.25ms | tok/sec: 1,822 | mfu: -1.00 | total time: 0.35m\n",
      "step 00280/00500 (56.00%) | loss: 7.955512 | grad norm: 2.1493 | lrm: 1.00 | dt: 74.74ms | tok/sec: 1,712 | mfu: -1.00 | total time: 0.35m\n",
      "step 00281/00500 (56.20%) | loss: 7.920300 | grad norm: 1.9301 | lrm: 1.00 | dt: 70.22ms | tok/sec: 1,822 | mfu: -1.00 | total time: 0.35m\n",
      "step 00282/00500 (56.40%) | loss: 7.860005 | grad norm: 1.8141 | lrm: 1.00 | dt: 71.62ms | tok/sec: 1,787 | mfu: -1.00 | total time: 0.35m\n",
      "step 00283/00500 (56.60%) | loss: 7.782966 | grad norm: 2.1626 | lrm: 1.00 | dt: 76.21ms | tok/sec: 1,679 | mfu: -1.00 | total time: 0.35m\n",
      "step 00284/00500 (56.80%) | loss: 7.730143 | grad norm: 2.1370 | lrm: 1.00 | dt: 69.32ms | tok/sec: 1,846 | mfu: -1.00 | total time: 0.35m\n",
      "step 00285/00500 (57.00%) | loss: 7.655753 | grad norm: 2.8127 | lrm: 1.00 | dt: 77.61ms | tok/sec: 1,649 | mfu: -1.00 | total time: 0.36m\n",
      "step 00286/00500 (57.20%) | loss: 7.594235 | grad norm: 1.7845 | lrm: 1.00 | dt: 74.82ms | tok/sec: 1,710 | mfu: -1.00 | total time: 0.36m\n",
      "step 00287/00500 (57.40%) | loss: 7.541590 | grad norm: 2.1695 | lrm: 1.00 | dt: 71.96ms | tok/sec: 1,778 | mfu: -1.00 | total time: 0.36m\n",
      "step 00288/00500 (57.60%) | loss: 7.403509 | grad norm: 1.9302 | lrm: 1.00 | dt: 73.66ms | tok/sec: 1,737 | mfu: -1.00 | total time: 0.36m\n",
      "step 00289/00500 (57.80%) | loss: 7.353679 | grad norm: 1.9870 | lrm: 1.00 | dt: 70.44ms | tok/sec: 1,817 | mfu: -1.00 | total time: 0.36m\n",
      "step 00290/00500 (58.00%) | loss: 7.318580 | grad norm: 2.0003 | lrm: 1.00 | dt: 74.22ms | tok/sec: 1,724 | mfu: -1.00 | total time: 0.36m\n",
      "step 00291/00500 (58.20%) | loss: 7.258792 | grad norm: 1.8071 | lrm: 1.00 | dt: 69.96ms | tok/sec: 1,829 | mfu: -1.00 | total time: 0.36m\n",
      "step 00292/00500 (58.40%) | loss: 7.280250 | grad norm: 2.6775 | lrm: 1.00 | dt: 66.56ms | tok/sec: 1,923 | mfu: -1.00 | total time: 0.36m\n",
      "step 00293/00500 (58.60%) | loss: 7.272463 | grad norm: 2.1666 | lrm: 1.00 | dt: 71.60ms | tok/sec: 1,787 | mfu: -1.00 | total time: 0.37m\n",
      "step 00294/00500 (58.80%) | loss: 7.358037 | grad norm: 1.7873 | lrm: 1.00 | dt: 73.87ms | tok/sec: 1,732 | mfu: -1.00 | total time: 0.37m\n",
      "step 00295/00500 (59.00%) | loss: 7.366842 | grad norm: 1.9333 | lrm: 1.00 | dt: 71.53ms | tok/sec: 1,789 | mfu: -1.00 | total time: 0.37m\n",
      "step 00296/00500 (59.20%) | loss: 7.350775 | grad norm: 1.8499 | lrm: 1.00 | dt: 74.36ms | tok/sec: 1,721 | mfu: -1.00 | total time: 0.37m\n",
      "step 00297/00500 (59.40%) | loss: 7.364811 | grad norm: 1.7533 | lrm: 1.00 | dt: 73.72ms | tok/sec: 1,736 | mfu: -1.00 | total time: 0.37m\n",
      "step 00298/00500 (59.60%) | loss: 7.414897 | grad norm: 1.8091 | lrm: 1.00 | dt: 71.93ms | tok/sec: 1,779 | mfu: -1.00 | total time: 0.37m\n",
      "step 00299/00500 (59.80%) | loss: 7.568434 | grad norm: 1.8867 | lrm: 1.00 | dt: 77.29ms | tok/sec: 1,656 | mfu: -1.00 | total time: 0.37m\n",
      "step 00300 | Validation bpb: 2.7355\n",
      "step 00300/00500 (60.00%) | loss: 7.614897 | grad norm: 2.0164 | lrm: 1.00 | dt: 71.57ms | tok/sec: 1,788 | mfu: -1.00 | total time: 0.37m\n",
      "step 00301/00500 (60.20%) | loss: 7.702436 | grad norm: 1.9789 | lrm: 1.00 | dt: 72.03ms | tok/sec: 1,777 | mfu: -1.00 | total time: 0.38m\n",
      "step 00302/00500 (60.40%) | loss: 7.744550 | grad norm: 2.4270 | lrm: 1.00 | dt: 68.42ms | tok/sec: 1,870 | mfu: -1.00 | total time: 0.38m\n",
      "step 00303/00500 (60.60%) | loss: 7.704748 | grad norm: 2.2324 | lrm: 1.00 | dt: 73.27ms | tok/sec: 1,746 | mfu: -1.00 | total time: 0.38m\n",
      "step 00304/00500 (60.80%) | loss: 7.837411 | grad norm: 2.7555 | lrm: 1.00 | dt: 68.65ms | tok/sec: 1,864 | mfu: -1.00 | total time: 0.38m\n",
      "step 00305/00500 (61.00%) | loss: 7.824866 | grad norm: 1.9541 | lrm: 1.00 | dt: 65.42ms | tok/sec: 1,956 | mfu: -1.00 | total time: 0.38m\n",
      "step 00306/00500 (61.20%) | loss: 7.814585 | grad norm: 1.9996 | lrm: 1.00 | dt: 70.22ms | tok/sec: 1,822 | mfu: -1.00 | total time: 0.38m\n",
      "step 00307/00500 (61.40%) | loss: 7.836470 | grad norm: 1.4571 | lrm: 1.00 | dt: 78.15ms | tok/sec: 1,637 | mfu: -1.00 | total time: 0.38m\n",
      "step 00308/00500 (61.60%) | loss: 7.936641 | grad norm: 1.8444 | lrm: 1.00 | dt: 74.93ms | tok/sec: 1,708 | mfu: -1.00 | total time: 0.38m\n",
      "step 00309/00500 (61.80%) | loss: 7.986009 | grad norm: 2.1342 | lrm: 1.00 | dt: 79.02ms | tok/sec: 1,619 | mfu: -1.00 | total time: 0.38m\n",
      "step 00310/00500 (62.00%) | loss: 7.993966 | grad norm: 3.0365 | lrm: 1.00 | dt: 71.69ms | tok/sec: 1,785 | mfu: -1.00 | total time: 0.39m\n",
      "step 00311/00500 (62.20%) | loss: 7.955422 | grad norm: 2.3337 | lrm: 1.00 | dt: 85.20ms | tok/sec: 1,502 | mfu: -1.00 | total time: 0.39m\n",
      "step 00312/00500 (62.40%) | loss: 7.986874 | grad norm: 2.7070 | lrm: 1.00 | dt: 64.62ms | tok/sec: 1,980 | mfu: -1.00 | total time: 0.39m\n",
      "step 00313/00500 (62.60%) | loss: 7.945388 | grad norm: 2.1748 | lrm: 1.00 | dt: 69.06ms | tok/sec: 1,853 | mfu: -1.00 | total time: 0.39m\n",
      "step 00314/00500 (62.80%) | loss: 7.871918 | grad norm: 2.4793 | lrm: 1.00 | dt: 70.86ms | tok/sec: 1,806 | mfu: -1.00 | total time: 0.39m\n",
      "step 00315/00500 (63.00%) | loss: 7.830608 | grad norm: 1.8517 | lrm: 1.00 | dt: 73.50ms | tok/sec: 1,741 | mfu: -1.00 | total time: 0.39m\n",
      "step 00316/00500 (63.20%) | loss: 7.776630 | grad norm: 2.3869 | lrm: 1.00 | dt: 68.47ms | tok/sec: 1,869 | mfu: -1.00 | total time: 0.39m\n",
      "step 00317/00500 (63.40%) | loss: 7.710724 | grad norm: 1.9758 | lrm: 1.00 | dt: 70.99ms | tok/sec: 1,803 | mfu: -1.00 | total time: 0.39m\n",
      "step 00318/00500 (63.60%) | loss: 7.762873 | grad norm: 2.4269 | lrm: 1.00 | dt: 74.17ms | tok/sec: 1,725 | mfu: -1.00 | total time: 0.40m\n",
      "step 00319/00500 (63.80%) | loss: 7.827814 | grad norm: 1.9862 | lrm: 1.00 | dt: 73.06ms | tok/sec: 1,752 | mfu: -1.00 | total time: 0.40m\n",
      "step 00320/00500 (64.00%) | loss: 7.827855 | grad norm: 1.7530 | lrm: 1.00 | dt: 73.53ms | tok/sec: 1,740 | mfu: -1.00 | total time: 0.40m\n",
      "step 00321/00500 (64.20%) | loss: 7.826088 | grad norm: 1.7043 | lrm: 1.00 | dt: 70.56ms | tok/sec: 1,814 | mfu: -1.00 | total time: 0.40m\n",
      "step 00322/00500 (64.40%) | loss: 7.788007 | grad norm: 1.6905 | lrm: 1.00 | dt: 78.43ms | tok/sec: 1,632 | mfu: -1.00 | total time: 0.40m\n",
      "step 00323/00500 (64.60%) | loss: 7.723681 | grad norm: 2.3233 | lrm: 1.00 | dt: 82.13ms | tok/sec: 1,558 | mfu: -1.00 | total time: 0.40m\n",
      "step 00324/00500 (64.80%) | loss: 7.681364 | grad norm: 1.7185 | lrm: 1.00 | dt: 90.20ms | tok/sec: 1,419 | mfu: -1.00 | total time: 0.40m\n",
      "step 00325/00500 (65.00%) | loss: 7.644346 | grad norm: 1.9710 | lrm: 1.00 | dt: 81.94ms | tok/sec: 1,562 | mfu: -1.00 | total time: 0.40m\n",
      "step 00326/00500 (65.20%) | loss: 7.688292 | grad norm: 2.5499 | lrm: 1.00 | dt: 72.14ms | tok/sec: 1,774 | mfu: -1.00 | total time: 0.41m\n",
      "step 00327/00500 (65.40%) | loss: 7.695880 | grad norm: 2.5059 | lrm: 1.00 | dt: 415.87ms | tok/sec: 307 | mfu: -1.00 | total time: 0.41m\n",
      "step 00328/00500 (65.60%) | loss: 7.736264 | grad norm: 1.8787 | lrm: 1.00 | dt: 95.81ms | tok/sec: 1,336 | mfu: -1.00 | total time: 0.41m\n",
      "step 00329/00500 (65.80%) | loss: 7.767367 | grad norm: 2.3874 | lrm: 1.00 | dt: 79.35ms | tok/sec: 1,613 | mfu: -1.00 | total time: 0.42m\n",
      "step 00330/00500 (66.00%) | loss: 7.809086 | grad norm: 2.2286 | lrm: 1.00 | dt: 83.00ms | tok/sec: 1,542 | mfu: -1.00 | total time: 0.42m\n",
      "step 00331/00500 (66.20%) | loss: 7.878901 | grad norm: 2.1345 | lrm: 1.00 | dt: 122.57ms | tok/sec: 1,044 | mfu: -1.00 | total time: 0.42m\n",
      "step 00332/00500 (66.40%) | loss: 7.843244 | grad norm: 2.1574 | lrm: 1.00 | dt: 222.35ms | tok/sec: 575 | mfu: -1.00 | total time: 0.42m\n",
      "step 00333/00500 (66.60%) | loss: 7.855476 | grad norm: 1.5821 | lrm: 1.00 | dt: 193.84ms | tok/sec: 660 | mfu: -1.00 | total time: 0.43m\n",
      "step 00334/00500 (66.80%) | loss: 7.822815 | grad norm: 1.7924 | lrm: 1.00 | dt: 133.90ms | tok/sec: 955 | mfu: -1.00 | total time: 0.43m\n",
      "step 00335/00500 (67.00%) | loss: 7.811390 | grad norm: 1.6491 | lrm: 1.00 | dt: 129.61ms | tok/sec: 987 | mfu: -1.00 | total time: 0.43m\n",
      "step 00336/00500 (67.20%) | loss: 7.718742 | grad norm: 2.7055 | lrm: 1.00 | dt: 75.59ms | tok/sec: 1,693 | mfu: -1.00 | total time: 0.43m\n",
      "step 00337/00500 (67.40%) | loss: 7.638691 | grad norm: 1.7983 | lrm: 1.00 | dt: 126.07ms | tok/sec: 1,015 | mfu: -1.00 | total time: 0.43m\n",
      "step 00338/00500 (67.60%) | loss: 7.508575 | grad norm: 1.9352 | lrm: 1.00 | dt: 69.91ms | tok/sec: 1,830 | mfu: -1.00 | total time: 0.44m\n",
      "step 00339/00500 (67.80%) | loss: 7.392104 | grad norm: 1.5713 | lrm: 1.00 | dt: 70.53ms | tok/sec: 1,814 | mfu: -1.00 | total time: 0.44m\n",
      "step 00340/00500 (68.00%) | loss: 7.254657 | grad norm: 1.6415 | lrm: 1.00 | dt: 142.01ms | tok/sec: 901 | mfu: -1.00 | total time: 0.44m\n",
      "step 00341/00500 (68.20%) | loss: 7.361197 | grad norm: 2.6500 | lrm: 1.00 | dt: 108.24ms | tok/sec: 1,182 | mfu: -1.00 | total time: 0.44m\n",
      "step 00342/00500 (68.40%) | loss: 7.379384 | grad norm: 2.0795 | lrm: 1.00 | dt: 108.42ms | tok/sec: 1,180 | mfu: -1.00 | total time: 0.44m\n",
      "step 00343/00500 (68.60%) | loss: 7.390335 | grad norm: 1.8528 | lrm: 1.00 | dt: 78.49ms | tok/sec: 1,630 | mfu: -1.00 | total time: 0.44m\n",
      "step 00344/00500 (68.80%) | loss: 7.345336 | grad norm: 2.1121 | lrm: 1.00 | dt: 91.56ms | tok/sec: 1,397 | mfu: -1.00 | total time: 0.45m\n",
      "step 00345/00500 (69.00%) | loss: 7.301844 | grad norm: 1.9962 | lrm: 1.00 | dt: 117.19ms | tok/sec: 1,092 | mfu: -1.00 | total time: 0.45m\n",
      "step 00346/00500 (69.20%) | loss: 7.301886 | grad norm: 2.0124 | lrm: 1.00 | dt: 74.41ms | tok/sec: 1,720 | mfu: -1.00 | total time: 0.45m\n",
      "step 00347/00500 (69.40%) | loss: 7.347222 | grad norm: 2.4079 | lrm: 1.00 | dt: 69.19ms | tok/sec: 1,850 | mfu: -1.00 | total time: 0.45m\n",
      "step 00348/00500 (69.60%) | loss: 7.354447 | grad norm: 2.2688 | lrm: 1.00 | dt: 78.22ms | tok/sec: 1,636 | mfu: -1.00 | total time: 0.45m\n",
      "step 00349/00500 (69.80%) | loss: 7.376518 | grad norm: 1.6313 | lrm: 1.00 | dt: 69.20ms | tok/sec: 1,849 | mfu: -1.00 | total time: 0.45m\n",
      "step 00350/00500 (70.00%) | loss: 7.356071 | grad norm: 2.3132 | lrm: 1.00 | dt: 68.05ms | tok/sec: 1,880 | mfu: -1.00 | total time: 0.45m\n",
      "step 00351/00500 (70.20%) | loss: 7.335531 | grad norm: 1.6251 | lrm: 1.00 | dt: 69.75ms | tok/sec: 1,835 | mfu: -1.00 | total time: 0.45m\n",
      "step 00352/00500 (70.40%) | loss: 7.365758 | grad norm: 2.5213 | lrm: 1.00 | dt: 68.90ms | tok/sec: 1,857 | mfu: -1.00 | total time: 0.46m\n",
      "step 00353/00500 (70.60%) | loss: 7.367500 | grad norm: 1.7562 | lrm: 1.00 | dt: 67.57ms | tok/sec: 1,894 | mfu: -1.00 | total time: 0.46m\n",
      "step 00354/00500 (70.80%) | loss: 7.355189 | grad norm: 1.4875 | lrm: 1.00 | dt: 67.92ms | tok/sec: 1,884 | mfu: -1.00 | total time: 0.46m\n",
      "step 00355/00500 (71.00%) | loss: 7.416304 | grad norm: 5.5819 | lrm: 1.00 | dt: 76.84ms | tok/sec: 1,665 | mfu: -1.00 | total time: 0.46m\n",
      "step 00356/00500 (71.20%) | loss: 7.523553 | grad norm: 2.1157 | lrm: 1.00 | dt: 66.25ms | tok/sec: 1,932 | mfu: -1.00 | total time: 0.46m\n",
      "step 00357/00500 (71.40%) | loss: 7.471830 | grad norm: 3.0083 | lrm: 1.00 | dt: 70.56ms | tok/sec: 1,814 | mfu: -1.00 | total time: 0.46m\n",
      "step 00358/00500 (71.60%) | loss: 7.424183 | grad norm: 1.9065 | lrm: 1.00 | dt: 71.75ms | tok/sec: 1,783 | mfu: -1.00 | total time: 0.46m\n",
      "step 00359/00500 (71.80%) | loss: 7.475222 | grad norm: 1.8736 | lrm: 1.00 | dt: 72.86ms | tok/sec: 1,756 | mfu: -1.00 | total time: 0.46m\n",
      "step 00360/00500 (72.00%) | loss: 7.503182 | grad norm: 4.5343 | lrm: 1.00 | dt: 80.50ms | tok/sec: 1,590 | mfu: -1.00 | total time: 0.46m\n",
      "step 00361/00500 (72.20%) | loss: 7.531358 | grad norm: 1.8501 | lrm: 1.00 | dt: 71.85ms | tok/sec: 1,781 | mfu: -1.00 | total time: 0.47m\n",
      "step 00362/00500 (72.40%) | loss: 7.597787 | grad norm: 1.9964 | lrm: 1.00 | dt: 68.75ms | tok/sec: 1,861 | mfu: -1.00 | total time: 0.47m\n",
      "step 00363/00500 (72.60%) | loss: 7.587651 | grad norm: 1.6492 | lrm: 1.00 | dt: 65.52ms | tok/sec: 1,953 | mfu: -1.00 | total time: 0.47m\n",
      "step 00364/00500 (72.80%) | loss: 7.592065 | grad norm: 2.0709 | lrm: 1.00 | dt: 72.48ms | tok/sec: 1,766 | mfu: -1.00 | total time: 0.47m\n",
      "step 00365/00500 (73.00%) | loss: 7.525371 | grad norm: 1.4526 | lrm: 1.00 | dt: 70.41ms | tok/sec: 1,818 | mfu: -1.00 | total time: 0.47m\n",
      "step 00366/00500 (73.20%) | loss: 7.580817 | grad norm: 2.0292 | lrm: 1.00 | dt: 69.55ms | tok/sec: 1,840 | mfu: -1.00 | total time: 0.47m\n",
      "step 00367/00500 (73.40%) | loss: 7.587823 | grad norm: 2.3104 | lrm: 1.00 | dt: 70.03ms | tok/sec: 1,827 | mfu: -1.00 | total time: 0.47m\n",
      "step 00368/00500 (73.60%) | loss: 7.709098 | grad norm: 3.1334 | lrm: 1.00 | dt: 68.78ms | tok/sec: 1,860 | mfu: -1.00 | total time: 0.47m\n",
      "step 00369/00500 (73.80%) | loss: 7.727017 | grad norm: 1.8503 | lrm: 1.00 | dt: 80.26ms | tok/sec: 1,594 | mfu: -1.00 | total time: 0.48m\n",
      "step 00370/00500 (74.00%) | loss: 7.688342 | grad norm: 1.8804 | lrm: 1.00 | dt: 81.16ms | tok/sec: 1,577 | mfu: -1.00 | total time: 0.48m\n",
      "step 00371/00500 (74.20%) | loss: 7.661497 | grad norm: 2.0552 | lrm: 1.00 | dt: 79.22ms | tok/sec: 1,615 | mfu: -1.00 | total time: 0.48m\n",
      "step 00372/00500 (74.40%) | loss: 7.610395 | grad norm: 5.4566 | lrm: 1.00 | dt: 71.21ms | tok/sec: 1,797 | mfu: -1.00 | total time: 0.48m\n",
      "step 00373/00500 (74.60%) | loss: 7.597583 | grad norm: 3.6731 | lrm: 1.00 | dt: 69.96ms | tok/sec: 1,829 | mfu: -1.00 | total time: 0.48m\n",
      "step 00374/00500 (74.80%) | loss: 7.626966 | grad norm: 2.1544 | lrm: 1.00 | dt: 82.52ms | tok/sec: 1,551 | mfu: -1.00 | total time: 0.48m\n",
      "step 00375/00500 (75.00%) | loss: 7.606153 | grad norm: 1.8745 | lrm: 1.00 | dt: 78.61ms | tok/sec: 1,628 | mfu: -1.00 | total time: 0.48m\n",
      "step 00376/00500 (75.20%) | loss: 7.557061 | grad norm: 2.0735 | lrm: 1.00 | dt: 84.94ms | tok/sec: 1,506 | mfu: -1.00 | total time: 0.48m\n",
      "step 00377/00500 (75.40%) | loss: 7.561460 | grad norm: 1.8216 | lrm: 1.00 | dt: 87.20ms | tok/sec: 1,467 | mfu: -1.00 | total time: 0.49m\n",
      "step 00378/00500 (75.60%) | loss: 7.628591 | grad norm: 2.7997 | lrm: 1.00 | dt: 101.99ms | tok/sec: 1,254 | mfu: -1.00 | total time: 0.49m\n",
      "step 00379/00500 (75.80%) | loss: 7.633312 | grad norm: 2.0034 | lrm: 1.00 | dt: 83.45ms | tok/sec: 1,533 | mfu: -1.00 | total time: 0.49m\n",
      "step 00380/00500 (76.00%) | loss: 7.623931 | grad norm: 1.7775 | lrm: 1.00 | dt: 93.95ms | tok/sec: 1,362 | mfu: -1.00 | total time: 0.49m\n",
      "step 00381/00500 (76.20%) | loss: 7.590719 | grad norm: 1.4546 | lrm: 1.00 | dt: 75.95ms | tok/sec: 1,685 | mfu: -1.00 | total time: 0.49m\n",
      "step 00382/00500 (76.40%) | loss: 7.595290 | grad norm: 1.7145 | lrm: 1.00 | dt: 84.99ms | tok/sec: 1,506 | mfu: -1.00 | total time: 0.49m\n",
      "step 00383/00500 (76.60%) | loss: 7.627600 | grad norm: 1.5061 | lrm: 1.00 | dt: 110.90ms | tok/sec: 1,154 | mfu: -1.00 | total time: 0.50m\n",
      "step 00384/00500 (76.80%) | loss: 7.565845 | grad norm: 2.5411 | lrm: 1.00 | dt: 71.16ms | tok/sec: 1,798 | mfu: -1.00 | total time: 0.50m\n",
      "step 00385/00500 (77.00%) | loss: 7.584006 | grad norm: 3.9927 | lrm: 1.00 | dt: 65.49ms | tok/sec: 1,954 | mfu: -1.00 | total time: 0.50m\n",
      "step 00386/00500 (77.20%) | loss: 7.573780 | grad norm: 1.5601 | lrm: 1.00 | dt: 64.47ms | tok/sec: 1,985 | mfu: -1.00 | total time: 0.50m\n",
      "step 00387/00500 (77.40%) | loss: 7.636190 | grad norm: 1.6220 | lrm: 1.00 | dt: 65.40ms | tok/sec: 1,957 | mfu: -1.00 | total time: 0.50m\n",
      "step 00388/00500 (77.60%) | loss: 7.643923 | grad norm: 1.8225 | lrm: 1.00 | dt: 66.42ms | tok/sec: 1,927 | mfu: -1.00 | total time: 0.50m\n",
      "step 00389/00500 (77.80%) | loss: 7.578824 | grad norm: 1.6857 | lrm: 1.00 | dt: 67.29ms | tok/sec: 1,902 | mfu: -1.00 | total time: 0.50m\n",
      "step 00390/00500 (78.00%) | loss: 7.605218 | grad norm: 1.5797 | lrm: 1.00 | dt: 64.91ms | tok/sec: 1,971 | mfu: -1.00 | total time: 0.50m\n",
      "step 00391/00500 (78.20%) | loss: 7.657625 | grad norm: 1.7594 | lrm: 1.00 | dt: 73.40ms | tok/sec: 1,743 | mfu: -1.00 | total time: 0.50m\n",
      "step 00392/00500 (78.40%) | loss: 7.689469 | grad norm: 1.8110 | lrm: 1.00 | dt: 69.89ms | tok/sec: 1,831 | mfu: -1.00 | total time: 0.51m\n",
      "step 00393/00500 (78.60%) | loss: 7.761372 | grad norm: 3.1235 | lrm: 1.00 | dt: 73.39ms | tok/sec: 1,744 | mfu: -1.00 | total time: 0.51m\n",
      "step 00394/00500 (78.80%) | loss: 7.783902 | grad norm: 1.7529 | lrm: 1.00 | dt: 89.71ms | tok/sec: 1,426 | mfu: -1.00 | total time: 0.51m\n",
      "step 00395/00500 (79.00%) | loss: 7.810158 | grad norm: 1.9348 | lrm: 1.00 | dt: 77.25ms | tok/sec: 1,657 | mfu: -1.00 | total time: 0.51m\n",
      "step 00396/00500 (79.20%) | loss: 7.774266 | grad norm: 2.5222 | lrm: 1.00 | dt: 73.23ms | tok/sec: 1,747 | mfu: -1.00 | total time: 0.51m\n",
      "step 00397/00500 (79.40%) | loss: 7.789851 | grad norm: 1.8928 | lrm: 1.00 | dt: 79.07ms | tok/sec: 1,618 | mfu: -1.00 | total time: 0.51m\n",
      "step 00398/00500 (79.60%) | loss: 7.807999 | grad norm: 1.4819 | lrm: 1.00 | dt: 78.63ms | tok/sec: 1,627 | mfu: -1.00 | total time: 0.51m\n",
      "step 00399/00500 (79.80%) | loss: 7.833021 | grad norm: 2.5424 | lrm: 1.00 | dt: 76.93ms | tok/sec: 1,663 | mfu: -1.00 | total time: 0.51m\n",
      "step 00400 | Validation bpb: 2.6808\n",
      "step 00400/00500 (80.00%) | loss: 7.832767 | grad norm: 2.3142 | lrm: 1.00 | dt: 68.75ms | tok/sec: 1,861 | mfu: -1.00 | total time: 0.52m\n",
      "step 00401/00500 (80.20%) | loss: 7.760051 | grad norm: 2.1505 | lrm: 0.99 | dt: 67.85ms | tok/sec: 1,886 | mfu: -1.00 | total time: 0.52m\n",
      "step 00402/00500 (80.40%) | loss: 7.770276 | grad norm: 1.5417 | lrm: 0.98 | dt: 66.30ms | tok/sec: 1,930 | mfu: -1.00 | total time: 0.52m\n",
      "step 00403/00500 (80.60%) | loss: 7.816846 | grad norm: 1.7036 | lrm: 0.97 | dt: 82.34ms | tok/sec: 1,554 | mfu: -1.00 | total time: 0.52m\n",
      "step 00404/00500 (80.80%) | loss: 7.856260 | grad norm: 1.7004 | lrm: 0.96 | dt: 73.06ms | tok/sec: 1,751 | mfu: -1.00 | total time: 0.52m\n",
      "step 00405/00500 (81.00%) | loss: 7.802546 | grad norm: 1.8912 | lrm: 0.95 | dt: 77.97ms | tok/sec: 1,641 | mfu: -1.00 | total time: 0.52m\n",
      "step 00406/00500 (81.20%) | loss: 7.847551 | grad norm: 2.1090 | lrm: 0.94 | dt: 74.69ms | tok/sec: 1,713 | mfu: -1.00 | total time: 0.52m\n",
      "step 00407/00500 (81.40%) | loss: 7.839204 | grad norm: 1.9210 | lrm: 0.93 | dt: 70.42ms | tok/sec: 1,817 | mfu: -1.00 | total time: 0.52m\n",
      "step 00408/00500 (81.60%) | loss: 7.850733 | grad norm: 1.5381 | lrm: 0.92 | dt: 73.03ms | tok/sec: 1,752 | mfu: -1.00 | total time: 0.53m\n",
      "step 00409/00500 (81.80%) | loss: 7.839751 | grad norm: 1.4945 | lrm: 0.91 | dt: 77.66ms | tok/sec: 1,648 | mfu: -1.00 | total time: 0.53m\n",
      "step 00410/00500 (82.00%) | loss: 7.882227 | grad norm: 1.6325 | lrm: 0.90 | dt: 74.62ms | tok/sec: 1,715 | mfu: -1.00 | total time: 0.53m\n",
      "step 00411/00500 (82.20%) | loss: 7.899013 | grad norm: 1.6829 | lrm: 0.89 | dt: 73.32ms | tok/sec: 1,745 | mfu: -1.00 | total time: 0.53m\n",
      "step 00412/00500 (82.40%) | loss: 7.883021 | grad norm: 1.6437 | lrm: 0.88 | dt: 71.76ms | tok/sec: 1,783 | mfu: -1.00 | total time: 0.53m\n",
      "step 00413/00500 (82.60%) | loss: 7.880196 | grad norm: 3.9787 | lrm: 0.87 | dt: 75.66ms | tok/sec: 1,691 | mfu: -1.00 | total time: 0.53m\n",
      "step 00414/00500 (82.80%) | loss: 7.923624 | grad norm: 1.5514 | lrm: 0.86 | dt: 81.50ms | tok/sec: 1,570 | mfu: -1.00 | total time: 0.53m\n",
      "step 00415/00500 (83.00%) | loss: 7.943980 | grad norm: 1.2596 | lrm: 0.85 | dt: 88.30ms | tok/sec: 1,449 | mfu: -1.00 | total time: 0.53m\n",
      "step 00416/00500 (83.20%) | loss: 7.922086 | grad norm: 2.5077 | lrm: 0.84 | dt: 72.52ms | tok/sec: 1,765 | mfu: -1.00 | total time: 0.54m\n",
      "step 00417/00500 (83.40%) | loss: 7.894677 | grad norm: 1.7663 | lrm: 0.83 | dt: 98.62ms | tok/sec: 1,297 | mfu: -1.00 | total time: 0.54m\n",
      "step 00418/00500 (83.60%) | loss: 7.887119 | grad norm: 1.5500 | lrm: 0.82 | dt: 67.85ms | tok/sec: 1,886 | mfu: -1.00 | total time: 0.54m\n",
      "step 00419/00500 (83.80%) | loss: 7.872538 | grad norm: 1.8655 | lrm: 0.81 | dt: 68.43ms | tok/sec: 1,870 | mfu: -1.00 | total time: 0.54m\n",
      "step 00420/00500 (84.00%) | loss: 7.887113 | grad norm: 1.6600 | lrm: 0.80 | dt: 69.36ms | tok/sec: 1,845 | mfu: -1.00 | total time: 0.54m\n",
      "step 00421/00500 (84.20%) | loss: 7.899959 | grad norm: 1.7843 | lrm: 0.79 | dt: 69.62ms | tok/sec: 1,838 | mfu: -1.00 | total time: 0.54m\n",
      "step 00422/00500 (84.40%) | loss: 7.850831 | grad norm: 1.5422 | lrm: 0.78 | dt: 72.56ms | tok/sec: 1,763 | mfu: -1.00 | total time: 0.54m\n",
      "step 00423/00500 (84.60%) | loss: 7.816970 | grad norm: 1.7401 | lrm: 0.77 | dt: 73.27ms | tok/sec: 1,746 | mfu: -1.00 | total time: 0.54m\n",
      "step 00424/00500 (84.80%) | loss: 7.775979 | grad norm: 1.5891 | lrm: 0.76 | dt: 69.45ms | tok/sec: 1,843 | mfu: -1.00 | total time: 0.55m\n",
      "step 00425/00500 (85.00%) | loss: 7.824991 | grad norm: 2.4362 | lrm: 0.75 | dt: 78.04ms | tok/sec: 1,640 | mfu: -1.00 | total time: 0.55m\n",
      "step 00426/00500 (85.20%) | loss: 7.826214 | grad norm: 4.2578 | lrm: 0.74 | dt: 79.19ms | tok/sec: 1,616 | mfu: -1.00 | total time: 0.55m\n",
      "step 00427/00500 (85.40%) | loss: 7.808309 | grad norm: 1.5059 | lrm: 0.73 | dt: 74.85ms | tok/sec: 1,709 | mfu: -1.00 | total time: 0.55m\n",
      "step 00428/00500 (85.60%) | loss: 7.725552 | grad norm: 1.2263 | lrm: 0.72 | dt: 72.44ms | tok/sec: 1,766 | mfu: -1.00 | total time: 0.55m\n",
      "step 00429/00500 (85.80%) | loss: 7.695582 | grad norm: 2.1987 | lrm: 0.71 | dt: 74.11ms | tok/sec: 1,727 | mfu: -1.00 | total time: 0.55m\n",
      "step 00430/00500 (86.00%) | loss: 7.692456 | grad norm: 1.7090 | lrm: 0.70 | dt: 75.90ms | tok/sec: 1,686 | mfu: -1.00 | total time: 0.55m\n",
      "step 00431/00500 (86.20%) | loss: 7.684467 | grad norm: 1.5855 | lrm: 0.69 | dt: 73.75ms | tok/sec: 1,735 | mfu: -1.00 | total time: 0.55m\n",
      "step 00432/00500 (86.40%) | loss: 7.630748 | grad norm: 2.2405 | lrm: 0.68 | dt: 74.69ms | tok/sec: 1,713 | mfu: -1.00 | total time: 0.56m\n",
      "step 00433/00500 (86.60%) | loss: 7.540293 | grad norm: 1.5405 | lrm: 0.67 | dt: 73.90ms | tok/sec: 1,731 | mfu: -1.00 | total time: 0.56m\n",
      "step 00434/00500 (86.80%) | loss: 7.552474 | grad norm: 1.3899 | lrm: 0.66 | dt: 73.24ms | tok/sec: 1,747 | mfu: -1.00 | total time: 0.56m\n",
      "step 00435/00500 (87.00%) | loss: 7.489806 | grad norm: 3.8621 | lrm: 0.65 | dt: 74.28ms | tok/sec: 1,723 | mfu: -1.00 | total time: 0.56m\n",
      "step 00436/00500 (87.20%) | loss: 7.469231 | grad norm: 1.9449 | lrm: 0.64 | dt: 77.37ms | tok/sec: 1,654 | mfu: -1.00 | total time: 0.56m\n",
      "step 00437/00500 (87.40%) | loss: 7.421137 | grad norm: 1.5563 | lrm: 0.63 | dt: 80.11ms | tok/sec: 1,597 | mfu: -1.00 | total time: 0.56m\n",
      "step 00438/00500 (87.60%) | loss: 7.285001 | grad norm: 1.5494 | lrm: 0.62 | dt: 73.86ms | tok/sec: 1,732 | mfu: -1.00 | total time: 0.56m\n",
      "step 00439/00500 (87.80%) | loss: 7.368731 | grad norm: 1.5575 | lrm: 0.61 | dt: 82.37ms | tok/sec: 1,554 | mfu: -1.00 | total time: 0.56m\n",
      "step 00440/00500 (88.00%) | loss: 7.566934 | grad norm: 2.7546 | lrm: 0.60 | dt: 75.36ms | tok/sec: 1,698 | mfu: -1.00 | total time: 0.57m\n",
      "step 00441/00500 (88.20%) | loss: 7.651530 | grad norm: 4.6903 | lrm: 0.59 | dt: 80.31ms | tok/sec: 1,593 | mfu: -1.00 | total time: 0.57m\n",
      "step 00442/00500 (88.40%) | loss: 7.678194 | grad norm: 1.8413 | lrm: 0.58 | dt: 70.34ms | tok/sec: 1,819 | mfu: -1.00 | total time: 0.57m\n",
      "step 00443/00500 (88.60%) | loss: 7.759003 | grad norm: 1.6222 | lrm: 0.57 | dt: 78.83ms | tok/sec: 1,623 | mfu: -1.00 | total time: 0.57m\n",
      "step 00444/00500 (88.80%) | loss: 7.786559 | grad norm: 2.1894 | lrm: 0.56 | dt: 77.76ms | tok/sec: 1,646 | mfu: -1.00 | total time: 0.57m\n",
      "step 00445/00500 (89.00%) | loss: 7.796894 | grad norm: 2.8123 | lrm: 0.55 | dt: 76.64ms | tok/sec: 1,670 | mfu: -1.00 | total time: 0.57m\n",
      "step 00446/00500 (89.20%) | loss: 7.748937 | grad norm: 1.9157 | lrm: 0.54 | dt: 78.62ms | tok/sec: 1,628 | mfu: -1.00 | total time: 0.57m\n",
      "step 00447/00500 (89.40%) | loss: 7.822552 | grad norm: 2.3096 | lrm: 0.53 | dt: 74.68ms | tok/sec: 1,714 | mfu: -1.00 | total time: 0.57m\n",
      "step 00448/00500 (89.60%) | loss: 7.886032 | grad norm: 1.8361 | lrm: 0.52 | dt: 73.42ms | tok/sec: 1,743 | mfu: -1.00 | total time: 0.58m\n",
      "step 00449/00500 (89.80%) | loss: 7.930895 | grad norm: 2.2775 | lrm: 0.51 | dt: 73.50ms | tok/sec: 1,741 | mfu: -1.00 | total time: 0.58m\n",
      "step 00450/00500 (90.00%) | loss: 8.005934 | grad norm: 2.7574 | lrm: 0.50 | dt: 74.82ms | tok/sec: 1,710 | mfu: -1.00 | total time: 0.58m\n",
      "step 00451/00500 (90.20%) | loss: 8.144789 | grad norm: 2.8383 | lrm: 0.49 | dt: 74.81ms | tok/sec: 1,710 | mfu: -1.00 | total time: 0.58m\n",
      "step 00452/00500 (90.40%) | loss: 8.183875 | grad norm: 3.0756 | lrm: 0.48 | dt: 66.14ms | tok/sec: 1,935 | mfu: -1.00 | total time: 0.58m\n",
      "step 00453/00500 (90.60%) | loss: 8.186822 | grad norm: 2.5217 | lrm: 0.47 | dt: 74.27ms | tok/sec: 1,723 | mfu: -1.00 | total time: 0.58m\n",
      "step 00454/00500 (90.80%) | loss: 8.186287 | grad norm: 1.8369 | lrm: 0.46 | dt: 69.36ms | tok/sec: 1,845 | mfu: -1.00 | total time: 0.58m\n",
      "step 00455/00500 (91.00%) | loss: 8.210711 | grad norm: 1.8723 | lrm: 0.45 | dt: 73.89ms | tok/sec: 1,732 | mfu: -1.00 | total time: 0.58m\n",
      "step 00456/00500 (91.20%) | loss: 8.146213 | grad norm: 2.2555 | lrm: 0.44 | dt: 68.66ms | tok/sec: 1,864 | mfu: -1.00 | total time: 0.59m\n",
      "step 00457/00500 (91.40%) | loss: 8.155197 | grad norm: 1.5515 | lrm: 0.43 | dt: 73.14ms | tok/sec: 1,750 | mfu: -1.00 | total time: 0.59m\n",
      "step 00458/00500 (91.60%) | loss: 8.109940 | grad norm: 1.6797 | lrm: 0.42 | dt: 80.07ms | tok/sec: 1,598 | mfu: -1.00 | total time: 0.59m\n",
      "step 00459/00500 (91.80%) | loss: 8.054486 | grad norm: 1.8722 | lrm: 0.41 | dt: 75.31ms | tok/sec: 1,699 | mfu: -1.00 | total time: 0.59m\n",
      "step 00460/00500 (92.00%) | loss: 8.055642 | grad norm: 1.7536 | lrm: 0.40 | dt: 71.52ms | tok/sec: 1,789 | mfu: -1.00 | total time: 0.59m\n",
      "step 00461/00500 (92.20%) | loss: 8.060342 | grad norm: 2.0530 | lrm: 0.39 | dt: 82.11ms | tok/sec: 1,558 | mfu: -1.00 | total time: 0.59m\n",
      "step 00462/00500 (92.40%) | loss: 8.011327 | grad norm: 1.7916 | lrm: 0.38 | dt: 77.46ms | tok/sec: 1,652 | mfu: -1.00 | total time: 0.59m\n",
      "step 00463/00500 (92.60%) | loss: 8.031220 | grad norm: 1.6695 | lrm: 0.37 | dt: 68.04ms | tok/sec: 1,881 | mfu: -1.00 | total time: 0.59m\n",
      "step 00464/00500 (92.80%) | loss: 7.997338 | grad norm: 1.9387 | lrm: 0.36 | dt: 70.55ms | tok/sec: 1,814 | mfu: -1.00 | total time: 0.60m\n",
      "step 00465/00500 (93.00%) | loss: 7.967751 | grad norm: 4.0444 | lrm: 0.35 | dt: 73.58ms | tok/sec: 1,739 | mfu: -1.00 | total time: 0.60m\n",
      "step 00466/00500 (93.20%) | loss: 7.928831 | grad norm: 1.6452 | lrm: 0.34 | dt: 71.98ms | tok/sec: 1,778 | mfu: -1.00 | total time: 0.60m\n",
      "step 00467/00500 (93.40%) | loss: 7.864448 | grad norm: 1.3589 | lrm: 0.33 | dt: 71.34ms | tok/sec: 1,794 | mfu: -1.00 | total time: 0.60m\n",
      "step 00468/00500 (93.60%) | loss: 7.756088 | grad norm: 1.8189 | lrm: 0.32 | dt: 78.35ms | tok/sec: 1,633 | mfu: -1.00 | total time: 0.60m\n",
      "step 00469/00500 (93.80%) | loss: 7.693064 | grad norm: 1.3697 | lrm: 0.31 | dt: 72.17ms | tok/sec: 1,773 | mfu: -1.00 | total time: 0.60m\n",
      "step 00470/00500 (94.00%) | loss: 7.612652 | grad norm: 1.5907 | lrm: 0.30 | dt: 73.75ms | tok/sec: 1,735 | mfu: -1.00 | total time: 0.60m\n",
      "step 00471/00500 (94.20%) | loss: 7.550028 | grad norm: 1.4906 | lrm: 0.29 | dt: 76.31ms | tok/sec: 1,677 | mfu: -1.00 | total time: 0.60m\n",
      "step 00472/00500 (94.40%) | loss: 7.537699 | grad norm: 1.9036 | lrm: 0.28 | dt: 70.54ms | tok/sec: 1,814 | mfu: -1.00 | total time: 0.61m\n",
      "step 00473/00500 (94.60%) | loss: 7.493582 | grad norm: 1.5698 | lrm: 0.27 | dt: 70.58ms | tok/sec: 1,813 | mfu: -1.00 | total time: 0.61m\n",
      "step 00474/00500 (94.80%) | loss: 7.462062 | grad norm: 1.6669 | lrm: 0.26 | dt: 77.79ms | tok/sec: 1,645 | mfu: -1.00 | total time: 0.61m\n",
      "step 00475/00500 (95.00%) | loss: 7.560171 | grad norm: 2.0641 | lrm: 0.25 | dt: 68.15ms | tok/sec: 1,878 | mfu: -1.00 | total time: 0.61m\n",
      "step 00476/00500 (95.20%) | loss: 7.611117 | grad norm: 1.6253 | lrm: 0.24 | dt: 73.07ms | tok/sec: 1,751 | mfu: -1.00 | total time: 0.61m\n",
      "step 00477/00500 (95.40%) | loss: 7.564993 | grad norm: 1.5650 | lrm: 0.23 | dt: 217.90ms | tok/sec: 587 | mfu: -1.00 | total time: 0.61m\n",
      "step 00478/00500 (95.60%) | loss: 7.591728 | grad norm: 1.4811 | lrm: 0.22 | dt: 178.28ms | tok/sec: 717 | mfu: -1.00 | total time: 0.62m\n",
      "step 00479/00500 (95.80%) | loss: 7.618337 | grad norm: 1.5425 | lrm: 0.21 | dt: 161.45ms | tok/sec: 792 | mfu: -1.00 | total time: 0.62m\n",
      "step 00480/00500 (96.00%) | loss: 7.588040 | grad norm: 1.7013 | lrm: 0.20 | dt: 170.46ms | tok/sec: 750 | mfu: -1.00 | total time: 0.62m\n",
      "step 00481/00500 (96.20%) | loss: 7.577343 | grad norm: 1.5552 | lrm: 0.19 | dt: 67.03ms | tok/sec: 1,909 | mfu: -1.00 | total time: 0.62m\n",
      "step 00482/00500 (96.40%) | loss: 7.641484 | grad norm: 1.8438 | lrm: 0.18 | dt: 117.92ms | tok/sec: 1,085 | mfu: -1.00 | total time: 0.63m\n",
      "step 00483/00500 (96.60%) | loss: 7.631179 | grad norm: 1.5137 | lrm: 0.17 | dt: 142.74ms | tok/sec: 896 | mfu: -1.00 | total time: 0.63m\n",
      "step 00484/00500 (96.80%) | loss: 7.637001 | grad norm: 1.7437 | lrm: 0.16 | dt: 75.01ms | tok/sec: 1,706 | mfu: -1.00 | total time: 0.63m\n",
      "step 00485/00500 (97.00%) | loss: 7.582509 | grad norm: 2.3321 | lrm: 0.15 | dt: 68.31ms | tok/sec: 1,873 | mfu: -1.00 | total time: 0.63m\n",
      "step 00486/00500 (97.20%) | loss: 7.519006 | grad norm: 1.7825 | lrm: 0.14 | dt: 67.88ms | tok/sec: 1,885 | mfu: -1.00 | total time: 0.63m\n",
      "step 00487/00500 (97.40%) | loss: 7.514487 | grad norm: 1.6645 | lrm: 0.13 | dt: 67.93ms | tok/sec: 1,884 | mfu: -1.00 | total time: 0.63m\n",
      "step 00488/00500 (97.60%) | loss: 7.466664 | grad norm: 1.8204 | lrm: 0.12 | dt: 72.46ms | tok/sec: 1,766 | mfu: -1.00 | total time: 0.63m\n",
      "step 00489/00500 (97.80%) | loss: 7.494924 | grad norm: 1.5742 | lrm: 0.11 | dt: 73.04ms | tok/sec: 1,752 | mfu: -1.00 | total time: 0.63m\n",
      "step 00490/00500 (98.00%) | loss: 7.572274 | grad norm: 1.5495 | lrm: 0.10 | dt: 68.14ms | tok/sec: 1,878 | mfu: -1.00 | total time: 0.64m\n",
      "step 00491/00500 (98.20%) | loss: 7.588960 | grad norm: 1.4833 | lrm: 0.09 | dt: 74.15ms | tok/sec: 1,726 | mfu: -1.00 | total time: 0.64m\n",
      "step 00492/00500 (98.40%) | loss: 7.643925 | grad norm: 1.7241 | lrm: 0.08 | dt: 71.24ms | tok/sec: 1,796 | mfu: -1.00 | total time: 0.64m\n",
      "step 00493/00500 (98.60%) | loss: 7.690709 | grad norm: 1.5936 | lrm: 0.07 | dt: 73.76ms | tok/sec: 1,735 | mfu: -1.00 | total time: 0.64m\n",
      "step 00494/00500 (98.80%) | loss: 7.612015 | grad norm: 2.3215 | lrm: 0.06 | dt: 74.11ms | tok/sec: 1,727 | mfu: -1.00 | total time: 0.64m\n",
      "step 00495/00500 (99.00%) | loss: 7.636248 | grad norm: 1.3357 | lrm: 0.05 | dt: 70.35ms | tok/sec: 1,819 | mfu: -1.00 | total time: 0.64m\n",
      "step 00496/00500 (99.20%) | loss: 7.607473 | grad norm: 1.7336 | lrm: 0.04 | dt: 69.47ms | tok/sec: 1,842 | mfu: -1.00 | total time: 0.64m\n",
      "step 00497/00500 (99.40%) | loss: 7.571398 | grad norm: 1.5508 | lrm: 0.03 | dt: 73.92ms | tok/sec: 1,731 | mfu: -1.00 | total time: 0.64m\n",
      "step 00498/00500 (99.60%) | loss: 7.548290 | grad norm: 1.7146 | lrm: 0.02 | dt: 75.30ms | tok/sec: 1,699 | mfu: -1.00 | total time: 0.65m\n",
      "step 00499/00500 (99.80%) | loss: 7.522972 | grad norm: 2.0845 | lrm: 0.01 | dt: 74.05ms | tok/sec: 1,728 | mfu: -1.00 | total time: 0.65m\n",
      "step 00500 | Validation bpb: 2.6093\n",
      "<|bos|>The capital of France is not be a body of the body of the body\n",
      "<|bos|>The chemical symbol of gold is the body of the body of the body of the\n",
      "<|bos|>If yesterday was Friday, then tomorrow will be a body of the body of the body of the\n",
      "<|bos|>The opposite of hot is a body of the body of the body of the\n",
      "<|bos|>The planets of the solar system are: the the the the the body of the body of\n",
      "<|bos|>My favorite color is the body.\n",
      "The body of the body of the\n",
      "<|bos|>If 5*x + 3 = 13, then x is a body and the body and the body of the\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/model_000500.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/meta_000500.json\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4/optim_000500_rank0.pt\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.65m\n",
      "Minimum validation bpb: 2.6093\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_train \\\n",
    "    --depth=4 \\\n",
    "    --max_seq_len=128 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --num_iterations=500 \\\n",
    "    --total_batch_size=128 \\\n",
    "    --eval_every=100 \\\n",
    "    --eval_tokens=1280 \\\n",
    "    --core_metric_every=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a5431-30f2-49ce-b5cd-0da2dc40f3b9",
   "metadata": {},
   "source": [
    "^ looks good. Confirm can load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9f9dff8-1ed6-428a-a512-0f22dd86c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_checkpoint_manager import load_model\n",
    "from my_nanochat.my_common import compute_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12cb0435-1f2f-4a4e-b7d0-f776040bd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, device = compute_init(device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5a551b1-b384-4240-b49b-1ee11d71c780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4 with step 500\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, meta_data = load_model('base', model_tag='d4', device=device, phase='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae5930eb-868f-4596-bc9f-c402b824cc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(65536, 256)\n",
       "    (h): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (c_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (c_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=65536, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bb6857f-750a-4af5-9fe9-b0368e817f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 500,\n",
       " 'val_bpb': 2.6093299752526367,\n",
       " 'model_config': {'sequence_len': 128,\n",
       "  'vocab_size': 65536,\n",
       "  'n_layer': 4,\n",
       "  'n_head': 2,\n",
       "  'n_kv_head': 2,\n",
       "  'n_embd': 256},\n",
       " 'user_config': {'run': 'dummy',\n",
       "  'device_type': '',\n",
       "  'depth': 4,\n",
       "  'max_seq_len': 128,\n",
       "  'num_iterations': 500,\n",
       "  'target_param_data_ratio': 20,\n",
       "  'device_batch_size': 1,\n",
       "  'total_batch_size': 128,\n",
       "  'embedding_lr': 0.2,\n",
       "  'unembedding_lr': 0.004,\n",
       "  'weight_decay': 0.0,\n",
       "  'matrix_lr': 0.02,\n",
       "  'grad_clip': 1.0,\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmdown_ratio': 0.2,\n",
       "  'final_lr_frac': 0.0,\n",
       "  'eval_every': 100,\n",
       "  'eval_tokens': 1280,\n",
       "  'core_metric_every': 0,\n",
       "  'core_metric_max_per_task': 500,\n",
       "  'sample_every': 2000,\n",
       "  'model_tag': ''},\n",
       " 'device_batch_size': 1,\n",
       " 'max_seq_len': 128}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb925a76-d4f2-4e57-ab48-406eac584365",
   "metadata": {},
   "source": [
    "^ looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4e2f642-c21a-45e2-b0ba-e8efa416e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding model_tag = d4\n",
      "overriding num_iterations = 10\n",
      "overriding max_seq_len = 128\n",
      "overriding device_batch_size = 1\n",
      "overriding total_batch_size = 128\n",
      "overriding eval_tokens = 1280\n",
      "user_config: {'run': 'dummy', 'device_type': '', 'dtype': 'bfloat16', 'num_iterations': 10, 'max_seq_len': 128, 'device_batch_size': 1, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'init_lr_frac': 1.0, 'weight_decay': 0.0, 'eval_every': 150, 'eval_tokens': 1280, 'total_batch_size': 128, 'dry_run': 0}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4 with step 500\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n",
      "Tokens / micro-batch / rank: 1 x 128 = 128\n",
      "Tokens / micro-batch: 128\n",
      "Total batch size 128 => gradient accumulation steps: 1\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(256/768) = 1.7320508075688774\n",
      "step 00000 | Validation bpb: 2.1492\n",
      "step 00001 (20.00%) | loss: 4.377713 | lrm: 1.00 | dt: 779.52ms | tok/sec: 164 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002 (30.00%) | loss: 5.784250 | lrm: 1.00 | dt: 23.53ms | tok/sec: 5,439 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003 (40.00%) | loss: 6.181152 | lrm: 1.00 | dt: 22.38ms | tok/sec: 5,718 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004 (50.00%) | loss: 6.357811 | lrm: 1.00 | dt: 24.94ms | tok/sec: 5,132 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 (60.00%) | loss: 6.510358 | lrm: 1.00 | dt: 25.06ms | tok/sec: 5,107 | mfu: -1.00 | total time: 0.00m\n",
      "step 00006 (70.00%) | loss: 6.568862 | lrm: 1.00 | dt: 27.87ms | tok/sec: 4,591 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007 (80.00%) | loss: 6.644528 | lrm: 1.00 | dt: 26.88ms | tok/sec: 4,762 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008 (90.00%) | loss: 6.806477 | lrm: 0.50 | dt: 28.52ms | tok/sec: 4,487 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009 (100.00%) | loss: 6.824842 | lrm: 0.00 | dt: 24.23ms | tok/sec: 5,282 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009 | Validation bpb: 2.1994\n",
      "saved model to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d4/model_000009.pt\n",
      "saved metadata to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d4/meta_000009.json\n",
      "saved optimizer to /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d4/optim_000009_rank0.pt\n",
      "Peak memory usage: 0.00MiB\n",
      "Total training time: 0.00m\n",
      "Minimum validation bpb: 2.1492\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_mid_train \\\n",
    "    --model_tag=d4 \\\n",
    "    --num_iterations=10 \\\n",
    "    --max_seq_len=128 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --total_batch_size=128 \\\n",
    "    --eval_tokens=1280"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85118cc-df27-4b74-b9bb-ce2750e1378d",
   "metadata": {},
   "source": [
    "^ seems to work. Can we load the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c01e97b-da74-47b7-9cb8-00c6389803f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d4 with step 9\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_checkpoint_manager import load_model\n",
    "from my_nanochat.my_common import compute_init\n",
    "_, _, _, _, device = compute_init(device_type)\n",
    "model, tokenizer, meta_data = load_model('mid', model_tag='d4', device=device, phase='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a08a7451-1668-4cb6-8280-88ad0174173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(65536, 256)\n",
       "    (h): ModuleList(\n",
       "      (0-3): 4 x Block(\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (c_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (c_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (c_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=65536, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae282800-ab1b-4537-9f4b-3f530f8327a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 9,\n",
       " 'val_bpb': 2.1993844218554024,\n",
       " 'model_config': {'sequence_len': 128,\n",
       "  'vocab_size': 65536,\n",
       "  'n_layer': 4,\n",
       "  'n_head': 2,\n",
       "  'n_kv_head': 2,\n",
       "  'n_embd': 256},\n",
       " 'user_config': {'run': 'dummy',\n",
       "  'device_type': '',\n",
       "  'dtype': 'bfloat16',\n",
       "  'num_iterations': 10,\n",
       "  'max_seq_len': 128,\n",
       "  'device_batch_size': 1,\n",
       "  'unembedding_lr': 0.004,\n",
       "  'embedding_lr': 0.2,\n",
       "  'matrix_lr': 0.02,\n",
       "  'init_lr_frac': 1.0,\n",
       "  'weight_decay': 0.0,\n",
       "  'eval_every': 150,\n",
       "  'eval_tokens': 1280,\n",
       "  'total_batch_size': 128,\n",
       "  'dry_run': 0},\n",
       " 'device_batch_size': 1}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a904a2f-71e2-458f-9186-32141f4407d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 491, 332, 717, 651, 4432, 351, 348, 51801, 44]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(model.generate(tokenizer.encode('Hello', prepend=tokenizer.get_bos_token_id()), max_tokens=10))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0aa23e7-5491-4339-8ddf-4c984ce7a799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', which that would use ign an you Prospect,'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec569b-4b4e-40a5-a792-62243b1e4419",
   "metadata": {},
   "source": [
    "Now try running without specifying num_iterations. It will try to go through all the data which will take a long time so I'll interrupt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4dfa24a8-3df2-469c-96fe-ddb3cb0111f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overriding model_tag = d4\n",
      "overriding max_seq_len = 128\n",
      "overriding device_batch_size = 1\n",
      "overriding total_batch_size = 128\n",
      "overriding eval_tokens = 1280\n",
      "user_config: {'run': 'dummy', 'device_type': '', 'dtype': 'bfloat16', 'num_iterations': -1, 'max_seq_len': 128, 'device_batch_size': 1, 'unembedding_lr': 0.004, 'embedding_lr': 0.2, 'matrix_lr': 0.02, 'init_lr_frac': 1.0, 'weight_decay': 0.0, 'eval_every': 150, 'eval_tokens': 1280, 'total_batch_size': 128, 'dry_run': 0}\n",
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4 with step 500\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n",
      "Tokens / micro-batch / rank: 1 x 128 = 128\n",
      "Tokens / micro-batch: 128\n",
      "Total batch size 128 => gradient accumulation steps: 1\n",
      "Scaling the LR for the AdamW parameters proportional to 1/sqrt(256/768) = 1.7320508075688774\n",
      "step 00000 | Validation bpb: 2.1492\n",
      "step 00001 (0.00%) | loss: 4.377713 | lrm: 1.00 | dt: 808.67ms | tok/sec: 158 | mfu: -1.00 | total time: 0.00m\n",
      "step 00002 (0.00%) | loss: 5.784250 | lrm: 1.00 | dt: 23.03ms | tok/sec: 5,558 | mfu: -1.00 | total time: 0.00m\n",
      "step 00003 (0.00%) | loss: 6.181158 | lrm: 1.00 | dt: 29.73ms | tok/sec: 4,305 | mfu: -1.00 | total time: 0.00m\n",
      "step 00004 (0.00%) | loss: 6.357839 | lrm: 1.00 | dt: 21.97ms | tok/sec: 5,825 | mfu: -1.00 | total time: 0.00m\n",
      "step 00005 (0.00%) | loss: 6.510349 | lrm: 1.00 | dt: 22.80ms | tok/sec: 5,614 | mfu: -1.00 | total time: 0.00m\n",
      "step 00006 (0.00%) | loss: 6.568741 | lrm: 1.00 | dt: 25.03ms | tok/sec: 5,114 | mfu: -1.00 | total time: 0.00m\n",
      "step 00007 (0.00%) | loss: 6.644434 | lrm: 1.00 | dt: 24.52ms | tok/sec: 5,220 | mfu: -1.00 | total time: 0.00m\n",
      "step 00008 (0.00%) | loss: 6.806570 | lrm: 1.00 | dt: 26.64ms | tok/sec: 4,805 | mfu: -1.00 | total time: 0.00m\n",
      "step 00009 (0.00%) | loss: 6.813468 | lrm: 1.00 | dt: 30.73ms | tok/sec: 4,165 | mfu: -1.00 | total time: 0.00m\n",
      "step 00010 (0.00%) | loss: 6.827560 | lrm: 1.00 | dt: 23.91ms | tok/sec: 5,352 | mfu: -1.00 | total time: 0.00m\n",
      "step 00011 (0.00%) | loss: 6.895758 | lrm: 1.00 | dt: 26.43ms | tok/sec: 4,842 | mfu: -1.00 | total time: 0.00m\n",
      "step 00012 (0.00%) | loss: 6.867060 | lrm: 1.00 | dt: 29.87ms | tok/sec: 4,285 | mfu: -1.00 | total time: 0.00m\n",
      "step 00013 (0.00%) | loss: 7.067229 | lrm: 1.00 | dt: 26.00ms | tok/sec: 4,923 | mfu: -1.00 | total time: 0.00m\n",
      "step 00014 (0.00%) | loss: 7.368410 | lrm: 1.00 | dt: 26.76ms | tok/sec: 4,783 | mfu: -1.00 | total time: 0.00m\n",
      "step 00015 (0.00%) | loss: 7.601434 | lrm: 1.00 | dt: 30.99ms | tok/sec: 4,129 | mfu: -1.00 | total time: 0.00m\n",
      "step 00016 (0.00%) | loss: 7.782771 | lrm: 1.00 | dt: 26.22ms | tok/sec: 4,880 | mfu: -1.00 | total time: 0.00m\n",
      "step 00017 (0.00%) | loss: 7.766834 | lrm: 1.00 | dt: 26.31ms | tok/sec: 4,865 | mfu: -1.00 | total time: 0.00m\n",
      "step 00018 (0.00%) | loss: 7.765856 | lrm: 1.00 | dt: 27.03ms | tok/sec: 4,734 | mfu: -1.00 | total time: 0.00m\n",
      "step 00019 (0.00%) | loss: 7.752368 | lrm: 1.00 | dt: 26.75ms | tok/sec: 4,785 | mfu: -1.00 | total time: 0.00m\n",
      "step 00020 (0.00%) | loss: 7.661104 | lrm: 1.00 | dt: 27.63ms | tok/sec: 4,633 | mfu: -1.00 | total time: 0.00m\n",
      "step 00021 (0.00%) | loss: 7.673993 | lrm: 1.00 | dt: 27.93ms | tok/sec: 4,583 | mfu: -1.00 | total time: 0.01m\n",
      "step 00022 (0.00%) | loss: 7.619923 | lrm: 1.00 | dt: 26.66ms | tok/sec: 4,801 | mfu: -1.00 | total time: 0.01m\n",
      "step 00023 (0.00%) | loss: 7.544600 | lrm: 1.00 | dt: 26.37ms | tok/sec: 4,854 | mfu: -1.00 | total time: 0.01m\n",
      "step 00024 (0.00%) | loss: 7.578959 | lrm: 1.00 | dt: 30.04ms | tok/sec: 4,260 | mfu: -1.00 | total time: 0.01m\n",
      "step 00025 (0.00%) | loss: 7.580330 | lrm: 1.00 | dt: 31.11ms | tok/sec: 4,114 | mfu: -1.00 | total time: 0.01m\n",
      "step 00026 (0.00%) | loss: 7.571072 | lrm: 1.00 | dt: 29.24ms | tok/sec: 4,376 | mfu: -1.00 | total time: 0.01m\n",
      "step 00027 (0.00%) | loss: 7.587141 | lrm: 1.00 | dt: 23.96ms | tok/sec: 5,342 | mfu: -1.00 | total time: 0.01m\n",
      "step 00028 (0.00%) | loss: 7.551010 | lrm: 1.00 | dt: 24.19ms | tok/sec: 5,292 | mfu: -1.00 | total time: 0.01m\n",
      "step 00029 (0.00%) | loss: 7.575055 | lrm: 1.00 | dt: 25.85ms | tok/sec: 4,952 | mfu: -1.00 | total time: 0.01m\n",
      "step 00030 (0.00%) | loss: 7.547261 | lrm: 1.00 | dt: 23.35ms | tok/sec: 5,482 | mfu: -1.00 | total time: 0.01m\n",
      "step 00031 (0.00%) | loss: 7.426802 | lrm: 1.00 | dt: 29.93ms | tok/sec: 4,276 | mfu: -1.00 | total time: 0.01m\n",
      "step 00032 (0.00%) | loss: 7.451909 | lrm: 1.00 | dt: 32.07ms | tok/sec: 3,991 | mfu: -1.00 | total time: 0.01m\n",
      "step 00033 (0.00%) | loss: 7.583192 | lrm: 1.00 | dt: 45.66ms | tok/sec: 2,803 | mfu: -1.00 | total time: 0.01m\n",
      "step 00034 (0.00%) | loss: 7.636773 | lrm: 1.00 | dt: 24.00ms | tok/sec: 5,333 | mfu: -1.00 | total time: 0.01m\n",
      "step 00035 (0.00%) | loss: 7.675192 | lrm: 1.00 | dt: 24.55ms | tok/sec: 5,214 | mfu: -1.00 | total time: 0.01m\n",
      "step 00036 (0.00%) | loss: 7.639672 | lrm: 1.00 | dt: 26.77ms | tok/sec: 4,781 | mfu: -1.00 | total time: 0.01m\n",
      "step 00037 (0.00%) | loss: 7.588655 | lrm: 1.00 | dt: 26.21ms | tok/sec: 4,884 | mfu: -1.00 | total time: 0.01m\n",
      "step 00038 (0.00%) | loss: 7.595273 | lrm: 1.00 | dt: 27.50ms | tok/sec: 4,654 | mfu: -1.00 | total time: 0.01m\n",
      "step 00039 (0.00%) | loss: 7.576464 | lrm: 1.00 | dt: 30.14ms | tok/sec: 4,246 | mfu: -1.00 | total time: 0.01m\n",
      "step 00040 (0.00%) | loss: 7.587204 | lrm: 1.00 | dt: 25.16ms | tok/sec: 5,087 | mfu: -1.00 | total time: 0.01m\n",
      "step 00041 (0.00%) | loss: 7.545850 | lrm: 1.00 | dt: 25.93ms | tok/sec: 4,935 | mfu: -1.00 | total time: 0.01m\n",
      "step 00042 (0.00%) | loss: 7.552369 | lrm: 1.00 | dt: 26.47ms | tok/sec: 4,835 | mfu: -1.00 | total time: 0.01m\n",
      "step 00043 (0.00%) | loss: 7.590673 | lrm: 1.00 | dt: 26.75ms | tok/sec: 4,784 | mfu: -1.00 | total time: 0.02m\n",
      "step 00044 (0.00%) | loss: 7.500980 | lrm: 1.00 | dt: 26.92ms | tok/sec: 4,754 | mfu: -1.00 | total time: 0.02m\n",
      "step 00045 (0.00%) | loss: 7.518200 | lrm: 1.00 | dt: 25.36ms | tok/sec: 5,047 | mfu: -1.00 | total time: 0.02m\n",
      "step 00046 (0.00%) | loss: 7.483243 | lrm: 1.00 | dt: 26.08ms | tok/sec: 4,907 | mfu: -1.00 | total time: 0.02m\n",
      "step 00047 (0.00%) | loss: 7.548516 | lrm: 1.00 | dt: 27.82ms | tok/sec: 4,600 | mfu: -1.00 | total time: 0.02m\n",
      "step 00048 (0.00%) | loss: 7.558773 | lrm: 1.00 | dt: 25.59ms | tok/sec: 5,001 | mfu: -1.00 | total time: 0.02m\n",
      "step 00049 (0.00%) | loss: 7.532440 | lrm: 1.00 | dt: 26.31ms | tok/sec: 4,864 | mfu: -1.00 | total time: 0.02m\n",
      "step 00050 (0.00%) | loss: 7.507749 | lrm: 1.00 | dt: 31.17ms | tok/sec: 4,106 | mfu: -1.00 | total time: 0.02m\n",
      "step 00051 (0.00%) | loss: 7.425878 | lrm: 1.00 | dt: 26.03ms | tok/sec: 4,916 | mfu: -1.00 | total time: 0.02m\n",
      "step 00052 (0.00%) | loss: 7.375792 | lrm: 1.00 | dt: 26.29ms | tok/sec: 4,869 | mfu: -1.00 | total time: 0.02m\n",
      "step 00053 (0.00%) | loss: 7.361030 | lrm: 1.00 | dt: 27.35ms | tok/sec: 4,680 | mfu: -1.00 | total time: 0.02m\n",
      "step 00054 (0.00%) | loss: 7.391145 | lrm: 1.00 | dt: 26.88ms | tok/sec: 4,761 | mfu: -1.00 | total time: 0.02m\n",
      "step 00055 (0.00%) | loss: 7.392553 | lrm: 1.00 | dt: 26.49ms | tok/sec: 4,831 | mfu: -1.00 | total time: 0.02m\n",
      "step 00056 (0.00%) | loss: 7.337386 | lrm: 1.00 | dt: 26.67ms | tok/sec: 4,799 | mfu: -1.00 | total time: 0.02m\n",
      "step 00057 (0.00%) | loss: 7.329477 | lrm: 1.00 | dt: 26.70ms | tok/sec: 4,794 | mfu: -1.00 | total time: 0.02m\n",
      "step 00058 (0.00%) | loss: 7.224087 | lrm: 1.00 | dt: 26.20ms | tok/sec: 4,886 | mfu: -1.00 | total time: 0.02m\n",
      "step 00059 (0.00%) | loss: 7.214602 | lrm: 1.00 | dt: 28.39ms | tok/sec: 4,508 | mfu: -1.00 | total time: 0.02m\n",
      "step 00060 (0.00%) | loss: 7.122129 | lrm: 1.00 | dt: 26.55ms | tok/sec: 4,820 | mfu: -1.00 | total time: 0.02m\n",
      "step 00061 (0.00%) | loss: 7.106663 | lrm: 1.00 | dt: 27.78ms | tok/sec: 4,608 | mfu: -1.00 | total time: 0.02m\n",
      "step 00062 (0.00%) | loss: 7.023548 | lrm: 1.00 | dt: 30.41ms | tok/sec: 4,209 | mfu: -1.00 | total time: 0.02m\n",
      "step 00063 (0.00%) | loss: 7.012540 | lrm: 1.00 | dt: 18.71ms | tok/sec: 6,840 | mfu: -1.00 | total time: 0.02m\n",
      "step 00064 (0.00%) | loss: 6.973059 | lrm: 1.00 | dt: 25.33ms | tok/sec: 5,053 | mfu: -1.00 | total time: 0.02m\n",
      "step 00065 (0.00%) | loss: 6.830130 | lrm: 1.00 | dt: 32.36ms | tok/sec: 3,955 | mfu: -1.00 | total time: 0.03m\n",
      "step 00066 (0.00%) | loss: 6.818039 | lrm: 1.00 | dt: 25.29ms | tok/sec: 5,061 | mfu: -1.00 | total time: 0.03m\n",
      "step 00067 (0.00%) | loss: 6.826413 | lrm: 1.00 | dt: 30.64ms | tok/sec: 4,176 | mfu: -1.00 | total time: 0.03m\n",
      "step 00068 (0.00%) | loss: 6.789983 | lrm: 1.00 | dt: 22.03ms | tok/sec: 5,810 | mfu: -1.00 | total time: 0.03m\n",
      "step 00069 (0.00%) | loss: 6.725821 | lrm: 1.00 | dt: 21.85ms | tok/sec: 5,858 | mfu: -1.00 | total time: 0.03m\n",
      "step 00070 (0.00%) | loss: 6.643837 | lrm: 1.00 | dt: 45.96ms | tok/sec: 2,785 | mfu: -1.00 | total time: 0.03m\n",
      "step 00071 (0.00%) | loss: 6.624256 | lrm: 1.00 | dt: 34.21ms | tok/sec: 3,741 | mfu: -1.00 | total time: 0.03m\n",
      "step 00072 (0.00%) | loss: 6.624316 | lrm: 1.00 | dt: 26.22ms | tok/sec: 4,880 | mfu: -1.00 | total time: 0.03m\n",
      "step 00073 (0.00%) | loss: 6.534344 | lrm: 1.00 | dt: 23.81ms | tok/sec: 5,376 | mfu: -1.00 | total time: 0.03m\n",
      "step 00074 (0.00%) | loss: 6.524466 | lrm: 1.00 | dt: 23.98ms | tok/sec: 5,337 | mfu: -1.00 | total time: 0.03m\n",
      "step 00075 (0.00%) | loss: 6.466658 | lrm: 1.00 | dt: 28.13ms | tok/sec: 4,550 | mfu: -1.00 | total time: 0.03m\n",
      "step 00076 (0.00%) | loss: 6.331657 | lrm: 1.00 | dt: 28.53ms | tok/sec: 4,486 | mfu: -1.00 | total time: 0.03m\n",
      "step 00077 (0.00%) | loss: 6.293018 | lrm: 1.00 | dt: 30.75ms | tok/sec: 4,162 | mfu: -1.00 | total time: 0.03m\n",
      "step 00078 (0.00%) | loss: 6.330402 | lrm: 1.00 | dt: 29.90ms | tok/sec: 4,281 | mfu: -1.00 | total time: 0.03m\n",
      "step 00079 (0.00%) | loss: 6.416519 | lrm: 1.00 | dt: 29.00ms | tok/sec: 4,413 | mfu: -1.00 | total time: 0.03m\n",
      "step 00080 (0.00%) | loss: 6.517276 | lrm: 1.00 | dt: 28.87ms | tok/sec: 4,433 | mfu: -1.00 | total time: 0.03m\n",
      "step 00081 (0.00%) | loss: 6.590842 | lrm: 1.00 | dt: 27.83ms | tok/sec: 4,599 | mfu: -1.00 | total time: 0.03m\n",
      "step 00082 (0.00%) | loss: 6.737115 | lrm: 1.00 | dt: 29.09ms | tok/sec: 4,399 | mfu: -1.00 | total time: 0.03m\n",
      "step 00083 (0.00%) | loss: 6.759639 | lrm: 1.00 | dt: 24.82ms | tok/sec: 5,156 | mfu: -1.00 | total time: 0.03m\n",
      "step 00084 (0.00%) | loss: 6.868386 | lrm: 1.00 | dt: 24.35ms | tok/sec: 5,256 | mfu: -1.00 | total time: 0.03m\n",
      "step 00085 (0.00%) | loss: 7.017303 | lrm: 1.00 | dt: 25.05ms | tok/sec: 5,109 | mfu: -1.00 | total time: 0.03m\n",
      "step 00086 (0.00%) | loss: 7.093188 | lrm: 1.00 | dt: 25.88ms | tok/sec: 4,946 | mfu: -1.00 | total time: 0.03m\n",
      "step 00087 (0.00%) | loss: 7.053732 | lrm: 1.00 | dt: 24.88ms | tok/sec: 5,144 | mfu: -1.00 | total time: 0.04m\n",
      "step 00088 (0.00%) | loss: 6.986007 | lrm: 1.00 | dt: 25.02ms | tok/sec: 5,116 | mfu: -1.00 | total time: 0.04m\n",
      "step 00089 (0.00%) | loss: 6.901516 | lrm: 1.00 | dt: 27.39ms | tok/sec: 4,673 | mfu: -1.00 | total time: 0.04m\n",
      "step 00090 (0.00%) | loss: 6.737245 | lrm: 1.00 | dt: 27.85ms | tok/sec: 4,595 | mfu: -1.00 | total time: 0.04m\n",
      "step 00091 (0.00%) | loss: 6.525273 | lrm: 1.00 | dt: 22.47ms | tok/sec: 5,696 | mfu: -1.00 | total time: 0.04m\n",
      "step 00092 (0.00%) | loss: 6.438055 | lrm: 1.00 | dt: 24.13ms | tok/sec: 5,304 | mfu: -1.00 | total time: 0.04m\n",
      "step 00093 (0.00%) | loss: 6.314178 | lrm: 1.00 | dt: 24.57ms | tok/sec: 5,208 | mfu: -1.00 | total time: 0.04m\n",
      "step 00094 (0.00%) | loss: 6.215667 | lrm: 1.00 | dt: 28.86ms | tok/sec: 4,435 | mfu: -1.00 | total time: 0.04m\n",
      "step 00095 (0.00%) | loss: 6.292133 | lrm: 1.00 | dt: 27.16ms | tok/sec: 4,712 | mfu: -1.00 | total time: 0.04m\n",
      "step 00096 (0.00%) | loss: 6.369926 | lrm: 1.00 | dt: 26.10ms | tok/sec: 4,903 | mfu: -1.00 | total time: 0.04m\n",
      "step 00097 (0.00%) | loss: 6.410126 | lrm: 1.00 | dt: 22.76ms | tok/sec: 5,623 | mfu: -1.00 | total time: 0.04m\n",
      "step 00098 (0.00%) | loss: 6.419397 | lrm: 1.00 | dt: 22.63ms | tok/sec: 5,657 | mfu: -1.00 | total time: 0.04m\n",
      "step 00099 (0.00%) | loss: 6.463093 | lrm: 1.00 | dt: 24.21ms | tok/sec: 5,285 | mfu: -1.00 | total time: 0.04m\n",
      "step 00100 (0.00%) | loss: 6.466592 | lrm: 1.00 | dt: 23.37ms | tok/sec: 5,477 | mfu: -1.00 | total time: 0.04m\n",
      "step 00101 (0.00%) | loss: 6.453933 | lrm: 1.00 | dt: 28.42ms | tok/sec: 4,504 | mfu: -1.00 | total time: 0.04m\n",
      "step 00102 (0.00%) | loss: 6.452109 | lrm: 1.00 | dt: 26.58ms | tok/sec: 4,815 | mfu: -1.00 | total time: 0.04m\n",
      "step 00103 (0.00%) | loss: 6.462005 | lrm: 1.00 | dt: 28.33ms | tok/sec: 4,517 | mfu: -1.00 | total time: 0.04m\n",
      "step 00104 (0.00%) | loss: 6.465652 | lrm: 1.00 | dt: 27.84ms | tok/sec: 4,598 | mfu: -1.00 | total time: 0.04m\n",
      "step 00105 (0.00%) | loss: 6.513806 | lrm: 1.00 | dt: 30.12ms | tok/sec: 4,249 | mfu: -1.00 | total time: 0.04m\n",
      "step 00106 (0.00%) | loss: 6.511006 | lrm: 1.00 | dt: 26.07ms | tok/sec: 4,908 | mfu: -1.00 | total time: 0.04m\n",
      "step 00107 (0.00%) | loss: 6.533351 | lrm: 1.00 | dt: 26.22ms | tok/sec: 4,881 | mfu: -1.00 | total time: 0.04m\n",
      "step 00108 (0.00%) | loss: 6.595658 | lrm: 1.00 | dt: 29.89ms | tok/sec: 4,283 | mfu: -1.00 | total time: 0.04m\n",
      "step 00109 (0.00%) | loss: 6.577969 | lrm: 1.00 | dt: 31.99ms | tok/sec: 4,001 | mfu: -1.00 | total time: 0.04m\n",
      "step 00110 (0.00%) | loss: 6.577654 | lrm: 1.00 | dt: 28.52ms | tok/sec: 4,488 | mfu: -1.00 | total time: 0.05m\n",
      "step 00111 (0.00%) | loss: 6.546216 | lrm: 1.00 | dt: 26.90ms | tok/sec: 4,758 | mfu: -1.00 | total time: 0.05m\n",
      "step 00112 (0.00%) | loss: 6.467393 | lrm: 1.00 | dt: 28.88ms | tok/sec: 4,432 | mfu: -1.00 | total time: 0.05m\n",
      "step 00113 (0.00%) | loss: 6.330394 | lrm: 1.00 | dt: 35.78ms | tok/sec: 3,577 | mfu: -1.00 | total time: 0.05m\n",
      "step 00114 (0.00%) | loss: 6.440084 | lrm: 1.00 | dt: 31.97ms | tok/sec: 4,003 | mfu: -1.00 | total time: 0.05m\n",
      "step 00115 (0.00%) | loss: 6.617371 | lrm: 1.00 | dt: 29.67ms | tok/sec: 4,314 | mfu: -1.00 | total time: 0.05m\n",
      "step 00116 (0.00%) | loss: 6.725415 | lrm: 1.00 | dt: 29.77ms | tok/sec: 4,299 | mfu: -1.00 | total time: 0.05m\n",
      "step 00117 (0.00%) | loss: 6.752330 | lrm: 1.00 | dt: 27.09ms | tok/sec: 4,725 | mfu: -1.00 | total time: 0.05m\n",
      "step 00118 (0.00%) | loss: 6.762673 | lrm: 1.00 | dt: 27.18ms | tok/sec: 4,710 | mfu: -1.00 | total time: 0.05m\n",
      "step 00119 (0.00%) | loss: 6.861333 | lrm: 1.00 | dt: 25.77ms | tok/sec: 4,966 | mfu: -1.00 | total time: 0.05m\n",
      "step 00120 (0.00%) | loss: 6.852478 | lrm: 1.00 | dt: 23.90ms | tok/sec: 5,354 | mfu: -1.00 | total time: 0.05m\n",
      "step 00121 (0.00%) | loss: 6.901383 | lrm: 1.00 | dt: 26.86ms | tok/sec: 4,765 | mfu: -1.00 | total time: 0.05m\n",
      "step 00122 (0.00%) | loss: 6.925139 | lrm: 1.00 | dt: 24.70ms | tok/sec: 5,181 | mfu: -1.00 | total time: 0.05m\n",
      "step 00123 (0.00%) | loss: 6.893210 | lrm: 1.00 | dt: 24.74ms | tok/sec: 5,174 | mfu: -1.00 | total time: 0.05m\n",
      "step 00124 (0.00%) | loss: 6.910988 | lrm: 1.00 | dt: 28.69ms | tok/sec: 4,462 | mfu: -1.00 | total time: 0.05m\n",
      "step 00125 (0.00%) | loss: 6.857391 | lrm: 1.00 | dt: 350.33ms | tok/sec: 365 | mfu: -1.00 | total time: 0.06m\n",
      "step 00126 (0.00%) | loss: 6.872741 | lrm: 1.00 | dt: 126.29ms | tok/sec: 1,013 | mfu: -1.00 | total time: 0.06m\n",
      "step 00127 (0.00%) | loss: 6.867944 | lrm: 1.00 | dt: 114.69ms | tok/sec: 1,116 | mfu: -1.00 | total time: 0.06m\n",
      "step 00128 (0.00%) | loss: 6.864041 | lrm: 1.00 | dt: 22.95ms | tok/sec: 5,576 | mfu: -1.00 | total time: 0.06m\n",
      "step 00129 (0.00%) | loss: 6.940778 | lrm: 1.00 | dt: 58.19ms | tok/sec: 2,199 | mfu: -1.00 | total time: 0.06m\n",
      "step 00130 (0.00%) | loss: 6.982030 | lrm: 1.00 | dt: 29.91ms | tok/sec: 4,279 | mfu: -1.00 | total time: 0.06m\n",
      "step 00131 (0.00%) | loss: 7.012065 | lrm: 1.00 | dt: 24.56ms | tok/sec: 5,212 | mfu: -1.00 | total time: 0.06m\n",
      "step 00132 (0.00%) | loss: 7.056964 | lrm: 1.00 | dt: 25.88ms | tok/sec: 4,946 | mfu: -1.00 | total time: 0.06m\n",
      "step 00133 (0.00%) | loss: 7.031431 | lrm: 1.00 | dt: 25.20ms | tok/sec: 5,079 | mfu: -1.00 | total time: 0.06m\n",
      "step 00134 (0.00%) | loss: 6.976629 | lrm: 1.00 | dt: 29.30ms | tok/sec: 4,368 | mfu: -1.00 | total time: 0.07m\n",
      "step 00135 (0.00%) | loss: 6.931733 | lrm: 1.00 | dt: 24.66ms | tok/sec: 5,191 | mfu: -1.00 | total time: 0.07m\n",
      "step 00136 (0.00%) | loss: 6.950402 | lrm: 1.00 | dt: 23.19ms | tok/sec: 5,518 | mfu: -1.00 | total time: 0.07m\n",
      "step 00137 (0.00%) | loss: 7.051608 | lrm: 1.00 | dt: 23.50ms | tok/sec: 5,446 | mfu: -1.00 | total time: 0.07m\n",
      "step 00138 (0.00%) | loss: 7.097105 | lrm: 1.00 | dt: 27.93ms | tok/sec: 4,583 | mfu: -1.00 | total time: 0.07m\n",
      "step 00139 (0.00%) | loss: 7.165411 | lrm: 1.00 | dt: 26.04ms | tok/sec: 4,916 | mfu: -1.00 | total time: 0.07m\n",
      "step 00140 (0.01%) | loss: 7.171992 | lrm: 1.00 | dt: 29.44ms | tok/sec: 4,348 | mfu: -1.00 | total time: 0.07m\n",
      "step 00141 (0.01%) | loss: 7.199260 | lrm: 1.00 | dt: 24.62ms | tok/sec: 5,199 | mfu: -1.00 | total time: 0.07m\n",
      "step 00142 (0.01%) | loss: 7.241276 | lrm: 1.00 | dt: 25.44ms | tok/sec: 5,031 | mfu: -1.00 | total time: 0.07m\n",
      "step 00143 (0.01%) | loss: 7.296414 | lrm: 1.00 | dt: 22.76ms | tok/sec: 5,623 | mfu: -1.00 | total time: 0.07m\n",
      "step 00144 (0.01%) | loss: 7.367672 | lrm: 1.00 | dt: 23.32ms | tok/sec: 5,488 | mfu: -1.00 | total time: 0.07m\n",
      "step 00145 (0.01%) | loss: 7.260805 | lrm: 1.00 | dt: 25.40ms | tok/sec: 5,039 | mfu: -1.00 | total time: 0.07m\n",
      "step 00146 (0.01%) | loss: 7.108279 | lrm: 1.00 | dt: 27.87ms | tok/sec: 4,592 | mfu: -1.00 | total time: 0.07m\n",
      "step 00147 (0.01%) | loss: 6.917514 | lrm: 1.00 | dt: 33.65ms | tok/sec: 3,803 | mfu: -1.00 | total time: 0.07m\n",
      "step 00148 (0.01%) | loss: 6.834176 | lrm: 1.00 | dt: 35.84ms | tok/sec: 3,571 | mfu: -1.00 | total time: 0.07m\n",
      "step 00149 (0.01%) | loss: 6.915647 | lrm: 1.00 | dt: 29.36ms | tok/sec: 4,359 | mfu: -1.00 | total time: 0.07m\n",
      "step 00150 (0.01%) | loss: 6.949978 | lrm: 1.00 | dt: 27.93ms | tok/sec: 4,583 | mfu: -1.00 | total time: 0.07m\n",
      "step 00150 | Validation bpb: 2.2016\n",
      "step 00151 (0.01%) | loss: 6.874002 | lrm: 1.00 | dt: 36.42ms | tok/sec: 3,514 | mfu: -1.00 | total time: 0.07m\n",
      "step 00152 (0.01%) | loss: 6.587316 | lrm: 1.00 | dt: 31.00ms | tok/sec: 4,128 | mfu: -1.00 | total time: 0.07m\n",
      "step 00153 (0.01%) | loss: 6.691538 | lrm: 1.00 | dt: 24.19ms | tok/sec: 5,290 | mfu: -1.00 | total time: 0.07m\n",
      "step 00154 (0.01%) | loss: 6.856777 | lrm: 1.00 | dt: 23.89ms | tok/sec: 5,357 | mfu: -1.00 | total time: 0.07m\n",
      "step 00155 (0.01%) | loss: 6.985712 | lrm: 1.00 | dt: 23.05ms | tok/sec: 5,554 | mfu: -1.00 | total time: 0.07m\n",
      "step 00156 (0.01%) | loss: 7.118683 | lrm: 1.00 | dt: 22.01ms | tok/sec: 5,814 | mfu: -1.00 | total time: 0.08m\n",
      "step 00157 (0.01%) | loss: 7.172633 | lrm: 1.00 | dt: 22.40ms | tok/sec: 5,715 | mfu: -1.00 | total time: 0.08m\n",
      "step 00158 (0.01%) | loss: 7.216722 | lrm: 1.00 | dt: 27.40ms | tok/sec: 4,672 | mfu: -1.00 | total time: 0.08m\n",
      "step 00159 (0.01%) | loss: 7.264909 | lrm: 1.00 | dt: 28.41ms | tok/sec: 4,504 | mfu: -1.00 | total time: 0.08m\n",
      "step 00160 (0.01%) | loss: 7.332119 | lrm: 1.00 | dt: 25.12ms | tok/sec: 5,095 | mfu: -1.00 | total time: 0.08m\n",
      "step 00161 (0.01%) | loss: 7.281531 | lrm: 1.00 | dt: 23.26ms | tok/sec: 5,502 | mfu: -1.00 | total time: 0.08m\n",
      "step 00162 (0.01%) | loss: 7.288195 | lrm: 1.00 | dt: 28.53ms | tok/sec: 4,486 | mfu: -1.00 | total time: 0.08m\n",
      "step 00163 (0.01%) | loss: 7.294782 | lrm: 1.00 | dt: 28.55ms | tok/sec: 4,483 | mfu: -1.00 | total time: 0.08m\n",
      "step 00164 (0.01%) | loss: 7.311041 | lrm: 1.00 | dt: 24.30ms | tok/sec: 5,267 | mfu: -1.00 | total time: 0.08m\n",
      "step 00165 (0.01%) | loss: 7.303184 | lrm: 1.00 | dt: 31.01ms | tok/sec: 4,127 | mfu: -1.00 | total time: 0.08m\n",
      "step 00166 (0.01%) | loss: 7.254193 | lrm: 1.00 | dt: 27.66ms | tok/sec: 4,627 | mfu: -1.00 | total time: 0.08m\n",
      "step 00167 (0.01%) | loss: 7.228319 | lrm: 1.00 | dt: 41.72ms | tok/sec: 3,068 | mfu: -1.00 | total time: 0.08m\n",
      "step 00168 (0.01%) | loss: 7.273512 | lrm: 1.00 | dt: 32.95ms | tok/sec: 3,885 | mfu: -1.00 | total time: 0.08m\n",
      "step 00169 (0.01%) | loss: 7.299899 | lrm: 1.00 | dt: 32.74ms | tok/sec: 3,909 | mfu: -1.00 | total time: 0.08m\n",
      "step 00170 (0.01%) | loss: 7.348173 | lrm: 1.00 | dt: 28.25ms | tok/sec: 4,530 | mfu: -1.00 | total time: 0.08m\n",
      "step 00171 (0.01%) | loss: 7.304498 | lrm: 1.00 | dt: 28.11ms | tok/sec: 4,553 | mfu: -1.00 | total time: 0.08m\n",
      "step 00172 (0.01%) | loss: 7.361764 | lrm: 1.00 | dt: 25.67ms | tok/sec: 4,987 | mfu: -1.00 | total time: 0.08m\n",
      "step 00173 (0.01%) | loss: 7.295835 | lrm: 1.00 | dt: 22.16ms | tok/sec: 5,775 | mfu: -1.00 | total time: 0.08m\n",
      "step 00174 (0.01%) | loss: 7.284324 | lrm: 1.00 | dt: 23.39ms | tok/sec: 5,471 | mfu: -1.00 | total time: 0.08m\n",
      "step 00175 (0.01%) | loss: 7.220311 | lrm: 1.00 | dt: 32.58ms | tok/sec: 3,929 | mfu: -1.00 | total time: 0.08m\n",
      "step 00176 (0.01%) | loss: 7.070930 | lrm: 1.00 | dt: 27.40ms | tok/sec: 4,672 | mfu: -1.00 | total time: 0.08m\n",
      "step 00177 (0.01%) | loss: 7.032513 | lrm: 1.00 | dt: 28.55ms | tok/sec: 4,483 | mfu: -1.00 | total time: 0.09m\n",
      "step 00178 (0.01%) | loss: 7.003107 | lrm: 1.00 | dt: 26.45ms | tok/sec: 4,838 | mfu: -1.00 | total time: 0.09m\n",
      "step 00179 (0.01%) | loss: 7.032796 | lrm: 1.00 | dt: 23.17ms | tok/sec: 5,525 | mfu: -1.00 | total time: 0.09m\n",
      "step 00180 (0.01%) | loss: 7.005988 | lrm: 1.00 | dt: 27.34ms | tok/sec: 4,682 | mfu: -1.00 | total time: 0.09m\n",
      "step 00181 (0.01%) | loss: 7.029322 | lrm: 1.00 | dt: 26.22ms | tok/sec: 4,881 | mfu: -1.00 | total time: 0.09m\n",
      "step 00182 (0.01%) | loss: 7.006574 | lrm: 1.00 | dt: 28.23ms | tok/sec: 4,534 | mfu: -1.00 | total time: 0.09m\n",
      "step 00183 (0.01%) | loss: 6.962672 | lrm: 1.00 | dt: 27.06ms | tok/sec: 4,729 | mfu: -1.00 | total time: 0.09m\n",
      "step 00184 (0.01%) | loss: 6.941321 | lrm: 1.00 | dt: 25.80ms | tok/sec: 4,960 | mfu: -1.00 | total time: 0.09m\n",
      "step 00185 (0.01%) | loss: 6.933643 | lrm: 1.00 | dt: 22.14ms | tok/sec: 5,781 | mfu: -1.00 | total time: 0.09m\n",
      "step 00186 (0.01%) | loss: 6.936155 | lrm: 1.00 | dt: 22.83ms | tok/sec: 5,606 | mfu: -1.00 | total time: 0.09m\n",
      "step 00187 (0.01%) | loss: 6.999551 | lrm: 1.00 | dt: 24.77ms | tok/sec: 5,166 | mfu: -1.00 | total time: 0.09m\n",
      "step 00188 (0.01%) | loss: 6.996187 | lrm: 1.00 | dt: 22.48ms | tok/sec: 5,694 | mfu: -1.00 | total time: 0.09m\n",
      "step 00189 (0.01%) | loss: 6.994180 | lrm: 1.00 | dt: 23.03ms | tok/sec: 5,557 | mfu: -1.00 | total time: 0.09m\n",
      "step 00190 (0.01%) | loss: 7.137889 | lrm: 1.00 | dt: 26.28ms | tok/sec: 4,870 | mfu: -1.00 | total time: 0.09m\n",
      "step 00191 (0.01%) | loss: 7.067956 | lrm: 1.00 | dt: 24.43ms | tok/sec: 5,240 | mfu: -1.00 | total time: 0.09m\n",
      "step 00192 (0.01%) | loss: 6.879081 | lrm: 1.00 | dt: 26.57ms | tok/sec: 4,817 | mfu: -1.00 | total time: 0.09m\n",
      "step 00193 (0.01%) | loss: 6.852683 | lrm: 1.00 | dt: 24.62ms | tok/sec: 5,198 | mfu: -1.00 | total time: 0.09m\n",
      "step 00194 (0.01%) | loss: 6.884508 | lrm: 1.00 | dt: 28.58ms | tok/sec: 4,478 | mfu: -1.00 | total time: 0.09m\n",
      "step 00195 (0.01%) | loss: 7.023989 | lrm: 1.00 | dt: 24.25ms | tok/sec: 5,277 | mfu: -1.00 | total time: 0.09m\n",
      "step 00196 (0.01%) | loss: 7.140121 | lrm: 1.00 | dt: 26.52ms | tok/sec: 4,825 | mfu: -1.00 | total time: 0.09m\n",
      "step 00197 (0.01%) | loss: 7.073166 | lrm: 1.00 | dt: 29.91ms | tok/sec: 4,278 | mfu: -1.00 | total time: 0.09m\n",
      "step 00198 (0.01%) | loss: 7.111740 | lrm: 1.00 | dt: 28.53ms | tok/sec: 4,485 | mfu: -1.00 | total time: 0.09m\n",
      "step 00199 (0.01%) | loss: 7.023050 | lrm: 1.00 | dt: 25.74ms | tok/sec: 4,972 | mfu: -1.00 | total time: 0.09m\n",
      "step 00200 (0.01%) | loss: 6.970044 | lrm: 1.00 | dt: 23.25ms | tok/sec: 5,504 | mfu: -1.00 | total time: 0.09m\n",
      "step 00201 (0.01%) | loss: 6.886847 | lrm: 1.00 | dt: 26.68ms | tok/sec: 4,797 | mfu: -1.00 | total time: 0.10m\n",
      "step 00202 (0.01%) | loss: 6.816818 | lrm: 1.00 | dt: 28.41ms | tok/sec: 4,504 | mfu: -1.00 | total time: 0.10m\n",
      "step 00203 (0.01%) | loss: 6.662131 | lrm: 1.00 | dt: 26.29ms | tok/sec: 4,868 | mfu: -1.00 | total time: 0.10m\n",
      "step 00204 (0.01%) | loss: 6.543907 | lrm: 1.00 | dt: 31.96ms | tok/sec: 4,005 | mfu: -1.00 | total time: 0.10m\n",
      "step 00205 (0.01%) | loss: 6.521387 | lrm: 1.00 | dt: 24.79ms | tok/sec: 5,163 | mfu: -1.00 | total time: 0.10m\n",
      "step 00206 (0.01%) | loss: 6.476181 | lrm: 1.00 | dt: 29.44ms | tok/sec: 4,347 | mfu: -1.00 | total time: 0.10m\n",
      "step 00207 (0.01%) | loss: 6.432192 | lrm: 1.00 | dt: 28.77ms | tok/sec: 4,449 | mfu: -1.00 | total time: 0.10m\n",
      "step 00208 (0.01%) | loss: 6.402916 | lrm: 1.00 | dt: 25.58ms | tok/sec: 5,004 | mfu: -1.00 | total time: 0.10m\n",
      "step 00209 (0.01%) | loss: 6.413552 | lrm: 1.00 | dt: 30.60ms | tok/sec: 4,183 | mfu: -1.00 | total time: 0.10m\n",
      "step 00210 (0.01%) | loss: 6.289555 | lrm: 1.00 | dt: 28.60ms | tok/sec: 4,475 | mfu: -1.00 | total time: 0.10m\n",
      "step 00211 (0.01%) | loss: 6.163662 | lrm: 1.00 | dt: 24.93ms | tok/sec: 5,134 | mfu: -1.00 | total time: 0.10m\n",
      "step 00212 (0.01%) | loss: 6.075774 | lrm: 1.00 | dt: 23.13ms | tok/sec: 5,535 | mfu: -1.00 | total time: 0.10m\n",
      "step 00213 (0.01%) | loss: 6.004747 | lrm: 1.00 | dt: 24.19ms | tok/sec: 5,292 | mfu: -1.00 | total time: 0.10m\n",
      "step 00214 (0.01%) | loss: 5.897036 | lrm: 1.00 | dt: 25.62ms | tok/sec: 4,996 | mfu: -1.00 | total time: 0.10m\n",
      "step 00215 (0.01%) | loss: 5.818590 | lrm: 1.00 | dt: 27.34ms | tok/sec: 4,681 | mfu: -1.00 | total time: 0.10m\n",
      "step 00216 (0.01%) | loss: 5.780026 | lrm: 1.00 | dt: 34.09ms | tok/sec: 3,754 | mfu: -1.00 | total time: 0.10m\n",
      "step 00217 (0.01%) | loss: 5.744404 | lrm: 1.00 | dt: 32.88ms | tok/sec: 3,893 | mfu: -1.00 | total time: 0.10m\n",
      "step 00218 (0.01%) | loss: 5.653099 | lrm: 1.00 | dt: 29.06ms | tok/sec: 4,405 | mfu: -1.00 | total time: 0.10m\n",
      "step 00219 (0.01%) | loss: 5.501285 | lrm: 1.00 | dt: 29.01ms | tok/sec: 4,413 | mfu: -1.00 | total time: 0.10m\n",
      "step 00220 (0.01%) | loss: 5.751059 | lrm: 1.00 | dt: 27.50ms | tok/sec: 4,655 | mfu: -1.00 | total time: 0.10m\n",
      "step 00221 (0.01%) | loss: 6.048058 | lrm: 1.00 | dt: 26.64ms | tok/sec: 4,804 | mfu: -1.00 | total time: 0.10m\n",
      "step 00222 (0.01%) | loss: 6.244890 | lrm: 1.00 | dt: 27.29ms | tok/sec: 4,690 | mfu: -1.00 | total time: 0.11m\n",
      "step 00223 (0.01%) | loss: 6.432698 | lrm: 1.00 | dt: 27.66ms | tok/sec: 4,627 | mfu: -1.00 | total time: 0.11m\n",
      "step 00224 (0.01%) | loss: 6.589122 | lrm: 1.00 | dt: 27.83ms | tok/sec: 4,599 | mfu: -1.00 | total time: 0.11m\n",
      "step 00225 (0.01%) | loss: 6.642569 | lrm: 1.00 | dt: 26.63ms | tok/sec: 4,806 | mfu: -1.00 | total time: 0.11m\n",
      "step 00226 (0.01%) | loss: 6.695448 | lrm: 1.00 | dt: 28.09ms | tok/sec: 4,556 | mfu: -1.00 | total time: 0.11m\n",
      "step 00227 (0.01%) | loss: 6.736499 | lrm: 1.00 | dt: 25.80ms | tok/sec: 4,960 | mfu: -1.00 | total time: 0.11m\n",
      "step 00228 (0.01%) | loss: 6.821572 | lrm: 1.00 | dt: 27.85ms | tok/sec: 4,596 | mfu: -1.00 | total time: 0.11m\n",
      "step 00229 (0.01%) | loss: 6.851891 | lrm: 1.00 | dt: 28.38ms | tok/sec: 4,510 | mfu: -1.00 | total time: 0.11m\n",
      "step 00230 (0.01%) | loss: 6.902995 | lrm: 1.00 | dt: 28.18ms | tok/sec: 4,542 | mfu: -1.00 | total time: 0.11m\n",
      "step 00231 (0.01%) | loss: 6.956014 | lrm: 1.00 | dt: 25.02ms | tok/sec: 5,116 | mfu: -1.00 | total time: 0.11m\n",
      "step 00232 (0.01%) | loss: 6.934460 | lrm: 1.00 | dt: 25.78ms | tok/sec: 4,966 | mfu: -1.00 | total time: 0.11m\n",
      "step 00233 (0.01%) | loss: 6.871138 | lrm: 1.00 | dt: 22.04ms | tok/sec: 5,808 | mfu: -1.00 | total time: 0.11m\n",
      "step 00234 (0.01%) | loss: 6.887805 | lrm: 1.00 | dt: 22.40ms | tok/sec: 5,713 | mfu: -1.00 | total time: 0.11m\n",
      "step 00235 (0.01%) | loss: 6.896460 | lrm: 1.00 | dt: 22.78ms | tok/sec: 5,617 | mfu: -1.00 | total time: 0.11m\n",
      "step 00236 (0.01%) | loss: 6.878385 | lrm: 1.00 | dt: 21.67ms | tok/sec: 5,907 | mfu: -1.00 | total time: 0.11m\n",
      "step 00237 (0.01%) | loss: 6.832366 | lrm: 1.00 | dt: 22.40ms | tok/sec: 5,713 | mfu: -1.00 | total time: 0.11m\n",
      "step 00238 (0.01%) | loss: 6.801503 | lrm: 1.00 | dt: 25.86ms | tok/sec: 4,950 | mfu: -1.00 | total time: 0.11m\n",
      "step 00239 (0.01%) | loss: 6.745032 | lrm: 1.00 | dt: 36.26ms | tok/sec: 3,530 | mfu: -1.00 | total time: 0.11m\n",
      "step 00240 (0.01%) | loss: 6.822519 | lrm: 1.00 | dt: 33.08ms | tok/sec: 3,869 | mfu: -1.00 | total time: 0.11m\n",
      "step 00241 (0.01%) | loss: 6.862896 | lrm: 1.00 | dt: 34.93ms | tok/sec: 3,664 | mfu: -1.00 | total time: 0.11m\n",
      "step 00242 (0.01%) | loss: 6.936230 | lrm: 1.00 | dt: 33.35ms | tok/sec: 3,838 | mfu: -1.00 | total time: 0.11m\n",
      "step 00243 (0.01%) | loss: 6.887407 | lrm: 1.00 | dt: 27.52ms | tok/sec: 4,651 | mfu: -1.00 | total time: 0.11m\n",
      "step 00244 (0.01%) | loss: 6.788266 | lrm: 1.00 | dt: 27.28ms | tok/sec: 4,691 | mfu: -1.00 | total time: 0.12m\n",
      "step 00245 (0.01%) | loss: 6.630629 | lrm: 1.00 | dt: 27.56ms | tok/sec: 4,644 | mfu: -1.00 | total time: 0.12m\n",
      "step 00246 (0.01%) | loss: 6.589929 | lrm: 1.00 | dt: 27.05ms | tok/sec: 4,731 | mfu: -1.00 | total time: 0.12m\n",
      "step 00247 (0.01%) | loss: 6.644140 | lrm: 1.00 | dt: 29.07ms | tok/sec: 4,402 | mfu: -1.00 | total time: 0.12m\n",
      "step 00248 (0.01%) | loss: 6.622866 | lrm: 1.00 | dt: 26.84ms | tok/sec: 4,768 | mfu: -1.00 | total time: 0.12m\n",
      "step 00249 (0.01%) | loss: 6.620906 | lrm: 1.00 | dt: 27.14ms | tok/sec: 4,715 | mfu: -1.00 | total time: 0.12m\n",
      "step 00250 (0.01%) | loss: 6.666027 | lrm: 1.00 | dt: 30.54ms | tok/sec: 4,190 | mfu: -1.00 | total time: 0.12m\n",
      "step 00251 (0.01%) | loss: 6.686587 | lrm: 1.00 | dt: 26.47ms | tok/sec: 4,834 | mfu: -1.00 | total time: 0.12m\n",
      "step 00252 (0.01%) | loss: 6.707957 | lrm: 1.00 | dt: 28.31ms | tok/sec: 4,520 | mfu: -1.00 | total time: 0.12m\n",
      "step 00253 (0.01%) | loss: 6.821912 | lrm: 1.00 | dt: 23.89ms | tok/sec: 5,358 | mfu: -1.00 | total time: 0.12m\n",
      "step 00254 (0.01%) | loss: 7.013102 | lrm: 1.00 | dt: 22.72ms | tok/sec: 5,634 | mfu: -1.00 | total time: 0.12m\n",
      "step 00255 (0.01%) | loss: 7.016928 | lrm: 1.00 | dt: 29.52ms | tok/sec: 4,336 | mfu: -1.00 | total time: 0.12m\n",
      "step 00256 (0.01%) | loss: 7.107049 | lrm: 1.00 | dt: 28.50ms | tok/sec: 4,491 | mfu: -1.00 | total time: 0.12m\n",
      "step 00257 (0.01%) | loss: 7.110847 | lrm: 1.00 | dt: 28.77ms | tok/sec: 4,449 | mfu: -1.00 | total time: 0.12m\n",
      "step 00258 (0.01%) | loss: 7.105145 | lrm: 1.00 | dt: 27.81ms | tok/sec: 4,602 | mfu: -1.00 | total time: 0.12m\n",
      "step 00259 (0.01%) | loss: 7.120125 | lrm: 1.00 | dt: 26.11ms | tok/sec: 4,902 | mfu: -1.00 | total time: 0.12m\n",
      "step 00260 (0.01%) | loss: 7.181180 | lrm: 1.00 | dt: 31.17ms | tok/sec: 4,106 | mfu: -1.00 | total time: 0.12m\n",
      "step 00261 (0.01%) | loss: 7.186591 | lrm: 1.00 | dt: 27.58ms | tok/sec: 4,640 | mfu: -1.00 | total time: 0.12m\n",
      "step 00262 (0.01%) | loss: 7.192766 | lrm: 1.00 | dt: 23.63ms | tok/sec: 5,415 | mfu: -1.00 | total time: 0.12m\n",
      "step 00263 (0.01%) | loss: 7.203898 | lrm: 1.00 | dt: 26.03ms | tok/sec: 4,917 | mfu: -1.00 | total time: 0.12m\n",
      "step 00264 (0.01%) | loss: 7.180372 | lrm: 1.00 | dt: 23.76ms | tok/sec: 5,388 | mfu: -1.00 | total time: 0.12m\n",
      "step 00265 (0.01%) | loss: 7.092668 | lrm: 1.00 | dt: 24.31ms | tok/sec: 5,265 | mfu: -1.00 | total time: 0.12m\n",
      "step 00266 (0.01%) | loss: 7.158788 | lrm: 1.00 | dt: 26.64ms | tok/sec: 4,803 | mfu: -1.00 | total time: 0.13m\n",
      "step 00267 (0.01%) | loss: 7.139999 | lrm: 1.00 | dt: 23.92ms | tok/sec: 5,350 | mfu: -1.00 | total time: 0.13m\n",
      "step 00268 (0.01%) | loss: 7.067666 | lrm: 1.00 | dt: 24.00ms | tok/sec: 5,333 | mfu: -1.00 | total time: 0.13m\n",
      "step 00269 (0.01%) | loss: 7.019528 | lrm: 1.00 | dt: 23.09ms | tok/sec: 5,544 | mfu: -1.00 | total time: 0.13m\n",
      "step 00270 (0.01%) | loss: 6.970266 | lrm: 1.00 | dt: 23.80ms | tok/sec: 5,377 | mfu: -1.00 | total time: 0.13m\n",
      "step 00271 (0.01%) | loss: 6.904485 | lrm: 1.00 | dt: 26.65ms | tok/sec: 4,803 | mfu: -1.00 | total time: 0.13m\n",
      "step 00272 (0.01%) | loss: 6.853699 | lrm: 1.00 | dt: 26.03ms | tok/sec: 4,917 | mfu: -1.00 | total time: 0.13m\n",
      "step 00273 (0.01%) | loss: 6.761727 | lrm: 1.00 | dt: 29.01ms | tok/sec: 4,411 | mfu: -1.00 | total time: 0.13m\n",
      "step 00274 (0.01%) | loss: 6.733764 | lrm: 1.00 | dt: 31.35ms | tok/sec: 4,083 | mfu: -1.00 | total time: 0.13m\n",
      "step 00275 (0.01%) | loss: 6.739062 | lrm: 1.00 | dt: 26.13ms | tok/sec: 4,898 | mfu: -1.00 | total time: 0.13m\n",
      "step 00276 (0.01%) | loss: 6.733792 | lrm: 1.00 | dt: 32.65ms | tok/sec: 3,920 | mfu: -1.00 | total time: 0.13m\n",
      "step 00277 (0.01%) | loss: 6.595529 | lrm: 1.00 | dt: 29.38ms | tok/sec: 4,356 | mfu: -1.00 | total time: 0.13m\n",
      "step 00278 (0.01%) | loss: 6.612840 | lrm: 1.00 | dt: 25.84ms | tok/sec: 4,954 | mfu: -1.00 | total time: 0.13m\n",
      "step 00279 (0.01%) | loss: 6.608791 | lrm: 1.00 | dt: 25.18ms | tok/sec: 5,083 | mfu: -1.00 | total time: 0.13m\n",
      "step 00280 (0.01%) | loss: 6.498364 | lrm: 1.00 | dt: 25.94ms | tok/sec: 4,934 | mfu: -1.00 | total time: 0.13m\n",
      "step 00281 (0.01%) | loss: 6.485917 | lrm: 1.00 | dt: 23.55ms | tok/sec: 5,434 | mfu: -1.00 | total time: 0.13m\n",
      "step 00282 (0.01%) | loss: 6.606292 | lrm: 1.00 | dt: 30.19ms | tok/sec: 4,240 | mfu: -1.00 | total time: 0.13m\n",
      "step 00283 (0.01%) | loss: 6.702120 | lrm: 1.00 | dt: 21.85ms | tok/sec: 5,858 | mfu: -1.00 | total time: 0.13m\n",
      "step 00284 (0.01%) | loss: 6.751784 | lrm: 1.00 | dt: 27.14ms | tok/sec: 4,715 | mfu: -1.00 | total time: 0.13m\n",
      "step 00285 (0.01%) | loss: 6.851029 | lrm: 1.00 | dt: 31.64ms | tok/sec: 4,044 | mfu: -1.00 | total time: 0.13m\n",
      "step 00286 (0.01%) | loss: 6.868566 | lrm: 1.00 | dt: 27.59ms | tok/sec: 4,639 | mfu: -1.00 | total time: 0.13m\n",
      "step 00287 (0.01%) | loss: 6.866158 | lrm: 1.00 | dt: 28.51ms | tok/sec: 4,490 | mfu: -1.00 | total time: 0.13m\n",
      "step 00288 (0.01%) | loss: 6.855291 | lrm: 1.00 | dt: 29.66ms | tok/sec: 4,316 | mfu: -1.00 | total time: 0.13m\n",
      "step 00289 (0.01%) | loss: 6.854730 | lrm: 1.00 | dt: 29.92ms | tok/sec: 4,278 | mfu: -1.00 | total time: 0.14m\n",
      "step 00290 (0.01%) | loss: 6.639747 | lrm: 1.00 | dt: 33.29ms | tok/sec: 3,845 | mfu: -1.00 | total time: 0.14m\n",
      "step 00291 (0.01%) | loss: 6.556477 | lrm: 1.00 | dt: 32.18ms | tok/sec: 3,977 | mfu: -1.00 | total time: 0.14m\n",
      "step 00292 (0.01%) | loss: 6.526312 | lrm: 1.00 | dt: 29.04ms | tok/sec: 4,407 | mfu: -1.00 | total time: 0.14m\n",
      "step 00293 (0.01%) | loss: 6.523554 | lrm: 1.00 | dt: 25.39ms | tok/sec: 5,042 | mfu: -1.00 | total time: 0.14m\n",
      "step 00294 (0.01%) | loss: 6.473751 | lrm: 1.00 | dt: 23.04ms | tok/sec: 5,556 | mfu: -1.00 | total time: 0.14m\n",
      "step 00295 (0.01%) | loss: 6.494829 | lrm: 1.00 | dt: 22.14ms | tok/sec: 5,781 | mfu: -1.00 | total time: 0.14m\n",
      "step 00296 (0.01%) | loss: 6.498449 | lrm: 1.00 | dt: 32.16ms | tok/sec: 3,980 | mfu: -1.00 | total time: 0.14m\n",
      "step 00297 (0.01%) | loss: 6.452433 | lrm: 1.00 | dt: 33.14ms | tok/sec: 3,862 | mfu: -1.00 | total time: 0.14m\n",
      "step 00298 (0.01%) | loss: 6.407447 | lrm: 1.00 | dt: 31.37ms | tok/sec: 4,080 | mfu: -1.00 | total time: 0.14m\n",
      "step 00299 (0.01%) | loss: 6.341100 | lrm: 1.00 | dt: 28.99ms | tok/sec: 4,415 | mfu: -1.00 | total time: 0.14m\n",
      "step 00300 (0.01%) | loss: 6.330263 | lrm: 1.00 | dt: 25.51ms | tok/sec: 5,018 | mfu: -1.00 | total time: 0.14m\n",
      "step 00300 | Validation bpb: 2.2020\n",
      "step 00301 (0.01%) | loss: 6.496694 | lrm: 1.00 | dt: 35.93ms | tok/sec: 3,562 | mfu: -1.00 | total time: 0.14m\n",
      "step 00302 (0.01%) | loss: 6.607226 | lrm: 1.00 | dt: 29.04ms | tok/sec: 4,408 | mfu: -1.00 | total time: 0.14m\n",
      "step 00303 (0.01%) | loss: 6.675746 | lrm: 1.00 | dt: 28.04ms | tok/sec: 4,564 | mfu: -1.00 | total time: 0.14m\n",
      "step 00304 (0.01%) | loss: 6.744488 | lrm: 1.00 | dt: 217.44ms | tok/sec: 588 | mfu: -1.00 | total time: 0.15m\n",
      "step 00305 (0.01%) | loss: 6.858284 | lrm: 1.00 | dt: 47.34ms | tok/sec: 2,703 | mfu: -1.00 | total time: 0.15m\n",
      "step 00306 (0.01%) | loss: 6.959363 | lrm: 1.00 | dt: 25.35ms | tok/sec: 5,050 | mfu: -1.00 | total time: 0.15m\n",
      "step 00307 (0.01%) | loss: 6.974850 | lrm: 1.00 | dt: 24.70ms | tok/sec: 5,183 | mfu: -1.00 | total time: 0.15m\n",
      "step 00308 (0.01%) | loss: 7.007406 | lrm: 1.00 | dt: 27.32ms | tok/sec: 4,685 | mfu: -1.00 | total time: 0.15m\n",
      "step 00309 (0.01%) | loss: 7.123610 | lrm: 1.00 | dt: 25.41ms | tok/sec: 5,036 | mfu: -1.00 | total time: 0.15m\n",
      "step 00310 (0.01%) | loss: 7.155028 | lrm: 1.00 | dt: 23.77ms | tok/sec: 5,385 | mfu: -1.00 | total time: 0.15m\n",
      "step 00311 (0.01%) | loss: 7.180390 | lrm: 1.00 | dt: 25.78ms | tok/sec: 4,965 | mfu: -1.00 | total time: 0.15m\n",
      "step 00312 (0.01%) | loss: 7.157633 | lrm: 1.00 | dt: 28.94ms | tok/sec: 4,423 | mfu: -1.00 | total time: 0.15m\n",
      "step 00313 (0.01%) | loss: 7.113898 | lrm: 1.00 | dt: 23.32ms | tok/sec: 5,488 | mfu: -1.00 | total time: 0.15m\n",
      "step 00314 (0.01%) | loss: 7.144892 | lrm: 1.00 | dt: 22.86ms | tok/sec: 5,599 | mfu: -1.00 | total time: 0.15m\n",
      "step 00315 (0.01%) | loss: 7.224957 | lrm: 1.00 | dt: 23.60ms | tok/sec: 5,423 | mfu: -1.00 | total time: 0.15m\n",
      "step 00316 (0.01%) | loss: 7.242389 | lrm: 1.00 | dt: 24.38ms | tok/sec: 5,251 | mfu: -1.00 | total time: 0.15m\n",
      "step 00317 (0.01%) | loss: 7.237400 | lrm: 1.00 | dt: 26.25ms | tok/sec: 4,876 | mfu: -1.00 | total time: 0.15m\n",
      "step 00318 (0.01%) | loss: 7.215939 | lrm: 1.00 | dt: 22.79ms | tok/sec: 5,616 | mfu: -1.00 | total time: 0.15m\n",
      "step 00319 (0.01%) | loss: 7.190174 | lrm: 1.00 | dt: 26.32ms | tok/sec: 4,862 | mfu: -1.00 | total time: 0.15m\n",
      "step 00320 (0.01%) | loss: 7.232701 | lrm: 1.00 | dt: 31.09ms | tok/sec: 4,117 | mfu: -1.00 | total time: 0.15m\n",
      "step 00321 (0.01%) | loss: 7.241389 | lrm: 1.00 | dt: 28.29ms | tok/sec: 4,525 | mfu: -1.00 | total time: 0.15m\n",
      "step 00322 (0.01%) | loss: 7.153112 | lrm: 1.00 | dt: 24.71ms | tok/sec: 5,180 | mfu: -1.00 | total time: 0.15m\n",
      "step 00323 (0.01%) | loss: 6.967738 | lrm: 1.00 | dt: 34.35ms | tok/sec: 3,726 | mfu: -1.00 | total time: 0.15m\n",
      "step 00324 (0.01%) | loss: 6.982300 | lrm: 1.00 | dt: 24.71ms | tok/sec: 5,179 | mfu: -1.00 | total time: 0.15m\n",
      "step 00325 (0.01%) | loss: 6.939674 | lrm: 1.00 | dt: 29.57ms | tok/sec: 4,327 | mfu: -1.00 | total time: 0.16m\n",
      "step 00326 (0.01%) | loss: 6.912905 | lrm: 1.00 | dt: 29.72ms | tok/sec: 4,306 | mfu: -1.00 | total time: 0.16m\n",
      "step 00327 (0.01%) | loss: 6.910908 | lrm: 1.00 | dt: 28.96ms | tok/sec: 4,419 | mfu: -1.00 | total time: 0.16m\n",
      "step 00328 (0.01%) | loss: 6.926209 | lrm: 1.00 | dt: 29.59ms | tok/sec: 4,325 | mfu: -1.00 | total time: 0.16m\n",
      "step 00329 (0.01%) | loss: 6.940541 | lrm: 1.00 | dt: 25.69ms | tok/sec: 4,982 | mfu: -1.00 | total time: 0.16m\n",
      "step 00330 (0.01%) | loss: 6.924678 | lrm: 1.00 | dt: 26.41ms | tok/sec: 4,846 | mfu: -1.00 | total time: 0.16m\n",
      "step 00331 (0.01%) | loss: 6.868853 | lrm: 1.00 | dt: 27.64ms | tok/sec: 4,631 | mfu: -1.00 | total time: 0.16m\n",
      "step 00332 (0.01%) | loss: 6.751110 | lrm: 1.00 | dt: 30.86ms | tok/sec: 4,147 | mfu: -1.00 | total time: 0.16m\n",
      "step 00333 (0.01%) | loss: 6.465131 | lrm: 1.00 | dt: 29.23ms | tok/sec: 4,378 | mfu: -1.00 | total time: 0.16m\n",
      "step 00334 (0.01%) | loss: 6.148200 | lrm: 1.00 | dt: 23.65ms | tok/sec: 5,412 | mfu: -1.00 | total time: 0.16m\n",
      "step 00335 (0.01%) | loss: 6.224981 | lrm: 1.00 | dt: 29.02ms | tok/sec: 4,411 | mfu: -1.00 | total time: 0.16m\n",
      "step 00336 (0.01%) | loss: 6.198982 | lrm: 1.00 | dt: 33.26ms | tok/sec: 3,848 | mfu: -1.00 | total time: 0.16m\n",
      "step 00337 (0.01%) | loss: 6.218613 | lrm: 1.00 | dt: 28.11ms | tok/sec: 4,553 | mfu: -1.00 | total time: 0.16m\n",
      "step 00338 (0.01%) | loss: 6.171652 | lrm: 1.00 | dt: 24.39ms | tok/sec: 5,247 | mfu: -1.00 | total time: 0.16m\n",
      "step 00339 (0.01%) | loss: 6.136430 | lrm: 1.00 | dt: 32.84ms | tok/sec: 3,897 | mfu: -1.00 | total time: 0.16m\n",
      "step 00340 (0.01%) | loss: 6.108337 | lrm: 1.00 | dt: 30.58ms | tok/sec: 4,185 | mfu: -1.00 | total time: 0.16m\n",
      "step 00341 (0.01%) | loss: 6.036003 | lrm: 1.00 | dt: 31.53ms | tok/sec: 4,059 | mfu: -1.00 | total time: 0.16m\n",
      "step 00342 (0.01%) | loss: 6.017721 | lrm: 1.00 | dt: 34.22ms | tok/sec: 3,740 | mfu: -1.00 | total time: 0.16m\n",
      "step 00343 (0.01%) | loss: 6.020385 | lrm: 1.00 | dt: 26.61ms | tok/sec: 4,810 | mfu: -1.00 | total time: 0.16m\n",
      "step 00344 (0.01%) | loss: 6.121023 | lrm: 1.00 | dt: 29.46ms | tok/sec: 4,344 | mfu: -1.00 | total time: 0.16m\n",
      "step 00345 (0.01%) | loss: 6.230010 | lrm: 1.00 | dt: 25.13ms | tok/sec: 5,093 | mfu: -1.00 | total time: 0.17m\n",
      "step 00346 (0.01%) | loss: 6.276427 | lrm: 1.00 | dt: 28.22ms | tok/sec: 4,535 | mfu: -1.00 | total time: 0.17m\n",
      "step 00347 (0.01%) | loss: 6.370292 | lrm: 1.00 | dt: 28.91ms | tok/sec: 4,427 | mfu: -1.00 | total time: 0.17m\n",
      "step 00348 (0.01%) | loss: 6.400814 | lrm: 1.00 | dt: 28.88ms | tok/sec: 4,431 | mfu: -1.00 | total time: 0.17m\n",
      "step 00349 (0.01%) | loss: 6.472570 | lrm: 1.00 | dt: 30.63ms | tok/sec: 4,179 | mfu: -1.00 | total time: 0.17m\n",
      "step 00350 (0.01%) | loss: 6.441851 | lrm: 1.00 | dt: 25.93ms | tok/sec: 4,935 | mfu: -1.00 | total time: 0.17m\n",
      "step 00351 (0.01%) | loss: 6.429493 | lrm: 1.00 | dt: 26.16ms | tok/sec: 4,892 | mfu: -1.00 | total time: 0.17m\n",
      "step 00352 (0.01%) | loss: 6.401797 | lrm: 1.00 | dt: 23.61ms | tok/sec: 5,422 | mfu: -1.00 | total time: 0.17m\n",
      "step 00353 (0.01%) | loss: 6.382928 | lrm: 1.00 | dt: 32.34ms | tok/sec: 3,958 | mfu: -1.00 | total time: 0.17m\n",
      "step 00354 (0.01%) | loss: 6.291820 | lrm: 1.00 | dt: 27.40ms | tok/sec: 4,671 | mfu: -1.00 | total time: 0.17m\n",
      "step 00355 (0.01%) | loss: 6.356454 | lrm: 1.00 | dt: 28.22ms | tok/sec: 4,535 | mfu: -1.00 | total time: 0.17m\n",
      "step 00356 (0.01%) | loss: 6.500033 | lrm: 1.00 | dt: 28.74ms | tok/sec: 4,453 | mfu: -1.00 | total time: 0.17m\n",
      "step 00357 (0.01%) | loss: 6.516838 | lrm: 1.00 | dt: 32.50ms | tok/sec: 3,938 | mfu: -1.00 | total time: 0.17m\n",
      "step 00358 (0.01%) | loss: 6.582289 | lrm: 1.00 | dt: 31.75ms | tok/sec: 4,030 | mfu: -1.00 | total time: 0.17m\n",
      "step 00359 (0.01%) | loss: 6.646499 | lrm: 1.00 | dt: 38.74ms | tok/sec: 3,304 | mfu: -1.00 | total time: 0.17m\n",
      "step 00360 (0.01%) | loss: 6.714155 | lrm: 1.00 | dt: 29.06ms | tok/sec: 4,404 | mfu: -1.00 | total time: 0.17m\n",
      "step 00361 (0.01%) | loss: 6.762904 | lrm: 1.00 | dt: 23.57ms | tok/sec: 5,430 | mfu: -1.00 | total time: 0.17m\n",
      "step 00362 (0.01%) | loss: 6.784146 | lrm: 1.00 | dt: 23.15ms | tok/sec: 5,529 | mfu: -1.00 | total time: 0.17m\n",
      "step 00363 (0.01%) | loss: 6.785459 | lrm: 1.00 | dt: 30.93ms | tok/sec: 4,138 | mfu: -1.00 | total time: 0.17m\n",
      "step 00364 (0.01%) | loss: 6.759902 | lrm: 1.00 | dt: 31.23ms | tok/sec: 4,098 | mfu: -1.00 | total time: 0.17m\n",
      "step 00365 (0.01%) | loss: 6.720576 | lrm: 1.00 | dt: 30.61ms | tok/sec: 4,182 | mfu: -1.00 | total time: 0.17m\n",
      "step 00366 (0.01%) | loss: 6.691678 | lrm: 1.00 | dt: 24.53ms | tok/sec: 5,217 | mfu: -1.00 | total time: 0.18m\n",
      "step 00367 (0.01%) | loss: 6.723004 | lrm: 1.00 | dt: 22.81ms | tok/sec: 5,610 | mfu: -1.00 | total time: 0.18m\n",
      "step 00368 (0.01%) | loss: 6.760473 | lrm: 1.00 | dt: 26.66ms | tok/sec: 4,802 | mfu: -1.00 | total time: 0.18m\n",
      "step 00369 (0.01%) | loss: 6.847558 | lrm: 1.00 | dt: 32.72ms | tok/sec: 3,911 | mfu: -1.00 | total time: 0.18m\n",
      "step 00370 (0.01%) | loss: 6.882127 | lrm: 1.00 | dt: 31.08ms | tok/sec: 4,118 | mfu: -1.00 | total time: 0.18m\n",
      "step 00371 (0.01%) | loss: 6.919495 | lrm: 1.00 | dt: 27.96ms | tok/sec: 4,577 | mfu: -1.00 | total time: 0.18m\n",
      "step 00372 (0.01%) | loss: 6.895980 | lrm: 1.00 | dt: 29.51ms | tok/sec: 4,338 | mfu: -1.00 | total time: 0.18m\n",
      "step 00373 (0.01%) | loss: 6.880986 | lrm: 1.00 | dt: 27.62ms | tok/sec: 4,634 | mfu: -1.00 | total time: 0.18m\n",
      "step 00374 (0.01%) | loss: 6.961531 | lrm: 1.00 | dt: 25.59ms | tok/sec: 5,001 | mfu: -1.00 | total time: 0.18m\n",
      "step 00375 (0.01%) | loss: 6.962926 | lrm: 1.00 | dt: 25.75ms | tok/sec: 4,970 | mfu: -1.00 | total time: 0.18m\n",
      "step 00376 (0.01%) | loss: 6.944565 | lrm: 1.00 | dt: 25.45ms | tok/sec: 5,029 | mfu: -1.00 | total time: 0.18m\n",
      "step 00377 (0.01%) | loss: 6.893716 | lrm: 1.00 | dt: 27.71ms | tok/sec: 4,619 | mfu: -1.00 | total time: 0.18m\n",
      "step 00378 (0.01%) | loss: 6.861192 | lrm: 1.00 | dt: 26.73ms | tok/sec: 4,788 | mfu: -1.00 | total time: 0.18m\n",
      "step 00379 (0.01%) | loss: 6.865492 | lrm: 1.00 | dt: 26.21ms | tok/sec: 4,883 | mfu: -1.00 | total time: 0.18m\n",
      "step 00380 (0.01%) | loss: 6.802918 | lrm: 1.00 | dt: 25.96ms | tok/sec: 4,929 | mfu: -1.00 | total time: 0.18m\n",
      "step 00381 (0.01%) | loss: 6.629079 | lrm: 1.00 | dt: 26.70ms | tok/sec: 4,794 | mfu: -1.00 | total time: 0.18m\n",
      "step 00382 (0.01%) | loss: 6.637819 | lrm: 1.00 | dt: 28.25ms | tok/sec: 4,530 | mfu: -1.00 | total time: 0.18m\n",
      "step 00383 (0.01%) | loss: 6.721813 | lrm: 1.00 | dt: 30.54ms | tok/sec: 4,191 | mfu: -1.00 | total time: 0.18m\n",
      "step 00384 (0.01%) | loss: 6.695979 | lrm: 1.00 | dt: 27.08ms | tok/sec: 4,727 | mfu: -1.00 | total time: 0.18m\n",
      "step 00385 (0.01%) | loss: 6.712197 | lrm: 1.00 | dt: 24.75ms | tok/sec: 5,172 | mfu: -1.00 | total time: 0.18m\n",
      "step 00386 (0.01%) | loss: 6.781397 | lrm: 1.00 | dt: 30.76ms | tok/sec: 4,161 | mfu: -1.00 | total time: 0.18m\n",
      "step 00387 (0.01%) | loss: 6.790529 | lrm: 1.00 | dt: 26.75ms | tok/sec: 4,785 | mfu: -1.00 | total time: 0.18m\n",
      "step 00388 (0.01%) | loss: 6.881217 | lrm: 1.00 | dt: 22.85ms | tok/sec: 5,602 | mfu: -1.00 | total time: 0.19m\n",
      "step 00389 (0.01%) | loss: 6.866404 | lrm: 1.00 | dt: 26.62ms | tok/sec: 4,807 | mfu: -1.00 | total time: 0.19m\n",
      "step 00390 (0.01%) | loss: 6.865647 | lrm: 1.00 | dt: 24.41ms | tok/sec: 5,244 | mfu: -1.00 | total time: 0.19m\n",
      "step 00391 (0.01%) | loss: 6.870397 | lrm: 1.00 | dt: 23.05ms | tok/sec: 5,554 | mfu: -1.00 | total time: 0.19m\n",
      "step 00392 (0.01%) | loss: 6.897623 | lrm: 1.00 | dt: 29.34ms | tok/sec: 4,363 | mfu: -1.00 | total time: 0.19m\n",
      "step 00393 (0.01%) | loss: 6.865638 | lrm: 1.00 | dt: 24.15ms | tok/sec: 5,299 | mfu: -1.00 | total time: 0.19m\n",
      "step 00394 (0.01%) | loss: 6.829092 | lrm: 1.00 | dt: 28.55ms | tok/sec: 4,482 | mfu: -1.00 | total time: 0.19m\n",
      "step 00395 (0.01%) | loss: 6.771133 | lrm: 1.00 | dt: 26.66ms | tok/sec: 4,801 | mfu: -1.00 | total time: 0.19m\n",
      "step 00396 (0.01%) | loss: 6.753351 | lrm: 1.00 | dt: 22.87ms | tok/sec: 5,596 | mfu: -1.00 | total time: 0.19m\n",
      "step 00397 (0.01%) | loss: 6.716969 | lrm: 1.00 | dt: 26.37ms | tok/sec: 4,853 | mfu: -1.00 | total time: 0.19m\n",
      "step 00398 (0.01%) | loss: 6.664169 | lrm: 1.00 | dt: 24.05ms | tok/sec: 5,323 | mfu: -1.00 | total time: 0.19m\n",
      "step 00399 (0.01%) | loss: 6.665192 | lrm: 1.00 | dt: 22.37ms | tok/sec: 5,721 | mfu: -1.00 | total time: 0.19m\n",
      "step 00400 (0.01%) | loss: 6.650705 | lrm: 1.00 | dt: 29.88ms | tok/sec: 4,283 | mfu: -1.00 | total time: 0.19m\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ericsilberstein/.local/share/uv/python/cpython-3.10.18-macos-aarch64-none/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/ericsilberstein/.local/share/uv/python/cpython-3.10.18-macos-aarch64-none/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/ericsilberstein/Documents/ericsilberstein1-repos/nanogpt-learning/my_nanochat/scripts/my_mid_train.py\", line 248, in <module>\n",
      "    smooth_train_loss = ema_beta * smooth_train_loss + (1 - ema_beta) * train_loss.item()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_mid_train \\\n",
    "    --model_tag=d4 \\\n",
    "    --max_seq_len=128 \\\n",
    "    --device_batch_size=1 \\\n",
    "    --total_batch_size=128 \\\n",
    "    --eval_tokens=1280"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938ce23-fc74-4161-8964-8def2ddaaf7e",
   "metadata": {},
   "source": [
    "^ seems to be working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196ad36-2ac8-4dfd-ab42-ea6836410e83",
   "metadata": {},
   "source": [
    "#### How many tokens will we train on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fc85656-c329-472c-98de-6ef505b35217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_common import get_base_dir\n",
    "from my_tasks.my_common import MyTaskMixture\n",
    "from my_tasks.my_smoltalk import MySmolTalk\n",
    "from my_tasks.my_mmlu import MyMMLU\n",
    "from my_tasks.my_gsm8k import MyGSM8K\n",
    "from my_tasks.my_customjson import MyCustomJSON\n",
    "from my_tasks.my_spellingbee import MySimpleSpelling, MySpellingBee\n",
    "from my_nanochat.my_tokenizer import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce6006e5-c7ba-4d05-ba31-83c95c2e4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = get_base_dir()\n",
    "identity_conversations_filepath = os.path.join(base_dir, \"identity_conversations.jsonl\")\n",
    "train_dataset = MyTaskMixture([\n",
    "    MySmolTalk(split=\"train\"), # 460K rows of general conversations\n",
    "    MyMMLU(subset=\"auxiliary_train\", split=\"train\"), # 100K rows of multiple choice problems drawn from ARC, MC_TEST, OBQA, RACE\n",
    "    MyGSM8K(subset=\"main\", split=\"train\"), # 8K rows teaching simple math and (calculator) tool use\n",
    "    MyCustomJSON(filepath=identity_conversations_filepath), # 1000 rows of synthetic identity conversations\n",
    "    MyCustomJSON(filepath=identity_conversations_filepath), # let's do 2 epochs of these\n",
    "    MySimpleSpelling(size=200000, split=\"train\"), # 200K rows of Simple Spelling (e.g. spell the word 'apple')\n",
    "    MySpellingBee(size=80000, split=\"train\"), # 80K rows of Spelling Bee (e.g. how many 'r' are in 'strawberry'?)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1fc98007-4df8-441c-9cc0-eb5c7f243e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849648"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c47d3565-be92-4fa4-83c5-0b698b0fab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: <|bos|><|user_start|>Spell the word: bay (total so far: 25)\n",
      "10,000: <|bos|><|user_start|>Spell the word: tin (total so far: 4,956,861)\n",
      "20,000: <|bos|><|user_start|>Combien de 't' dans (total so far: 9,950,991)\n",
      "30,000: <|bos|><|user_start|>Consider the functi (total so far: 14,933,129)\n",
      "40,000: <|bos|><|user_start|>You are the US Pres (total so far: 19,936,407)\n",
      "50,000: <|bos|><|user_start|>Plan a trip from Ne (total so far: 24,981,555)\n",
      "60,000: <|bos|><|user_start|>Spell the word: mic (total so far: 29,890,302)\n",
      "70,000: <|bos|><|user_start|>Spell the word: bro (total so far: 34,897,761)\n",
      "80,000: <|bos|><|user_start|>What distinguishes  (total so far: 39,944,523)\n",
      "90,000: <|bos|><|user_start|>Assume the role of  (total so far: 44,896,363)\n",
      "100,000: <|bos|><|user_start|>'zibets'  'b' (total so far: 49,902,274)\n",
      "110,000: <|bos|><|user_start|>What is the connect (total so far: 54,898,446)\n",
      "120,000: <|bos|><|user_start|>Multiple Choice que (total so far: 59,994,245)\n",
      "130,000: <|bos|><|user_start|>Act like you are th (total so far: 65,006,845)\n",
      "140,000: <|bos|><|user_start|>You're an AI assist (total so far: 69,959,157)\n",
      "150,000: <|bos|><|user_start|>You're an AI assist (total so far: 74,946,893)\n",
      "160,000: <|bos|><|user_start|>Write your beginnin (total so far: 79,964,081)\n",
      "170,000: <|bos|><|user_start|>You are an AI assis (total so far: 84,904,290)\n",
      "180,000: <|bos|><|user_start|>Provide a concise,  (total so far: 89,807,537)\n",
      "190,000: <|bos|><|user_start|>Let's say I work at (total so far: 94,794,284)\n",
      "200,000: <|bos|><|user_start|>I've been offered a (total so far: 99,780,945)\n",
      "210,000: <|bos|><|user_start|>Spell the word: mus (total so far: 104,855,575)\n",
      "220,000: <|bos|><|user_start|>Spell the word: pet (total so far: 109,906,016)\n",
      "230,000: <|bos|><|user_start|>Spell the word: bat (total so far: 114,908,007)\n",
      "240,000: <|bos|><|user_start|>Provide a concise,  (total so far: 119,916,389)\n",
      "250,000: <|bos|><|user_start|>Hello<|user_end|><| (total so far: 124,878,892)\n",
      "260,000: <|bos|><|user_start|>You are a private i (total so far: 130,011,550)\n",
      "270,000: <|bos|><|user_start|>You are given the f (total so far: 135,080,969)\n",
      "280,000: <|bos|><|user_start|>You are an AI assis (total so far: 140,146,573)\n",
      "290,000: <|bos|><|user_start|>Compte les t dans \" (total so far: 145,163,121)\n",
      "300,000: <|bos|><|user_start|>It takes Bryan 5 mi (total so far: 150,165,525)\n",
      "310,000: <|bos|><|user_start|>Spell the word: cus (total so far: 155,169,140)\n",
      "320,000: <|bos|><|user_start|>Can quitting your j (total so far: 160,236,059)\n",
      "330,000: <|bos|><|user_start|>Your response shoul (total so far: 165,169,832)\n",
      "340,000: <|bos|><|user_start|>For a square inscri (total so far: 170,153,256)\n",
      "350,000: <|bos|><|user_start|>Multiple Choice que (total so far: 175,224,404)\n",
      "360,000: <|bos|><|user_start|>Your response shoul (total so far: 180,138,936)\n",
      "370,000: <|bos|><|user_start|>You are a successfu (total so far: 185,136,068)\n",
      "380,000: <|bos|><|user_start|>What is statistical (total so far: 190,075,972)\n",
      "390,000: <|bos|><|user_start|>Write about ways to (total so far: 195,053,508)\n",
      "400,000: <|bos|><|user_start|>Implement a simple  (total so far: 200,006,775)\n",
      "410,000: <|bos|><|user_start|>What is logistic re (total so far: 205,008,856)\n",
      "420,000: <|bos|><|user_start|>Spell the word: fru (total so far: 210,035,527)\n",
      "430,000: <|bos|><|user_start|>Multiple Choice que (total so far: 215,116,737)\n",
      "440,000: <|bos|><|user_start|>Write a Python func (total so far: 220,198,303)\n",
      "450,000: <|bos|><|user_start|>Spell the word: int (total so far: 225,275,122)\n",
      "460,000: <|bos|><|user_start|>You are a helpful a (total so far: 230,228,700)\n",
      "470,000: <|bos|><|user_start|>You are a 50-year-o (total so far: 235,319,219)\n",
      "480,000: <|bos|><|user_start|>What is the best wa (total so far: 240,334,281)\n",
      "490,000: <|bos|><|user_start|>Count how many 'd'  (total so far: 245,462,036)\n",
      "500,000: <|bos|><|user_start|>Given a dictionary  (total so far: 250,497,352)\n",
      "510,000: <|bos|><|user_start|>Spell the word: ove (total so far: 255,473,858)\n",
      "520,000: <|bos|><|user_start|>Spell the word: abd (total so far: 260,435,139)\n",
      "530,000: <|bos|><|user_start|>Extract and present (total so far: 265,457,755)\n",
      "540,000: <|bos|><|user_start|>A recent study anal (total so far: 270,430,745)\n",
      "550,000: <|bos|><|user_start|>Your response shoul (total so far: 275,474,748)\n",
      "560,000: <|bos|><|user_start|>I am going to start (total so far: 280,479,377)\n",
      "570,000: <|bos|><|user_start|>I'm tasked with org (total so far: 285,473,710)\n",
      "580,000: <|bos|><|user_start|>How can I use React (total so far: 290,509,711)\n",
      "590,000: <|bos|><|user_start|>You are a helpful a (total so far: 295,558,986)\n",
      "600,000: <|bos|><|user_start|>The half-hour newsc (total so far: 300,516,879)\n",
      "610,000: <|bos|><|user_start|>Consider a scenario (total so far: 305,488,788)\n",
      "620,000: <|bos|><|user_start|>Write a Python func (total so far: 310,548,220)\n",
      "630,000: <|bos|><|user_start|>You are an experien (total so far: 315,600,542)\n",
      "640,000: <|bos|><|user_start|>You are a helpful a (total so far: 320,680,615)\n",
      "650,000: <|bos|><|user_start|>Your response shoul (total so far: 325,654,931)\n",
      "660,000: <|bos|><|user_start|>Write a python prog (total so far: 330,672,270)\n",
      "670,000: <|bos|><|user_start|>Spell the word: sis (total so far: 335,738,186)\n",
      "680,000: <|bos|><|user_start|>You're a female mag (total so far: 340,861,712)\n",
      "690,000: <|bos|><|user_start|>Beckett is 12 and i (total so far: 345,949,463)\n",
      "700,000: <|bos|><|user_start|>Multiple Choice que (total so far: 350,922,854)\n",
      "710,000: <|bos|><|user_start|>I am researching th (total so far: 355,955,074)\n",
      "720,000: <|bos|><|user_start|>What is the differe (total so far: 360,990,381)\n",
      "730,000: <|bos|><|user_start|>You're an AI assist (total so far: 366,018,298)\n",
      "740,000: <|bos|><|user_start|>You are a bartender (total so far: 370,981,347)\n",
      "750,000: <|bos|><|user_start|>You're an AI assist (total so far: 376,030,794)\n",
      "760,000: <|bos|><|user_start|>Multiple Choice que (total so far: 381,015,753)\n",
      "770,000: <|bos|><|user_start|>How many times is l (total so far: 386,033,347)\n",
      "780,000: <|bos|><|user_start|>Multiple Choice que (total so far: 391,015,909)\n",
      "790,000: <|bos|><|user_start|>Spell the word: sho (total so far: 395,995,237)\n",
      "800,000: <|bos|><|user_start|>What are some innov (total so far: 400,975,884)\n",
      "810,000: <|bos|><|user_start|>Spell the word: res (total so far: 405,902,230)\n",
      "820,000: <|bos|><|user_start|>Your task is to wri (total so far: 411,030,569)\n",
      "830,000: <|bos|><|user_start|>Spell the word: fra (total so far: 416,032,838)\n",
      "840,000: <|bos|><|user_start|>What are some of th (total so far: 421,078,611)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "425846694"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens = 0\n",
    "for i, conversation in enumerate(train_dataset):\n",
    "    tokens, _ = tokenizer.render_conversation(conversation)\n",
    "    total_tokens += len(tokens)\n",
    "    if i % 10_000 == 0:\n",
    "        decoded = tokenizer.decode(tokens)\n",
    "        print(f\"{i:,d}: {decoded[:40]} (total so far: {total_tokens:,d})\")\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f53858-a9b4-48f4-9b39-5f3b5b3390cc",
   "metadata": {},
   "source": [
    "Let's say we get around 1M tokens / second again for d20 on 8xH100, so that's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "501a832a-ba60-4ea0-87f0-8dec4e94ce6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0974449"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "425846694 / 1_000_000 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee89774-f13a-4c6c-b55f-604f7452dd70",
   "metadata": {},
   "source": [
    "7 minutes? Is that right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabf8e8-a8f6-47dd-96fa-6427891ba912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "839106c3-9788-46c8-abdf-4149252aefaa",
   "metadata": {},
   "source": [
    "Code added as part of this challenge:\n",
    "\n",
    "- All of the code under `my_tasks` except for a task for ARC\n",
    "\n",
    "- Added `render_conversation()` to `MyTokenizer`\n",
    "\n",
    "- Added `load_model()` and supporting functions to `my_checkpoint_manager.py`\n",
    "\n",
    "- Created `my_mid_train.py` which needed all of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57c7d6-7cad-44b2-8aad-65d6759cfd38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
