{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0252eb6-b245-45c7-bed0-c9ef406afc72",
   "metadata": {},
   "source": [
    "## Understand Chat Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a44f5-564b-4fa3-af59-87e4cd806aea",
   "metadata": {},
   "source": [
    "Before I try mid training the d20 model I want to get the chat eval stuff in place. In [speedrun.sh](https://github.com/karpathy/nanochat/blob/master/speedrun.sh) he calls [chat_eval.py](https://github.com/karpathy/nanochat/blob/master/scripts/chat_eval.py) after midtraining. Could I also call it before to see the difference?\n",
    "\n",
    "I see I'm now going to add the ARC task that I skipped before and also `humaneval.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f44d34-45e4-4627-9066-0867566e5536",
   "metadata": {},
   "source": [
    "#### MyTokenizer.render_for_completion()\n",
    "\n",
    "See I will now need this. Go add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d3a200-1cab-45de-8803-455cc50633ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_tokenizer import get_tokenizer\n",
    "from my_tasks.my_spellingbee import MySimpleSpelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e1b199-5bfc-45fc-9dd9-da0f1363e85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Spell the word: baggers'},\n",
       "  {'role': 'assistant', 'content': 'baggers:b,a,g,g,e,r,s'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "task = MySimpleSpelling()\n",
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83dfe203-03e0-4554-b9b6-4e35e8ea93e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|bos|><|user_start|>Spell the word: baggers<|user_end|><|assistant_start|>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call render_for_completion, we want the final message to be\n",
    "# gone but do want to end with an assistant start token\n",
    "tokens = tokenizer.render_for_completion(task[0])\n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843afdb-c42a-4e51-8487-e160543b5669",
   "metadata": {},
   "source": [
    "#### run_generative_eval()\n",
    "\n",
    "Good place to start. Will copy this code into `my_chat_eval.py` and then try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a60ebc-79b0-45b8-921b-6e4cc8aaad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_tokenizer import get_tokenizer\n",
    "from my_tasks.my_gsm8k import MyGSM8K\n",
    "from scripts.my_chat_eval import run_generative_eval\n",
    "from my_nanochat.my_checkpoint_manager import load_model\n",
    "from my_nanochat.my_common import compute_init, autodetect_device_type\n",
    "from my_nanochat.my_engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d450d6-6ab2-4083-8029-ec9266d199af",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MyGSM8K(subset=\"main\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3252c7bc-e1b8-459c-b464-4f830a20a35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': \"Darrell and Allen's ages are in the ratio of 7:11. If their total age now is 162, calculate Allen's age 10 years from now.\"},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'The total ratio representing their ages is 7+11= '},\n",
       "    {'type': 'python', 'text': '7+11'},\n",
       "    {'type': 'python_output', 'text': '18'},\n",
       "    {'type': 'text',\n",
       "     'text': \"18\\nSince the fraction of the ratio that represents Allen's age is 11/18, Allen's current age is 11/18*162 = \"},\n",
       "    {'type': 'python', 'text': '11/18*162'},\n",
       "    {'type': 'python_output', 'text': '99'},\n",
       "    {'type': 'text',\n",
       "     'text': '99\\nIf Allen is currently 99 years old, in 10 years he will be 99+10 = '},\n",
       "    {'type': 'python', 'text': '99+10'},\n",
       "    {'type': 'python_output', 'text': '109'},\n",
       "    {'type': 'text', 'text': '109 years old\\n#### 109'}]}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5bcef07-2cc3-4fc7-901d-d52307242a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4 with step 500\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_type = autodetect_device_type() \n",
    "_, _, _, _, device = compute_init(device_type)\n",
    "model, tokenizer, meta_data = load_model('base', model_tag='d4', device=device, phase='eval')\n",
    "engine = Engine(model, tokenizer)\n",
    "run_generative_eval(\n",
    "    task,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    engine,\n",
    "    num_samples=1,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0,\n",
    "    top_k=50,\n",
    "    max_problems=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fda498-60c4-4dfd-94d8-2de70b6669fd",
   "metadata": {},
   "source": [
    "^ That stay on the same line thing works in Jupyter. Guess not a surprise because have seen that before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e432004-3ea5-4bff-88df-56657b26a494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_generative_eval(\n",
    "    task,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    engine,\n",
    "    num_samples=2,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0,\n",
    "    top_k=50,\n",
    "    max_problems=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcff8bd-d8e1-45a5-8c94-89a73d5e6e86",
   "metadata": {},
   "source": [
    "#### run_categorical_eval()\n",
    "\n",
    "Copy this code into `my_chat_eval.py` and then try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acfd160-304d-4679-b0e8-bf3649bdae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "075ef8d0-6310-4f77-bf7d-bea49f8cbc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see this tensor slicing technique used to \"focus\" logits, didn't realize you could do this\n",
    "# maybe not true, have used this before with torch and numpy I think, just thought of it different\n",
    "torch.tensor([1,2,3,4,5], dtype=torch.long)[[1,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9ddcc1-4779-4dd2-8476-1a897b451465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.my_tokenizer import get_tokenizer\n",
    "from my_tasks.my_mmlu import MyMMLU\n",
    "from scripts.my_chat_eval import run_categorical_eval\n",
    "from my_nanochat.my_checkpoint_manager import load_model\n",
    "from my_nanochat.my_common import compute_init, autodetect_device_type\n",
    "from my_nanochat.my_engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eecade2-b82e-4b83-a44b-7054aa2e392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MyMMLU(subset=\"all\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5f9c58-ca2e-4de9-865a-72ce542cb343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'Multiple Choice question: Positronium is an atom formed by an electron and a positron (antielectron). It is similar to the hydrogen atom, with the positron replacing the proton. If a positronium atom makes a transition from the state with n=3 to a state with n=1, the energy of the photon emitted in this transition is closest to\\n- 6.0 e=A\\n- 6.8 eV=B\\n- 12.2 eV=C\\n- 13.6 eV=D\\n\\nRespond only with the letter of the correct answer.'},\n",
       "  {'role': 'assistant', 'content': 'A'}],\n",
       " 'subject': 'college_physics',\n",
       " 'letters': ('A', 'B', 'C', 'D')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f671f0-94ea-4cb5-8e14-027bdfc43c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4 with step 500\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n",
      "final: 266/1000 (26.60%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.266"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_type = autodetect_device_type() \n",
    "_, _, _, _, device = compute_init(device_type)\n",
    "model, tokenizer, meta_data = load_model('base', model_tag='d4', device=device, phase='eval')\n",
    "engine = Engine(model, tokenizer)\n",
    "run_categorical_eval(\n",
    "    task,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    batch_size=1,\n",
    "    max_problems=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61a7ea-1dfe-49d0-b2d4-f2ef04320f94",
   "metadata": {},
   "source": [
    "### ARC Task\n",
    "\n",
    "Go implement the ARC task. Skipped before, but did look at the dataset in `challenge-26-understand-midtrain/understand-midtrain.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ba7527-ae5c-490d-a21a-ad09fb50f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_tasks.my_arc import MyARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003cdbca-c9e0-4c0b-9e28-338b705e6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MyARC(subset=\"ARC-Easy\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4e49eb4-6bb5-476a-a2a6-1a957b75d1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'Multiple Choice question: A force of 5 N is required to increase the speed of a box from a rate of 1.0 m/s to 3.0 m/s within 5 s along a level surface. What change would most likely require additional force to produce the same results?\\n- reduce the mass of the box=A\\n- increase the mass of the box=B\\n- make the surfaces of the box smooth=C\\n- make the surface of the floor smooth=D\\n\\nRespond only with the letter of the correct answer.'},\n",
       "  {'role': 'assistant', 'content': 'B'}],\n",
       " 'letters': ['A', 'B', 'C', 'D']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd4bbf9-fed2-404f-b1fb-d77b19541f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40245f8-2858-4370-9895-cd9ad0e678e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f55a5-1ce9-4120-9529-cfd5ce7a7371",
   "metadata": {},
   "source": [
    "### HumanEval Task\n",
    "\n",
    "See what it is and implement.\n",
    "\n",
    "His comment: Btw this dataset is a misnomer and has nothing to do with humans. It is a coding benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a192fd3f-2ea1-4317-9d38-337cc2583baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5e0e3fcb2d4b5d98f5cd532d41686b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset('openai/openai_humaneval', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a749d1d-8a6c-4a26-b39b-5dfcf5e2a490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/0',\n",
       " 'prompt': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n',\n",
       " 'canonical_solution': '    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n',\n",
       " 'test': \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\",\n",
       " 'entry_point': 'has_close_elements'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab7597f-b418-448e-a1da-024cb8c03f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds[0]['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaff08-712e-4b07-a67b-0e8061bb50c9",
   "metadata": {},
   "source": [
    "Going to cheat and just copy and paste all of `humaneval.py` and `execution.py` at least for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4245661-7782-48be-b238-891485e94492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from my_nanochat.execution import execute_code\n",
    "from my_tasks.humaneval import HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffbe91f-f97b-465f-a218-1fc72617c6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionResult(success=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_code('2+3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a60bd6-75ca-4994-85da-40e30355b731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionResult(success=True, stdout='5\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_code('print(2+3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71c4782-0ebe-4a4c-abb8-d25c54b568ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionResult(success=False, error=\"TypeError: 'NoneType' object is not callable\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_code('import os; print(os.getcwd())')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9e85d3c-50b5-4aa8-9a9d-1f9a28c29bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionResult(success=False, error=\"SyntaxError: '(' was never closed (<string>, line 1)\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_code('print(2+3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "792152c9-1d38-49ee-b365-2d2345975a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = HumanEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76bdae0-2db3-4074-8a40-fb6e61c2624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': '\\n\\ndef below_threshold(l: list, t: int):\\n    \"\"\"Return True if all numbers in the list l are below threshold t.\\n    >>> below_threshold([1, 2, 4, 10], 100)\\n    True\\n    >>> below_threshold([1, 20, 4, 10], 5)\\n    False\\n    \"\"\"\\n'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '\\n\\ndef below_threshold(l: list, t: int):\\n    \"\"\"Return True if all numbers in the list l are below threshold t.\\n    >>> below_threshold([1, 2, 4, 10], 100)\\n    True\\n    >>> below_threshold([1, 20, 4, 10], 5)\\n    False\\n    \"\"\"\\n\\n    for e in l:\\n        if e >= t:\\n            return False\\n    return True\\n'}],\n",
       " 'entry_point': 'below_threshold',\n",
       " 'test': '\\n\\nMETADATA = {}\\n\\n\\ndef check(candidate):\\n    assert candidate([1, 2, 4, 10], 100)\\n    assert not candidate([1, 20, 4, 10], 5)\\n    assert candidate([1, 20, 4, 10], 21)\\n    assert candidate([1, 20, 4, 10], 22)\\n    assert candidate([1, 8, 4, 10], 11)\\n    assert not candidate([1, 8, 4, 10], 10)\\n\\n'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13f982af-3827-466e-b161-1eb80a78fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conversation(conversation):\n",
    "    for message in conversation['messages']:\n",
    "        print(f\"_____{message['role']}_____\")\n",
    "        content = message['content']\n",
    "        if isinstance(content, str):\n",
    "            print(content)\n",
    "        else:\n",
    "            assert isinstance(content, list)\n",
    "            for part in content:\n",
    "                print(f\"{part['type']}: {part['text']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6994657f-45fc-4af3-a3c1-7eb2daa8ea93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____user_____\n",
      "\n",
      "\n",
      "def below_threshold(l: list, t: int):\n",
      "    \"\"\"Return True if all numbers in the list l are below threshold t.\n",
      "    >>> below_threshold([1, 2, 4, 10], 100)\n",
      "    True\n",
      "    >>> below_threshold([1, 20, 4, 10], 5)\n",
      "    False\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "_____assistant_____\n",
      "\n",
      "\n",
      "def below_threshold(l: list, t: int):\n",
      "    \"\"\"Return True if all numbers in the list l are below threshold t.\n",
      "    >>> below_threshold([1, 2, 4, 10], 100)\n",
      "    True\n",
      "    >>> below_threshold([1, 20, 4, 10], 5)\n",
      "    False\n",
      "    \"\"\"\n",
      "\n",
      "    for e in l:\n",
      "        if e >= t:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_conversation(task[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a889498f-00c9-453e-9b95-8791f5310c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], \"\"\"\n",
    "def below_threshold(l: list, t: int):\n",
    "    for e in l:\n",
    "        if e >= t:\n",
    "            return False\n",
    "    return True\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cbff63d-f15c-4282-b70b-621e2b3c9db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate(task[0], \"\"\"\n",
    "def below_threshold(l: list, t: int):\n",
    "    return not any(e >= t for e in l)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa8a77-7cf9-43a7-b23c-c2d20841e66a",
   "metadata": {},
   "source": [
    "### Back to `chat_eval.py`\n",
    "\n",
    "copy `run_chat_eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d0f51b2-6980-4cf9-9411-662b22987b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "from scripts.my_chat_eval import run_chat_eval\n",
    "from my_nanochat.my_checkpoint_manager import load_model\n",
    "from my_nanochat.my_common import compute_init, autodetect_device_type\n",
    "from my_nanochat.my_engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca5464ce-f258-49c7-907c-a3c53bf0d7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4 with step 500\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n"
     ]
    }
   ],
   "source": [
    "device_type = autodetect_device_type() \n",
    "_, _, _, _, device = compute_init(device_type)\n",
    "model, tokenizer, meta_data = load_model('base', model_tag='d4', device=device, phase='eval')\n",
    "engine = Engine(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "554f50c7-31a9-4f63-8a7d-e2ca7a884b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final: 2/5 (40.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_chat_eval('MMLU', model, tokenizer, engine, max_problems=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca8ebfe9-bb36-4d0b-99d8-1237cfc1e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_chat_eval('HumanEval', model, tokenizer, engine, max_problems=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d3fc4-9503-446c-9f73-6b33ce28545b",
   "metadata": {},
   "source": [
    "### main\n",
    "\n",
    "Add the stuff so it can run as a standalone script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "491cf1ae-161c-4589-9147-83a8febfc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2da8f00e-5efa-453e-a723-96707692c8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/mid_checkpoints/d4 with step 9\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Easy accuracy: 0.00%\n",
      "final: 0/5 (0.00%)\n",
      "ARC-Challenge accuracy: 0.00%\n",
      "final: 2/5 (40.00%)\n",
      "MMLU accuracy: 40.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "GSM8K accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "HumanEval accuracy: 0.00%\n",
      "\u001b[KRank 0 | 0/5 (0.00%)]\n",
      "==================================================\n",
      "final: 0/5 (0.00%)\n",
      "SpellingBee accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_chat_eval --source=mid --batch-size=1 --model-tag=d4 --max-problems=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65970d28-95ab-4fd7-b3fc-beb9a1e84ef1",
   "metadata": {},
   "source": [
    "### Make base_eval able to run as standalone script\n",
    "\n",
    "Unrelated to chat eval, I'm thinking that after midtraining I'll want to see the CORE metrics. I skipped making `my_base_eval.py` able to run as a script earlier. Add now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f28545e-e7a3-4f47-90ab-a6406e7ff178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"../my_nanochat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "553f10c7-d3fe-43b3-ae37-9fa5d1cc87be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autodetected device type: mps\n",
      "loading the model from /Users/ericsilberstein/.cache/my_nanochat/base_checkpoints/d4 with step 500\n",
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65536, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n",
      "Evaluating: hellaswag_zeroshot (0-shot, type: multiple_choice)... accuracy: 0.3500 | centered: 0.1333 | time: 2.03s\n",
      "Evaluating: jeopardy (10-shot, type: language_modeling)... accuracy: 0.0000 | centered: 0.0000 | time: 1.34s\n",
      "CORE metric: 0.0667\n",
      "centered results:\n",
      "{\n",
      "    \"hellaswag_zeroshot\": 0.13333332538604736,\n",
      "    \"jeopardy\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.my_base_eval \\\n",
    "    --source=base \\\n",
    "    --model-tag=d4 \\\n",
    "    --max-per-task=20 \\\n",
    "    --tasks-to-run=\"hellaswag_zeroshot|jeopardy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732eee5-f0b5-47f4-8f78-ad419963657e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e1ef7b9-a1ec-4448-a2f2-b439b3068065",
   "metadata": {},
   "source": [
    "Code added as part of this challenge:\n",
    "\n",
    "- added `render_for_completion()` to `MyTokenizer`\n",
    "   \n",
    "- added `my_arc.py` for ARC task skipped earlier\n",
    "\n",
    "- copied (breaking rule!) `humaneval.py` for HumanEval tasks and `execution.py` which it uses to execute python programs\n",
    "\n",
    "- all that needed to create `my_chat_eval.py`\n",
    "\n",
    "- also added made `my_base_eval.py` able to run as a standalone script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d80be0-5121-4e99-827f-234190bff152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
