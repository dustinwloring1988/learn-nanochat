{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607c7b03-7f87-48c1-8657-ef004b9d31bf",
   "metadata": {},
   "source": [
    "This is not the main notebook in this challenge. Start with `understand-engine.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9fe3fb4-7564-4189-838e-ee6cb370a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082abb05-a530-455c-af95-c3a9bbf62b8c",
   "metadata": {},
   "source": [
    "I'm now going to start copying other parts of `engine.py` to `my_engine.py`.\n",
    "\n",
    "Much of the code looks like it applies after pre-training once we have special tokens, a state machine to keep track of turns, a calculator to evaluate python expressions, etc. I'm going to try to leave all that out for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f04316-c281-4aaf-96f6-c4daef45a084",
   "metadata": {},
   "source": [
    "#### sample_next_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95be94e8-caa6-4256-87a3-94f3a1bfc6c2",
   "metadata": {},
   "source": [
    "There is a function `sample_next_token(logits, rng, temperature=1.0, top_k=None)` that looks very similar to `GPT.generate()` that we looked at in `add-generate-to-gpt.ipynb` in this same challenge.\n",
    "\n",
    "Looks clear except not sure why we need `idx.gather(1, choice)` because aren't we already dealing in indexes? Maybe it's an easy way to get the dimensions to be right? I'll hand copy the function and then play with it a bit. Ah, in copying it, I saw that for top_k we first cut down to just the top k, so after choosing we have to convert back to our original indexes. This is unlike in `GPT.generate()` which achieves the same thing by changing all the non-top-k ones to -inf so they won't be chosen. This way feels a bit cleaner and probably more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a16679-d610-4bd4-b0c3-4b00557bea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_nanochat.my_engine import sample_next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e5e7d5-bcd6-4d86-87a9-337871338284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9216,  1.8903,  0.9157,  0.5659, -0.4409],\n",
       "        [-0.7331, -0.1370, -1.1918,  0.2197, -0.8647]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 2\n",
    "V = 5\n",
    "logits = torch.randn((B,V))\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f89067d-0b3b-4f36-91f8-def72cce0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = torch.Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2207f312-940a-446c-b3a5-ff7396c89f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_next_token(logits, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8cb9073-ca0a-4326-919b-65d42da2d65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_next_token(logits, rng, temperature=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f25b89c-2d1e-4dc5-858b-f5f817dc05bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_next_token(logits, rng, temperature=5.0, top_k=1) # expect 1, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88458c6f-192b-47af-a1fb-b812596cf6a1",
   "metadata": {},
   "source": [
    "#### Engine.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e9e969-f3f7-4f5c-9f24-d0f9ffb60657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../my_nanochat')\n",
    "import torch\n",
    "from my_nanochat.my_common import get_base_dir\n",
    "from my_nanochat.my_checkpoint_manager import build_model\n",
    "from my_nanochat.my_engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94617f82-aef4-4f20-bc78-a4e96399087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with config: {'sequence_len': 128, 'vocab_size': 65537, 'n_layer': 4, 'n_head': 2, 'n_kv_head': 2, 'n_embd': 256}\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = os.path.join(get_base_dir(), \"base_checkpoints\", \"d4\")\n",
    "model, tokenizer, meta_data = build_model(checkpoint_dir, step=10, device=torch.get_default_device(), phase=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a1d7ad-b5c1-48c2-812a-17de737f968b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65536, 28466]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens = tokenizer.encode('Hello', prepend=tokenizer.get_bos_token_id())\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49d98ed-ae95-44f9-a811-89fee815bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = Engine(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155f8fd7-1395-4110-bfb0-574bb912efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49458]\n",
      "[331]\n",
      "[28461]\n",
      "[46644]\n",
      "[3247]\n",
      "[3493]\n",
      "[33440]\n",
      "[47865]\n",
      "[21686]\n",
      "[24330]\n"
     ]
    }
   ],
   "source": [
    "for token_column, token_masks in engine.generate(prompt_tokens, max_tokens=10):\n",
    "    print(token_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826fe60d-bd73-4f45-9245-fc57cf50f2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49458, 49458]\n",
      "[331, 28461]\n",
      "[46644, 8527]\n",
      "[3493, 33440]\n",
      "[47865, 21686]\n",
      "[24330, 403]\n",
      "[2236, 1581]\n",
      "[51928, 10607]\n",
      "[50547, 40263]\n",
      "[31660, 47889]\n"
     ]
    }
   ],
   "source": [
    "for token_column, token_masks in engine.generate(prompt_tokens, max_tokens=10, num_samples=2):\n",
    "    print(token_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4136b0-d0f5-4a9c-a5f2-33cf73438548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n",
      "[668, 668]\n"
     ]
    }
   ],
   "source": [
    "# expect same samples\n",
    "for token_column, token_masks in engine.generate(prompt_tokens, max_tokens=10, num_samples=2, temperature=0):\n",
    "    print(token_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4b8b0-5923-4663-822d-4e90289fa26c",
   "metadata": {},
   "source": [
    "#### Engine.generate_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a88a4b-ef3f-4347-8476-358d0d1b9c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[65536,\n",
       "   28466,\n",
       "   49458,\n",
       "   331,\n",
       "   28461,\n",
       "   46644,\n",
       "   3247,\n",
       "   3493,\n",
       "   33440,\n",
       "   47865,\n",
       "   21686,\n",
       "   24330]],\n",
       " [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.generate_batch(prompt_tokens, max_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0869e4b5-55bd-4b91-920f-1abc62f6fd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[65536,\n",
       "   28466,\n",
       "   49458,\n",
       "   331,\n",
       "   46644,\n",
       "   3493,\n",
       "   47865,\n",
       "   24330,\n",
       "   2236,\n",
       "   51928,\n",
       "   50547,\n",
       "   31660],\n",
       "  [65536,\n",
       "   28466,\n",
       "   49458,\n",
       "   28461,\n",
       "   8527,\n",
       "   33440,\n",
       "   21686,\n",
       "   403,\n",
       "   1581,\n",
       "   10607,\n",
       "   40263,\n",
       "   47889]],\n",
       " [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.generate_batch(prompt_tokens, max_tokens=10, num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a54a94-9b7a-4fbb-be85-2fe664da4b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
